<!DOCTYPE html>
<html lang="zh-CN">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<title>Pipelinedb文档概览</title>
	<link href="%3cnil%3e" rel="alternate" type="application/rss+xml" title="Let&#39;s Go!" />
	<base href="https://zhangeamon.top/">
	<link href="https://zhangeamon.top/css/style.min.css" rel="stylesheet">
	<link href="https://zhangeamon.top/css/main.css" rel="stylesheet">
        <script src="https://zhangeamon.top/js/jquery-1.12.4.min.js"></script>
        <script src="https://zhangeamon.top/js/main.js"></script>
        
        <a href=https://github.com/bodani/blog-hugo><img style="position: absolute; top: 0; left: 0; border: 0;" src="images/forkme_left_red_aa0000.png" alt="Fork me on GitHub" data-canonical-src="images/forkme_left_red_aa0000.png"></a>
               
 
        
        <script>
          var _hmt = _hmt || [];
            (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?1f6605a363a50554aa03adcc685b7699";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
          })();
       </script>
</head>
<body>
<header class="site-header">
	<div class="container">
		<h1 class="site-title"><a href="https://zhangeamon.top/">Let&#39;s Go!</a></h1>
		<p class="lead blog-description">Let&#39;s build private cloud native together,  go! go! go! </p>
	</div>
</header>

<nav class="main-nav">
  <div class="container" id="main-navbar">
    <ul class="main-menu">
            <li class="navlinks-container">
               <a class="navlinks-parent" href="javascript:void(0)" title="" >数据库</a>
                <div class="navlinks-children">
                  <a href="https://zhangeamon.top//content/postgres/" title="">Postgres</a>
                  <a href="https://zhangeamon.top/mysql/" title="">Mysql</a>
                  
                  <a href="https://zhangeamon.top/es/" title="">ElasticSearch</a>
                  <a href="https://zhangeamon.top/dw/" title="">DataWarehose</a>
                </div>
            </li>

            <li class="navlinks-container">
               <a class="navlinks-parent" href="javascript:void(0)" title="" >云平台</a>
                <div class="navlinks-children">
                  <a href="https://zhangeamon.top/kvm/" title="">虚拟化</a>
                  <a href="https://zhangeamon.top/storage/" title="">云存储</a>
                  <a href="https://zhangeamon.top/docker/" title="">Docker</a>
                  <a href="https://zhangeamon.top/k8s/" title="">Kubernetes</a>
                  <a href="https://zhangeamon.top/elk/" title="">日志</a>
                  <a href="https://zhangeamon.top/istio/" title="">微服务治理</a>
                </div>
            </li>
             
            <li class="navlinks-container">
               <a class="navlinks-parent" href="javascript:void(0)" title="" >中间件</a>
                <div class="navlinks-children">
                  <a href="https://zhangeamon.top/redis/" title="">Redis</a>
                  <a href="https://zhangeamon.top/kafka/" title="">Kafka</a>
                  <a href="https://zhangeamon.top/memcached/" title="">Memcached</a>
                  <a href="https://zhangeamon.top/rabbitmq/" title="">RabbitMQ</a>
                  <a href="https://zhangeamon.top/middleware/" title="">其他</a>
                </div>
            </li>
           
            <li class="navlinks-container">
               <a class="navlinks-parent" href="javascript:void(0)" title="" >写代码</a>
                <div class="navlinks-children">
                  <a href="https://zhangeamon.top/python/" title="">Python</a>
                  <a href="https://zhangeamon.top/go/" title="">GO</a>
                  <a href="https://zhangeamon.top/lua/" title="">Lua</a>
                  <a href="https://zhangeamon.top/ansible/" title="">Ansible</a>
                </div>
            </li>
	    <li><a href="https://zhangeamon.top/monitor/" title="">监控</a></li>
	    <li><a href="https://zhangeamon.top/network-security/" title="">网络/安全</a></li>
            <li><a href="https://zhangeamon.top/linux/" title=""> Linux </a></li>
	    <li><a href="https://zhangeamon.top/about/" title="">关于</a></li>
     </ul>
  </div>
</nav>

<div class="main-content container">
	<div class="post">
		<h1 class="post-title">Pipelinedb文档概览</h1>
		<div class="post-meta">
			<p>2018年12月12日</p>
		</div>
		<p><a href="http://docs.pipelinedb.com/index.html">官方文档</a></p>
<h4 id="介绍">介绍</h4>
<p>What PipelineDB is <br>
What PipelineDB is not</p>
<h4 id="quitstart">QuitStart</h4>
<p>一个统计wiki浏览的例子</p>
<h4 id="安装">安装</h4>
<p>各种环境安装</p>
<h4 id="continuous-views">Continuous Views</h4>
<p>定义流视图，其实就是定义 统计分析的QUERY， 例如select id, count(*), avg(x), &hellip; from table group by &hellip;;
定义好之后，数据插入table，这个流视图就会不断增量的进行统计，你只要查询这个流视图，就可以查看到实时的统计结果。
数据库中存储的是实时统计的结果（实际上是在内存中进行增量合并的，增量的方式持久化）。</p>
<p>CREATE CONTINUOUS VIEW <br>
DROP CONTINUOUS VIEW <br>
TRUNCATE CONTINUOUS VIEW <br>
Viewing Continuous Views <br>
Data Retrieval <br>
Time-to-Live (TTL) Expiration <br>
Activation and Deactivation <br>
Examples</p>
<h4 id="continuous-transforms">Continuous Transforms</h4>
<p>与流视图不同的是，transform是用来转换数据流的，所以它可以不保留数据，但是可以设定条件，当记录满足条件时，就触发事件。</p>
<p>用途，将输入的数据流进行转换处理，过滤，加工等，用于复杂的业务逻辑，比如多个来源的数据流的合并加工。与现有的表进行joins操作,可以将结果传入其他流中，实现持续转换。</p>
<p>例如监视传感器的值，当值的范围超出时，触发报警（如通过REST接口发给指定的server），或者将报警记录下来（通过触发器函数）。</p>
<p>CREATE CONTINUOUS TRANSFORM <br>
DROP CONTINUOUS TRANSFORM <br>
Viewing Continuous Transforms <br>
Built-in Transform Triggers <br>
Creating Your Own Trigger</p>
<h4 id="streams">Streams</h4>
<p>流视图和transform都是基于流的，所以流是基础。</p>
<p>我们首先需要定义流，往流里面写数据，然后在流动的数据中使用流视图或者transform对数据进行实时处理。</p>
<p>Writing To Streams <br>
Output Streams <br>
stream_targets <br>
Arrival Ordering <br>
Event Expiration</p>
<h4 id="built-in-functionality">Built-in Functionality</h4>
<p>内置的函数</p>
<p>General <br>
Aggregates <br>
PipelineDB-specific Types <br>
PipelineDB-specific Functions <br>
Miscellaneous Functions</p>
<h4 id="continuous-aggregates">Continuous Aggregates</h4>
<p>聚合的介绍，通常流处理分两类，即前面讲的</p>
<p>流视图（通常是实时聚合的结果），比如按分钟实时的对红绿灯的车流统计数据绘图，或者按分钟对股票的实时数据进行绘图。</p>
<p>transform（事件处理机制），比如监控水质，传感器的值超出某个范围时，记录日志，并同时触发告警（发送给server）。</p>
<p>PipelineDB-specific Aggregates <br>
Combine <br>
CREATE AGGREGATE <br>
General Aggregates <br>
Statistical Aggregates <br>
Ordered-set Aggregates <br>
Hypothetical-set Aggregates <br>
Unsupported Aggregates</p>
<h4 id="clients">Clients</h4>
<p>几种常见的客户端用法，实际上支持PostgreSQL的都支持pipelinedb，他们的连接协议是一致的。</p>
<p>Python <br>
Ruby <br>
Java</p>
<h4 id="probabilistic-data-structures--algorithms">Probabilistic Data Structures &amp; Algorithms</h4>
<p>概率统计相关的功能，例如HLL等。用起来也非常的爽，例如统计网站的UV，或者红绿灯通过的汽车编号唯一值车流，通过手机信号统计基站辐射方圆多少公里的按时UV等。</p>
<p>Bloom Filter <br>
Count-Min Sketch <br>
Filtered-Space Saving Top-K <br>
HyperLogLog <br>
T-Digest</p>
<h4 id="sliding-windows">Sliding Windows</h4>
<p>因为很多场景的数据有时效，或者有时间窗口的概念，所以pipelinedb提供了窗口分片的接口，允许用户对数据的时效进行定义。</p>
<p>例如仅仅统计最近一分钟的时间窗口内的统计数据。</p>
<p>比如热力图，展示最近一分钟的热度，对于旧的数据不关心，就可以适应SW进行定义，从而保留的数据少，对机器的要求低，效率还高。</p>
<p>Examples <br>
Sliding Aggregates <br>
Temporal Invalidation <br>
Multiple Windows <br>
step_factor</p>
<h4 id="continuous-joins">Continuous JOINs</h4>
<p>流视图 支持JOIN，支持JOIN，支持JOIN，重要的事情说三遍。</p>
<p>流 JOIN 流(未来版本支持,目前可以通过transform间接实现)</p>
<p>流 JOIN TABLE(已支持)</p>
<p>Stream-table JOINs <br>
Supported Join Types <br>
Examples <br>
Stream-stream JOINs</p>
<h4 id="backup">Backup</h4>
<p>与pg数据相同，如果单独备份出一个视图需要与对应的物化表一同备份。</p>
<h4 id="replication">Replication</h4>
<p>依赖于pg数据库流复制， HA 可以使用Patroni</p>
<h4 id="integrations">Integrations</h4>
<ul>
<li>
<p>Apache Kafka</p>
</li>
<li>
<p>Amazon Kinesis</p>
</li>
</ul>
<h4 id="statistics">Statistics</h4>
<p>统计信息，对于DBA有很大的帮助</p>
<p>pipelinedb.proc_stats <br>
pipelinedb.query_stats <br>
pipelinedb.stream_stats <br>
pipelinedb.db_stats</p>
<h4 id="configuration">Configuration</h4>
<h5 id="pipelinedbstream_insert_level">pipelinedb.stream_insert_level</h5>
<p>性能最佳，可以设置为async，数据写入内存即响应写入客户端。<br>
性能适中，设置为sync_receive，数据被worker process接收后响应写入客户端。 (默认值)
测试环境, sync_commit</p>
<h5 id="pipelinedbnum_combiners">pipelinedb.num_combiners</h5>
<p>有多少个combiner进程。由于combiner进程负责将计算好的结果数据合并落盘，所以当设置的COMBINER进程个数足够达到IO瓶颈时为宜。设置取决于IO能力。</p>
<h5 id="pipelinedbcommit_interval">pipelinedb.commit_interval</h5>
<p>每个combiner进程，会先将合并的结果数据HOLD在combiner_work_mem，以提高性能。commit_interval表示间隔多长时间刷提交结果。</p>
<h5 id="pipelinedbnum_workers">pipelinedb.num_workers</h5>
<p>worker进程负责计算STREAM上定义的continue view, continue transform。<br>
设置取决于有多少STREAM，有多少continue view, continue transform，有多少CPU能力。</p>
<h6 id="pipelinedbnum_queues">pipelinedb.num_queues</h6>
<p>当数据从STREAM取出（worker和combiner批量消费、计算stream内的数据，并将结果持久化到磁盘，然后从stream中清掉对应的流数据。整个过程需要queue process，确保做这一系列动作的时候，不影响用户持续将数据写入stream。） <br>
设置取决于num_workers，num_combiners。</p>
<h5 id="pipelinedbnum_reapers">pipelinedb.num_reapers</h5>
<p>reaper进程，用于清除设置了TTL的continue view的过期数据。<br>
类似于后台定时任务进程。不需要太多，设置取决于有多少设置了TTL的continue view。</p>
<h5 id="pipelinedbttl_expiration_batch_size">pipelinedb.ttl_expiration_batch_size</h5>
<p>清除设置了TTL的continue view的过期数据。
一个事务中，最多清理多少条数据，主要防止长事务。</p>
<h5 id="pipelinedbttl_expiration_threshold">pipelinedb.ttl_expiration_threshold</h5>
<p>当超出设置阈值多少后，开始清理过期数据。<br>
例如设置TTL为2天，设置ttl_expiration_threshold为5%。<br>
那么当数据过期达到 (2 + 5%*2) 天后，才开始触发清理。<br>
也可以理解为TTL continue view的膨胀率。</p>
<h5 id="pipelinedbbatch_size">pipelinedb.batch_size</h5>
<p>当查询continuous view时，会触发PIPELINEDB对continuous view的结果进行持久化。 <br>
batch_size设置，表示执行continuous view查询前，最多允许多少个events堆积(例如insert stream的条数)。 <br>
设置越大，可能增加查询continuous view的响应延迟，或者当数据库CRASH时丢掉更多数据。</p>
<h5 id="pipelinedbcombiner_work_mem">pipelinedb.combiner_work_mem</h5>
<p>每个combiner的工作内存大小。combiner process在合并WORKER计算结果时用于排序，HASH TABLE等。<br>
如果combiner使用内存超出这个设置，则使用磁盘。</p>
<h5 id="pipelinedbanonymous_update_checks">pipelinedb.anonymous_update_checks</h5>
<p>Toggles whether PipelineDB should anonymous check if a new version is available. Default: true.</p>
<h5 id="pipelinedbmatrels_writable">pipelinedb.matrels_writable</h5>
<p>是否允许continue view被直接修改。（直接通过SQL修改，而不是仅被combiner进程修改）
Toggles whether changes can be directly made to materialization tables. Default: false.</p>
<h5 id="pipelinedbipc_hwm">pipelinedb.ipc_hwm</h5>
<p>Sets the high watermark for IPC messages between worker and combiner processes. Default: 10.</p>
<h5 id="pipelinedbmax_wait">pipelinedb.max_wait</h5>
<p>与pipelinedb.batch_size含义类似，只是时间度量。<br>
执行continuous view查询前，最多允许等多长时间。</p>
<h5 id="pipelinedbfillfactor">pipelinedb.fillfactor</h5>
<p>continue view的fillfactor，由于流计算的结果continue view需要经常被combiner更新，所以多数为更新操作，那么设置合理的fillfactor可以使得更容易HOT（避免索引膨胀）。<br>
Default: 50.</p>
<h5 id="pipelinedbsliding_window_step_factor">pipelinedb.sliding_window_step_factor</h5>
<p>滑窗continue view的小窗颗粒度。
例如定义滑窗为1小时，那么这个视图就是最近一小时的统计，为了得到这个统计值，必须实时老化一小时前的数据，保持统计是最近一小时的。怎么做到的呢？<br>
实际上pipelinedb内部通过定义比滑窗更小粒度窗口的实时统计，把窗口切成更小的窗口，查询时对小粒度窗口进行汇聚产生大窗口的数据。<br>
例如定义的窗口为1小时，那么可以按分钟的粒度进行统计，查询时，汇聚最近的60个窗口的数据，得到小时的窗口数据。<br>
颗粒度为5，表示5%的颗粒。例如定义窗口为1小时，那么颗粒就是5%*60min = 3min，也就是说会3分钟统计一个值，最后查询时汇聚为1小时的窗口值</p>

	</div>
	<ul class="pager">
		 &nbsp;<li class="previous"><a href="https://zhangeamon.top/monitor/introduce/">«常用监控介绍</a></li>
		 &nbsp;<li class="next"><a href="https://zhangeamon.top/postgres/pipelinedb02/">Pipelinedb 简介»</a></li>
	</ul>
</div>
<footer class="site-footer">
	<div class="container">
		<p>本站使用 <a href="https://gohugo.io/">Hugo</a> 并基于 <a href="https://github.com/bodani/Simple">Simple</a> 主题构建.&nbsp;
		<p class="text-muted small">&copy; 2018-2021 by Eamon</p>
	</div>
</footer>

</body>
</html>

