<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Postgres on Let&#39;s Go!</title>
    <link>https://zhangeamon.top/postgres/</link>
    <description>Recent content in Postgres on Let&#39;s Go!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Jan 2021 13:49:11 +0800</lastBuildDate>
    
	<atom:link href="https://zhangeamon.top/postgres/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>hot update</title>
      <link>https://zhangeamon.top/postgres/hotupdate/</link>
      <pubDate>Thu, 14 Jan 2021 13:49:11 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/hotupdate/</guid>
      <description>What is HOT HOT是“Heap Only Tuple”（仅元组堆）的缩写, 用来提高update效率。
行的新版本和旧版本位于同一块中时，该行的外部地址（原始行指针）保持不变，利用hot link指针进行转发地址。索引不需要任何改动。
前提条件   包含更新行的块中必须有足够的空间
  在已修改值的任何列上均未定义索引
  生产应用 使用fillfactor以获取HOT更新
例子 建表
CREATE TABLE mytable ( id integer PRIMARY KEY, val integer NOT NULL ) WITH (autovacuum_enabled = off); INSERT INTO mytable SELECT *, 0 FROM generate_series(1, 235) AS n; 8k page 物理分布
SELECT ctid, id, val FROM mytable; ctid | id | val ---------+-----+----- (0,1) | 1 | 0 (0,2) | 2 | 0 (0,3) | 3 | 0 (0,4) | 4 | 0 (0,5) | 5 | 0 .</description>
    </item>
    
    <item>
      <title>数据库优化思考 - 模块调优</title>
      <link>https://zhangeamon.top/postgres/thinking_in_db_tune/</link>
      <pubDate>Wed, 13 Jan 2021 09:04:35 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/thinking_in_db_tune/</guid>
      <description>开始乱说 主要是结合postgres数据库自身特点，根据具体的业务场景，作出相应调整，使其更加合理。
数据库作为一个整体对外提供服务，单是其内部是由不同的功能模块组成，相互协调来共同完成任务。
各个功能模块完成不同的功能，每个模块的特点也不同，在调整的时候至少需要理解各个模块实现的基本原理（属于内功需修炼）才好下手。
各个功能模块又相互影响，共享资源，也就是他们之间会存在竞争资源。比如当系统发生gc时对几乎各个模块都会产生影响。
有些问题可能是多个模块共同产生的。 最常见的如一条慢sql，可能引起的原因可能是索引不合理，执行计划跑偏，sql本身问题，lock, 当时系统正在gc。等等。
数据库作为一个产品，为了适应更广泛的场景，通常情况下默认设置都比较保守。默认的设置能够在大多数情况下满足的的需求，但是在对性能用所要求的生产环境下需必要的调整，甚至会私人定制。
不同场景区别对待 场景主要分为TP、AP两种场景。
不同的使用场景优化的方向应该是不同的，侧重点也会不同。
TP 强调的短平快，注重TPS。相当于跑车追求速度，效率。
AP 强调的吞吐量，相当于大卡车。
针对不同车辆设计不同的道路才合理。
在跑车的赛道上开来一辆大卡车，彼此伤害。TP如果不幸就此挂掉，真的不能说是系统不够健壮。
补充： 慢Sql可视为TP系统性能上的bug , 高速运行的列车，飞机任何碰撞都是致命的。
监测很重要 你是我的眼 👀
作用
  早期发现问题
  评估调整后效果
  工具
  监控系统
  日志系统
  功能模块概览  vacuum  避免在高峰时发生，又能及时处理，避免表膨胀。调整触发条件及手动触发
 checkpoint  频率，IO平滑度
 sql  满足功能同时是否考虑性能
 wal  输出量，FPI
 hotupdate  热更新比例 调整fillfactor
 缓存 buffer  命中率 是否产生tempfile</description>
    </item>
    
    <item>
      <title>unlogged table</title>
      <link>https://zhangeamon.top/postgres/unlogged_table/</link>
      <pubDate>Tue, 12 Jan 2021 10:21:36 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/unlogged_table/</guid>
      <description>介绍 在写数据的时候不记录wal的表。
在意外发生时表中的数据被trunce 。如断电、 主进程kill 、scrash 等。
正常关闭重启数据库时数据不会丢失。
优点： 提高写入效率
不足： 数据安全性不能得到保障。 由于没有wal 流复制从库不能同步
应用场景：
数据可丢失，如频繁更新，只保留最后状态信息的表。
导入表数据，后将表改为正常表。
使用 -- 创建unlogged table,与创建普通的表类似。加个unlogged 关键字 postgres=# create unlogged table ult (id int,name text); CREATE TABLE postgres=# \d+ ult 不记录日志的表 &amp;quot;public.ult&amp;quot; 栏位 | 类型 | 校对规则 | 可空的 | 预设 | 存储 | 统计目标 | 描述 ------+---------+----------+--------+------+----------+----------+------ id | integer | | | | plain | | name | text | | | | extended | | -- 将普通表与unlogged table 之间转换 postgres=# alter table ult set logged ; ALTER TABLE postgres=# \d+ ult 数据表 &amp;quot;public.</description>
    </item>
    
    <item>
      <title>误操作闪回</title>
      <link>https://zhangeamon.top/postgres/reback/</link>
      <pubDate>Mon, 11 Jan 2021 17:19:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/reback/</guid>
      <description>原理 利用mvcc原理，数据在删除或更新时只是标记为删除。当没有发生过gc时历史数据仍然存在。只是对当前事务不可见。
通过修改当前事务号为误操作前的事务号就可以看到历史数据。
例如 T1 （添加数据） T2 - T8（其他操作） T9（删除了T1加入的数据）T10&amp;hellip; (其他操作)。 自需要将当前事务号修改为T1之后T9之前的任何时刻都可以看到T1 加入的数据。
前提：误操作表在误操作后没有发生过gc
select last_vacuum , last_autovacuum from pg_stat_all_tables where = ?; 修改方法：利用pg_resetwal工具重置当前事务号
注意： 尽快将找到的数据导出，随着当前数据库事务号增加，数据将再次不可见，T10 也会同样不可见。
示例 通过pg_xlogdump找到误删的事务号（xid），停止数据库，然后重置xlog，启动数据库，数据就是重置的xid位置可见
模拟事故现场
-- 创建测试表 postgres=# create table reback_t (i int); postgres=# select txid_current(); txid_current -------------- 26913040 (1 行记录) -- 模拟业务插入数据 postgres=# insert into reback_t values (1); INSERT 0 1 postgres=# insert into reback_t values (2); INSERT 0 1 postgres=# insert into reback_t values (3); INSERT 0 1 postgres=# insert into reback_t values (4); INSERT 0 1 postgres=# select txid_current(); txid_current -------------- 26913045 (1 行记录) postgres=# insert into reback_t values (5); INSERT 0 1 postgres=# insert into reback_t values (6); INSERT 0 1 postgres=# insert into reback_t values (7); INSERT 0 1 postgres=# insert into reback_t values (8); INSERT 0 1 postgres=# insert into reback_t values (9); INSERT 0 1 postgres=# insert into reback_t values (10); INSERT 0 1 postgres=# select txid_current(); txid_current -------------- 26913052 (1 行记录) -- 误删除数据,事故点 postgres=# delete from reback_t where i &amp;lt; 4; DELETE 3 -- 在线业务继续 postgres=# insert into reback_t values (11); INSERT 0 1 postgres=# insert into reback_t values (12); INSERT 0 1 postgres=# insert into reback_t values (13); INSERT 0 1 postgres=# select * from reback_t ; i ---- 4 5 6 7 8 9 10 11 12 13 (10 行记录) postgres=# \q 停服闪退 [root@pg-d data]# systemctl stop postgresql-10 回退到指定事务号 [root@pg-d data]# su postgres -c &amp;quot;/usr/pgsql-10/bin/pg_resetwal -x 26913047 -D /var/lib/pgsql/10/data/&amp;quot; Write-ahead log reset 建议使用 --single 维护模式启动数据库 查看回退效果, 1,2 又可见 postgres=# select * from reback_t ; i --- 1 2 3 4 5 (5 行记录) 事务号 +1 postgres=# select txid_current(); txid_current -------------- 26913047 (1 行记录) postgres=# select * from reback_t ; i --- 1 2 3 4 5 6 (6 行记录) -- 其他操作 , 事务继续向前。。。 postgres=# insert into reback_t values (21); INSERT 0 1 postgres=# select * from reback_t ; i ---- 1 2 3 4 5 6 7 8 21 (9 行记录) -- 当事务号增长到事故点26913053时，事故再次重现 postgres=# select * from reback_t ; i ---- 3 4 5 6 7 8 21 (7 行记录) -- 事务真相 postgres=# select xmin,xmax,* from reback_t ; xmin | xmax | i ----------+------+---- 26913044 | 0 | 4 26913046 | 0 | 5 26913047 | 0 | 6 26913048 | 0 | 7 26913049 | 0 | 8 26913050 | 0 | 9 26913051 | 0 | 10 26913054 | 0 | 11 26913055 | 0 | 12 26913049 | 0 | 21 思考 trunce 后是否能够闪回</description>
    </item>
    
    <item>
      <title>高级SQL</title>
      <link>https://zhangeamon.top/postgres/high_level_sql/</link>
      <pubDate>Mon, 11 Jan 2021 17:05:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/high_level_sql/</guid>
      <description>分组集 排序集 假象集 窗口函数 递归  递归应用 递归加速count(distint) 查询。 使用场景，数据分布：大数据集但其中的类型却很少
-- 创建表 test1=# create table recurive_t(user_id int,free float,info text); CREATE TABLE -- 加入数据 test1=# insert into recurive_t select 1 ,generate_series(0,1000000),&#39;user 1 pay !!!&#39;; test1=# insert into recurive_t select 2 ,generate_series(0,2000000),&#39;user 2 pay !!!&#39;; test1=# insert into recurive_t select 3 ,generate_series(0,3000000),&#39;user 3 pay !!!&#39;; test1=# insert into recurive_t select 4 ,generate_series(0,4000000),&#39;user 4 pay !!!&#39;; test1=# insert into recurive_t select 5 ,generate_series(0,4000000),&#39;user 5 pay !</description>
    </item>
    
    <item>
      <title>数据库优化思考 - 结构设计</title>
      <link>https://zhangeamon.top/postgres/thinking_in_db_fd/</link>
      <pubDate>Mon, 11 Jan 2021 10:10:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/thinking_in_db_fd/</guid>
      <description>DB 与 APP 的不同 有无状态 无状态应用，每个实例提供的服务都是等价、对等的。APP 应用为无状态应用，DB应用为有状态应用。
数据库正是因为有状态，所以维护起来更有挑战。
APP 在面对大量高并发请求时可以无所顾及的增加实例，加机器进行扩容。处理能里也会将得到线性提升。简单粗暴又有效。
DB 面对同样的压力挑战时正因为其有状态，扩容起来就没有那么从容。因为当前的请求携带的信息需要与已有的数据进行融合累积。
状态不仅要考虑当前状态，还需要考虑历史状态。因为数据是累积的。
 当前状态 历史状态  如交易订单，当前订单信息，累积账单信息
同样面临的挑战还有比如高可用（当前状态），迁移（历史状态）。在线扩容、不停机迁移，升级,维护（当前状态+历史状态）。
比如电脑新装系统、新购置手机，有一个顾虑就是里面的数据需要拷贝到新系统里。搬家头疼的也是东西太多了。
综上所述，由于DB应用具有当前状态、历史状态属性，DB在高压下面临的真正挑战，
可归结为吞吐量（QPS）挑战，存储量（SIZE）挑战。
认清DB真正面对的挑战 QPS（QPS+TPS） + SIZE (历史累积 + 增长速度)。要缓解数据库压力，下面将从qps、size两个方面来进一步思考解决之道。
进一步思考，QPS 与 SIZE 之间亦相互影响。
tps 加速SIZE 增长
SIZE 增大QPS下降
取舍策略： 时间换空间，空间换时间。
多Master方案 多master，即可多写。能够解决以上两个问题吗？
tps 表面来看将写的压力分散到多个实例来处理，分担了总体压力。但是要保持多个实例数据的一致性。强一致性下多个实例都要处理完成才返回结果。
tps的角度来分析，单个实例的处理量并没有减少，反而可能产生相互等待。即使是最终一致性，tps总量也没有没减少。
可以降低的是单机所承担的qps。
可能多个实例之间由协议来完成实例间的数据同步，但是对tps性能来说影响也是负面的。对size来说也没带来好处。
多master带来的优势更多的是高可用，或类似CDN多机房本地优先处理。
总结： 多master方案 在tps和size 两个方面都不能做到缓解服务压力的作用
伪命题。随着机器增加复杂难度指数上升。mysql 最新8.0 多master方案官方不建议生产环境中使用。
现有方案： bucardo 同步通过触发器来记录变化 、 自身逻辑复制。
注意问题，多写造成多实例之间的写循环。
读写分离 读写分离的核心是将读请求与写请求分开来处理，请求=qps+tps。master只处理写请求，由slave来处理读请求。
通常在现实的TP生产环境中，读请求往往是写请求的数倍或数十倍。这样通过一主多从的方式可以非常有效的将请求分散到多个实例，增加从库也比较容易实现。
将数据库的读请求分离开来对写的影响也会产生积极的作用，因为读写都会占有IO资源，CPU资源。将读请求分到其他实例，资源完全交给写处理，写的性能进而会得到极大的提升。
总结： 读写分离解决的是并发请求量qps，对SIZE方面的问题没有得到解决
现有方案： 数据库流复制，应用层通常框架自带读写路由功能。 如jdbc不仅有路由功能，还可以自动识别主从</description>
    </item>
    
    <item>
      <title>auto vacuum 触发机制</title>
      <link>https://zhangeamon.top/postgres/auto_vacuum_trigger/</link>
      <pubDate>Fri, 08 Jan 2021 09:20:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/auto_vacuum_trigger/</guid>
      <description>数据库自动垃圾回收触发条件分析 在postgres 中 垃圾回收的重要意义及在执行垃圾回收时具体都做了些什么很多地方都有介绍。
但是何时触发垃圾回收，即垃圾回收的触发条件是什么。
官网的介绍一般是有如下几个参数决定
#autovacuum = on # Enable autovacuum subprocess? &#39;on&#39; #autovacuum_vacuum_threshold = 50 # min number of row updates before vacuum #autovacuum_analyze_threshold = 50 # min number of row updates before analyze #autovacuum_vacuum_scale_factor = 0.2 # fraction of table size before vacuum #autovacuum_analyze_scale_factor = 0.1 # fraction of table size before analyze #autovacuum_freeze_max_age = 200000000 # maximum XID age before forced vacuum 大概意思 当表中的数据更新为总数量的20% 是触发垃圾回收，但是当表中总数量小于50的时候20%来的太容易了，
这样就会过于频繁的满足触发条件。于是50就相当于一个最低门槛。表中总数量在50以内的就暂时不触发垃圾回收了。</description>
    </item>
    
    <item>
      <title>分区表</title>
      <link>https://zhangeamon.top/postgres/partition/</link>
      <pubDate>Thu, 31 Dec 2020 10:17:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/partition/</guid>
      <description>分区表 数据库分区是一种将数据做物理分片的数据库设计技术，虽然分区技术可以有多种实现方法，
但其主要目的是为了在特定的SQL操作中减少数据读取的总量以缩减响应时间。
分区方式   水平分区
订单按时间维度
  垂直分区
范式规范 ： 订单数据 （客户表，商品表，订单表）
  优点  性能 ，范围或点查询。 管理 归档，删除 统计信息，vacuum  注意事项  默认分区 索引操作，对字表无效 分区键更新 主键，唯一键约束。 全局还是子表有效。(唯一键+分区键)  普通表转换为分区表  pg 版本 &amp;lt; 12 利用pathman 可在线平滑转换 pg 版本 &amp;gt;=12 原始方式 思路：1 新建一张结构完全相同的表，2 将原表作为新表子表 ，3 修改对换表名 （过程加锁）  更多 PPT 下载</description>
    </item>
    
    <item>
      <title>跨库操作</title>
      <link>https://zhangeamon.top/postgres/pg_fdw/</link>
      <pubDate>Thu, 24 Dec 2020 09:11:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_fdw/</guid>
      <description>dblink
https://www.cnblogs.com/lottu/p/13331387.html
fdw
https://www.cnblogs.com/lottu/p/13345187.html
注意事项
  查询条件下推，新版本功能更全
  ddl 操作 , fdw 如果用于历史归档
  </description>
    </item>
    
    <item>
      <title>找回supper user 权限</title>
      <link>https://zhangeamon.top/postgres/reback_supper_user/</link>
      <pubDate>Tue, 22 Dec 2020 17:12:53 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/reback_supper_user/</guid>
      <description>背景 意外删除postgres supper user 权限
找回方法 关闭数据库 用单用户模式重新启动
/usr/lib/postgresql/xxxx/bin/postgres --single -D $PGDATA 重新设置supper user 权限
alter user postgres with superuser; </description>
    </item>
    
    <item>
      <title>数据库监控指标</title>
      <link>https://zhangeamon.top/postgres/monitor_explain/</link>
      <pubDate>Fri, 20 Nov 2020 14:46:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/monitor_explain/</guid>
      <description>实体机  硬盘空间 cup利用率 内存利用率 IO 网络带宽 tcp连接情况 温度  数据库年龄  -- 数据库database 年龄 select datname,age(datfrozenxid),pg_size_pretty(pg_database_size(oid)) from pg_database order by age(datfrozenxid) desc limit 10 ; -- 表年龄 select relname,age(relfrozenxid), pg_size_pretty(pg_table_size(oid)) from pg_class where relkind in (&#39;t&#39;,&#39;r&#39;) order by age(relfrozenxid) desc limit 10; 说明： 当age到达2亿（默认）时触发自动回卷，期间会大量占用系统资源。提前做好监控避免在业务高峰时发生。可在库级别操作，也可在表基本操作。 VACUUM ANALYZE VERBOSE ; 垃圾回收 -- 表空间膨胀率, 死元组 select relname,size,ratio from monitor.pg_table_bloat; 视图定义 -见
-- 垃圾回收开始时间结束时间 进程数 WAL --- 过去5分钟内生成wal个数 select count(1) from pg_catalog.pg_ls_waldir() where modification &amp;gt; CURRENT_TIMESTAMP - &#39;5 minutes&#39; :: INTERVAL ; --- wal写入速率 SELECT CASE WHEN pg_is_in_recovery() THEN pg_last_wal_replay_lsn() ELSE pg_current_wal_lsn() END - &#39;0/0&#39; as wal_lsn; CheckPoint -- checkpoint 发生频率 连接数  长事物 pg_stat_activity &amp;gt; 2小时 2pc 未提交事物 pg_prepared_xact() &amp;gt; 5 分钟 复制槽  </description>
    </item>
    
    <item>
      <title>kylin系统postgresql编译安装</title>
      <link>https://zhangeamon.top/postgres/compile_kylin/</link>
      <pubDate>Mon, 16 Nov 2020 15:26:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/compile_kylin/</guid>
      <description>背景 麒麟系统默认自带postgresql10.5
安装过程与centos基本相同 ,
注意事项
1 安装postgresql-dev
2 编译 postgis 时./configure &amp;ndash;with-pgconfig=/usr/bin/pg_config
但是如果想安装其他版本的postgres 需一番周折
首先第一个问题麒麟系统对openssl过进行改造。在编译postgres支持ssl时不能通过。
其次安装postgres其他拓展也需要解决好各个安装包之间的依赖关系。编译的过程也比较漫长。
银河麒麟V10编译安装postgresql12.5 安装openssl 麒麟v10 版操作系统openssl 被指定义安装在内核中。在安装postgresql时支持openssl编译不能通过。
解决思路，独立安装openssl,postgres对ssl 的依赖指向独立安装的openssl
查看原有版本 openssl version 下载并安装对应版本的openssl wget https://www.openssl.org/source/openssl-1.1.1d.tar.gz tar -zxf openssl-1.1.1d.tar.gz cd openssl-1.1.1d/ ./config --prefix=/usr/local/openssl no-zlib 依赖包安装 yum install openldap-devel yum install systemd-devel -y 安装postgres tar -zxf postgresql-12.5.tar.gz 指定openssl 路径 ./configure --with-openssl --with-includes=/usr/local/openssl/include/openssl --with-libraries=/usr/local/openssl/lib/ --with-systemd ./configure &#39;--enable-rpath&#39; &#39;--prefix=/usr/pgsql-12&#39; &#39;--includedir=/usr/pgsql-12/include&#39; &#39;--libdir=/usr/pgsql-12/lib&#39; &#39;--mandir=/usr/pgsql-12/share/man&#39; &#39;--datadir=/usr/pgsql-12/share&#39; &#39;--with-icu&#39; &#39;--with-llvm&#39; &#39;--with-perl&#39; &#39;--with-python&#39; &#39;--with-tcl&#39; &#39;--with-tclconfig=/usr/lib64&#39; &#39;--with-openssl&#39; &#39;--with-pam&#39; &#39;--with-gssapi&#39; &#39;--with-includes=/usr/include:/usr/local/openssl/include/openssl&#39; &#39;--with-libraries=/usr/lib64:/usr/local/openssl/lib&#39; &#39;--enable-nls&#39; &#39;--enable-dtrace&#39; &#39;--with-uuid=e2fs&#39; &#39;--with-libxml&#39; &#39;--with-libxslt&#39; &#39;--with-ldap&#39; &#39;--with-selinux&#39; &#39;--with-systemd&#39; &#39;--with-system-tzdata=/usr/share/zoneinfo&#39; &#39;--sysconfdir=/etc/sysconfig/pgsql&#39; &#39;--docdir=/usr/pgsql-12/doc&#39; &#39;--htmldir=/usr/pgsql-12/doc/html&#39; &#39;CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic&#39; &#39;LDFLAGS=-Wl,--as-needed&#39; &#39;LLVM_CONFIG=/usr/lib64/llvm5.</description>
    </item>
    
    <item>
      <title>创建只读用户</title>
      <link>https://zhangeamon.top/postgres/readonly/</link>
      <pubDate>Tue, 08 Sep 2020 09:28:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/readonly/</guid>
      <description>1.创建一个用户名为readonly密码为ropass的用户 CREATE USER readonly WITH ENCRYPTED PASSWORD &#39;ropass&#39;; 2.用户只读事务 alter user readonly set default_transaction_read_only=on; 3.把所有库的语言的USAGE权限给到readonly GRANT USAGE ON SCHEMA public to readonly; 4.授予select权限(这句要进入具体数据库操作在哪个db环境执行就授予那个db的权) grant select on all tables in schema public to readonly; </description>
    </item>
    
    <item>
      <title>数据库 OOM 预防</title>
      <link>https://zhangeamon.top/postgres/oom/</link>
      <pubDate>Tue, 30 Jun 2020 09:26:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/oom/</guid>
      <description>降低主进程被OOM kill 掉的风险 1. restart_after_crash 默认崩溃重启
postgres=# show restart_after_crash; restart_after_crash --------------------- on (1 row) 2. vm.overcommit # vi /etc/sysctl.conf # 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程 # 1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何 # 2 表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 2 vm.overcommit_ratio = 90 # overcommit_memory= 2 时生效 vm.swappiness = 1 # 交换分区 # sysctl -p 3. oom_score_adj oom_score_adj 的取值范围为 -1000 到 1000，值越大，被os干掉的风险越大。
启动前设置
#vi /usr/lib/systemd/system/postgresql-10.service # Disable OOM kill on the postmaster OOMScoreAdjust=-1000 Environment=PG_OOM_ADJUST_FILE=/proc/self/oom_score_adj Environment=PG_OOM_ADJUST_VALUE=0 启动后设置
Pid=`head -n 1 /PATH/TO/postmaster.</description>
    </item>
    
    <item>
      <title>数据库 ssl认证</title>
      <link>https://zhangeamon.top/postgres/ssl/</link>
      <pubDate>Wed, 03 Jun 2020 15:06:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/ssl/</guid>
      <description>SSL双向认证和SSL单向认证的区别 双向认证 SSL 协议要求服务器和用户双方都有证书。单向认证 SSL 协议不需要客户拥有CA证书，服务器端不会验证客户证书，以及在协商对称密码方案，对称通话密钥时，服务器发送给客户的是没有加过密的(这并不影响 SSL 过程的安全性)密码方案。
这样，双方具体的通讯内容，都是加过密的数据，如果有第三方攻击，获得的只是加密的数据，第三方要获得有用的信息，就需要对加密的数据进行解密，这时候的安全就依赖于密码方案的安全。
而幸运的是，目前所用的密码方案，只要通讯密钥长度足够的长，就足够的安全。这也是我们强调要求使用128位加密通讯的原因。
一般Web应用都是采用SSL单向认证的，原因很简单，用户数目广泛，且无需在通讯层对用户身份进行验证，一般都在应用逻辑层来保证用户的合法登入。但如果是企业应用对接，情况就不一样，可能会要求对客户端(相对而言)做身份验证。这时就需要做SSL双向认证。
由于单向认证和双向认证的区别仅在于创建连接阶段，数据的传输均为加密的，因此客户端与PG服务端的连接采取SSL单向认证即可，即仅在PG Server端配置SSL证书。
生成自签名证书  server.key – 私钥 server.crt – 服务器证书 root.crt – 受信任的根证书  创建私钥 ， 需要密码，随意输入 openssl genrsa -des3 -out server.key 1024 删除密码 openssl rsa -in server.key -out server.key 修改权限 chmod 400 server.key 创建基于server.key文件的服务器证书 有效期十年 openssl req -new -key server.key -days 3650 -out server.crt -x509 查看证书 openssl x509 -in server.crt -text -noout 为了得到自己签名的证书，把生成的服务器证书作为受信任的根证书，只需要复制并取一个合适的名字 cp server.crt root.crt 数据库配置 将以上生成的证书文件拷贝到数据库的data目录下</description>
    </item>
    
    <item>
      <title>工作中所使用的postgres</title>
      <link>https://zhangeamon.top/postgres/awsome-postgres/</link>
      <pubDate>Wed, 27 May 2020 11:34:24 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/awsome-postgres/</guid>
      <description>Postgres 实际应用概览
 MVCC 多版本控制  一个绕不开的话题， 主要是对抗表空间的膨胀。解决垃圾回收问题，主从库之间从库查询冲突问题。
目前方法每日低峰期定时 vaccum ，gocron自定定时任务 。 根据pgstattuple对磁盘空间利用率进行分析。决定是否vaccum full ,pg_repack
 流复制  主从复制，读写分离的基础。五种同步方式
 逻辑订阅  大版本升级，数据并归。迁移
 执行计划调优  调节成本因子比例，如不同的磁盘类型比例有所区别
 参数调优  主机 和 服务
 分区表  采用pg_pathman ,因为都是根据业务数据量来决定是否分区。pg_pathman 能够不停服的前提下自动分区数据。
 高可用  patroni
 分表  citus 注意亲和性 和表之间的join ddl 等限制。
 监控，日志  promethues 套件，自定义监控项 。 filebeat elasticsearch kibana 日志收集
 统计  结合数据库自带的统计信息及pg_stat_statements 插件生产报表
 压测  pg_bench ,自定义sql</description>
    </item>
    
    <item>
      <title>数据预加载</title>
      <link>https://zhangeamon.top/postgres/pg_prewarm/</link>
      <pubDate>Wed, 27 May 2020 10:26:10 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_prewarm/</guid>
      <description>https://blog.csdn.net/Hehuyi_In/article/details/102653909</description>
    </item>
    
    <item>
      <title>Bloom 索引</title>
      <link>https://zhangeamon.top/postgres/index-bloom/</link>
      <pubDate>Thu, 23 Apr 2020 15:37:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/index-bloom/</guid>
      <description>Bloom 索引 Bloom 过滤器代表的是一组值。它的作用是检测一个元素是否可能属于集合，它可以允许有一些false positive，但是不允许存在false negative。也就是说，尽管某个元素不在集合中，测试也可能返回true。然而，如果元素在集合中，就不可能返回false。 创建在一组列中的Bloom索引可以被用来加速在这些列的子集上用AND相连的等式的查询。
当表具有很多属性并且查询可能会测试其中任意组合时，这种类型的索引最有用。传统的 btree 索引比布鲁姆索引更快，但是需要很多 btree 索引来支持所有可能的查询，而对于布鲁姆索引来说只需要一个即可。
注意: bloom 索引只支持等值查询，而 btree 索引还能执行不等和范围搜索。 创建一个索引 CREATE INDEX bloomidx ON tbloom USING bloom (i1,i2,i3) WITH (length=80, col1=2, col2=2, col3=4); with 部分可省略
length 每个签名（索引项）的长度位数。默认是80位，最长是4096位。
col1 — col32 从每一个索引列产生的位数。每个参数的名字表示它所控制的索引列的编号。默认是2位，最大是4095位。没有实际使用的索引列的参数会被忽略。
使用例子 http://postgres.cn/docs/10/bloom.html</description>
    </item>
    
    <item>
      <title>方法和函数</title>
      <link>https://zhangeamon.top/postgres/functionsandoperators/</link>
      <pubDate>Mon, 13 Apr 2020 16:15:51 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/functionsandoperators/</guid>
      <description>条件表达式 https://www.postgresql.org/docs/10/functions-conditional.html
postgresql支持CASE,COALESCE,NULLIF,GREATEST,LEAST条件表达式，使用它们有时候可以简化许多功能实现。
CASE CASE类似其他语言中的if/else等，当符合不同条件时则进行不同的运算
tbl_001表
create table tbl_001(id int,name varchar(32),sex varchar(1)); insert into tbl_001 values(1,&#39;张三&#39;,&#39;m&#39;),(2,&#39;李四&#39;,&#39;m&#39;),(3,&#39;王五&#39;,&#39;f&#39;); 测试
简单应用 postgres=# select case when sex = &#39;m&#39; then &#39;男&#39; when sex = &#39;f&#39; then &#39;女&#39; else &#39;O&#39; end as sex from tbl_001 ; sex ----- 男 男 女 (3 rows) 统计男女人数 postgres=# select count(sex) as 男 from tbl_001 where sex = &#39;m&#39;; 男 ---- 2 (1 row) postgres=# select count(sex) as 女 from tbl_001 where sex = &#39;f&#39;; 女 ---- 1 (1 row) 使用case 一条搞定 select sum(case when sex = &#39;m&#39; then 1 else 0 end) as 男, sum(case when sex = &#39;f&#39; then 1 else 0 end) as 女 from tbl_001 ; 男 | 女 ----+---- 2 | 1 (1 row) COALESCE COALESCE(value [, .</description>
    </item>
    
    <item>
      <title>数据库日常管理</title>
      <link>https://zhangeamon.top/postgres/daily_management/</link>
      <pubDate>Tue, 07 Apr 2020 10:38:45 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/daily_management/</guid>
      <description>日常管理  可用性 监测项  可用性  主从 HA 全量备份 增量备份 恢复  监测项 磁盘空间  全库  select pg_size_pretty(sum(pg_database_size(oid))) from pg_database;  数据库  select datname, pg_size_pretty(pg_database_size(oid)) from pg_database order by pg_database_size(oid) desc limit 10;  表总   SELECT table_schema || &#39;.&#39; || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size(&#39;&amp;quot;&#39; || table_schema || &#39;&amp;quot;.&amp;quot;&#39; || table_name || &#39;&amp;quot;&#39;)) AS size FROM information_schema.tables where table_schema = &#39;public&#39; ORDER BY pg_total_relation_size(&#39;&amp;quot;&#39; || table_schema || &#39;&amp;quot;.</description>
    </item>
    
    <item>
      <title>锁等待</title>
      <link>https://zhangeamon.top/postgres/lock_wait/</link>
      <pubDate>Fri, 27 Mar 2020 16:27:02 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/lock_wait/</guid>
      <description>锁等待场景 一个事务尚未执行提交时持有锁，当另一个事务需要持有改行的锁时则需要等待。
Session 1
postgres=# \d+ wt Table &amp;quot;public.wt&amp;quot; Column | Type | Collation | Nullable | Default | Storage | Stats target | Description --------+---------+-----------+----------+---------+----------+--------------+------------- id | integer | | | | plain | | t | text | | | | extended | | postgres=# begin; BEGIN postgres=# update wt set t = &#39;aaaa&#39; where id = 1; UPDATE 1 postgres=# select pg_backend_pid(); pg_backend_pid ---------------- 20034 (1 row) Session 2</description>
    </item>
    
    <item>
      <title>数据库安装 Postgres12 Ubuntu18</title>
      <link>https://zhangeamon.top/postgres/install02/</link>
      <pubDate>Thu, 19 Mar 2020 15:22:09 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/install02/</guid>
      <description>软件源
echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main&amp;quot; &amp;gt;&amp;gt; /etc/apt/sources.list.d/pgdg.list wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - sudo apt-get update -y 安装
apt-get install postgresql-12 postgresql-client-12 postgresql-12-postgis-2.5 postgresql-contrib -y 初始化
/usr/pgsql-12/bin/postgresql-12-setup initdb 启动
systemctl start postgresql systemctl stop postgresql systemctl status postgresql systemctl enable postgresql 配置
cd /etc/postgresql/12/main/ vi postgres.conf vi pg_hba.conf </description>
    </item>
    
    <item>
      <title>数据库年龄</title>
      <link>https://zhangeamon.top/postgres/pgage/</link>
      <pubDate>Tue, 07 Jan 2020 09:47:18 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgage/</guid>
      <description>背景 数据库的事务标识符使用的是32位的,最大可表示42个亿。当前事务的数据在20亿个事务之后将变的不可见。为了解决这个问题（回卷），Postgres引入了一个冻结事务标识的概念。 并实现了名为freeze的冻结过程。
冻结过程 两种模式
  惰性模式
  迫切模式
  惰性模式回跳过页中所有的数据都位可见的数据库块（由数据库中的vm可见性映射）
迫切模式会扫描所有的页，检查表中的所有元组。并可能删除不必要的clog文件与页面。
改进的迫切模式，会跳过页面中所有的元组都已被冻结过的页面
首先介绍几个数据库值
 -- 当前事务号 select txid_current(); -- 记录事务号 select xmax,xmin ,* from table_name where xxxx; -- 表年龄， 表中最老行的事务号 select age(relfrozenxid) from pg_class where relname = table_name; -- database 年龄 select datname , age(datfrozenxid) from pg_database ; -- 数据配置 show vacuum_freeze_min_age ; -- 默认值5千万 show vacuum_freeze_table_age ; -- 默认值1.5亿 show autovacuum_freeze_max_age ; -- 默认值2亿 show autovacuum_naptime ; -- 默认值1 分钟 触发条件 当前年龄大于5千万时 惰性模式 当前库年龄大于1.</description>
    </item>
    
    <item>
      <title>postgres 12</title>
      <link>https://zhangeamon.top/postgres/postgres12/</link>
      <pubDate>Tue, 19 Nov 2019 08:43:36 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/postgres12/</guid>
      <description>安装&amp;amp;启动 #下载源 yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm #安装服务 yum install postgresql12 postgresql12-server postgresql12-contrib #初始化 /usr/pgsql-12/bin/postgresql-12-setup initdb #启动服务 systemctl enable postgresql-12 systemctl start postgresql-12 流复制 #从机 建立从库 pg_basebackup -h 10.1.30.13 -U postgres -F p -P -R -D /var/lib/pgsql/12/data/ --checkpoint=fast -l postgresback #从库升级为主库 sudo su postgres -c &amp;quot;/usr/pgsql-12/bin/pg_ctl promote -D /var/lib/pgsql/12/data/&amp;quot;  recovery.conf 配置文件不再支持，此文件中的参数合并到 postgresql.conf(postgresql.auto.conf) Recovery Target, 若 recovery.conf 存在，数据库无法启动 新增 recovery.signal 标识文件，表示数据库处于 recovery 模式 新增加 standby.signal 标识文件，表示数据库处于 standby 模式 trigger_file 参数更名为 promote_trigger_file standby_mode 参数不再支持  在postgres 12 版本中新增一个激活从库为主库的方式。pg_promote 函数，相比原有的两种方式，这种方法的优点在于不需要登陆到实体机上，可远程通过sql进行操作。 pg_promote() 函数有两个参数:</description>
    </item>
    
    <item>
      <title>数据库视图之 pg_stat_activity</title>
      <link>https://zhangeamon.top/postgres/t_pg_stat_activity/</link>
      <pubDate>Fri, 23 Aug 2019 13:47:12 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/t_pg_stat_activity/</guid>
      <description>介绍 当需要了解数据库当前运行状态或需要排查问题时，首先需要查看的就是pg_stat_activity。该视图中包含了你想知道的数据库连接信息，正在执行的有哪些sql，并处于何状态。
One row per server process, showing information related to the current activity of that process, such as state and current query.
每一行都表示一个系统进程，显示与当前会话的活动进程的一些信息，比如当前回话的状态和查询等。
字段解读    Column Type Description     datid oid OID of the database this backend is connected to   datname name Name of the database this backend is connected to   pid integer Process ID of this backend   usesysid oid OID of the user logged into this backend   usename name Name of the user logged into this backend   application_name text Name of the application that is connected to this backend   client_addr inet IP address of the client connected to this backend.</description>
    </item>
    
    <item>
      <title>tpch AP测试</title>
      <link>https://zhangeamon.top/postgres/tpch/</link>
      <pubDate>Wed, 05 Jun 2019 09:36:21 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/tpch/</guid>
      <description>背景介绍 24sql
TPC-H 基准测试 下载安装 tpch-tools安装包
修改makefile.suite 模版
CC=gcc DATABASE-TDAT MACHINE=LINUX WORKLOAD=TPCH 执行 make 进行编译
生成测试数据 生成20G测试数据
./dbgen -s 20 ls -lrth *.tbl 自动生成的测试数据每行的结尾多余一个 &amp;lsquo;|&amp;rsquo; 需要处理
for i in `ls *.tbl`; do sed &#39;s/|$//&#39; $i &amp;gt; ${i/tbl/csv}; echo $i; done; 创建表及索引 在下面的文件中分别是创建表和对应索引的sql
dss.ddl dss.ri
导入数据 copy customer from &#39;/opt/tpch-tools/dbgen/customer.csv&#39; with DELIMITER &#39;|&#39;; copy lineitem from &#39;/opt/tpch-tools/dbgen/lineitem.csv&#39; with DELIMITER &#39;|&#39;; copy nation from &#39;/opt/tpch-tools/dbgen/nation.csv&#39; with DELIMITER &#39;|&#39;; copy orders from &#39;/opt/tpch-tools/dbgen/orders.csv&#39; with DELIMITER &#39;|&#39;; copy partsupp from &#39;/opt/tpch-tools/dbgen/partsupp.</description>
    </item>
    
    <item>
      <title>表空间膨胀</title>
      <link>https://zhangeamon.top/postgres/pgstattuple/</link>
      <pubDate>Wed, 22 May 2019 17:26:45 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgstattuple/</guid>
      <description>背景介绍 由于mvcc机制，数据被删除后只是被标记为删除，实际空间没有被释放，这是表空间膨胀的根本原因。
目前用于解决表空间膨胀方式有如下方式
1 删除dead tuple
 vacuum ,tuple被清理。数据库可以自动执行autovacuum vacuum full ,tuple被清理并且空间连续紧凑。弊端，在执行过程中会锁表。应用不可用 为了避免锁表的影响，提供的pg_squeeze拓展,使用逻辑复制。pg_repack拓展，使用了触发器，影响业务的性能。  2 fillfactor
3 vacuum_defer_cleanup_age &amp;gt; 0, 是以事务为单位。配合pg_resetwal 可以做到flashback
代价1，主库膨胀，因为垃圾版本要延迟若干个事务后才能被回收。 代价2，重复扫描垃圾版本，重复耗费垃圾回收进程的CPU资源。（n_dead_tup会一直处于超过垃圾回收阈值的状态，从而autovacuum 不断唤醒worker进行回收动作）。 当主库的 autovacuum_naptime=很小的值，同时autovacuum_vacuum_scale_factor=很小的值时，尤为明显。 代价3，如果期间发生大量垃圾，垃圾版本可能会在事务到达并解禁后，爆炸性的被回收，产生大量的WAL日志，从而造成WAL的写IO尖刺。 4 reindex 从新建立索引，不要忽略表膨胀中索引的影响，通常来说索引所占的空间和维护成本要高于数据表，在pg version 12版本中预计reindex时不需要锁表。
处理完毕后需要重新生成统计信息  ANALYZE; 在执行以上操作时建议设置
set maintenance_work_mem = &#39;10GB&#39;; 监控表空间膨胀 pgstattuple提供了pgstatetuple()和pgstatindex()两个统计表和索引的方法，较PostgreSQL系统表pg_class的表统计信息，pgstatetuple()还统计了表中的dead tuples。
https://www.postgresql.org/docs/current/pgstattuple.html
创建拓展
create extension pgstattuple ; 表 test=&amp;gt; SELECT * FROM pgstattuple(&#39;tablename&#39;); -[ RECORD 1 ]------+------- table_len | 458752 tuple_count | 1470 tuple_len | 438896 tuple_percent | 95.</description>
    </item>
    
    <item>
      <title>checkpoint 检查点</title>
      <link>https://zhangeamon.top/postgres/checkpoint/</link>
      <pubDate>Wed, 13 Mar 2019 15:57:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/checkpoint/</guid>
      <description>作用 一般checkpoint会将某个时间点之前的脏数据全部刷新到磁盘，以实现数据的一致性与完整性。其主要目的是为了缩短崩溃恢复时间。
触发  超级用户（其他用户不可）执行CHECKPOINT命令 数据库shutdown 数据库recovery完成 XLOG日志量达到了触发checkpoint阈值 周期性地进行checkpoint 需要刷新所有脏页  相关参数  checkpoint_segments WAL log的最大数量，系统默认值是3。超过该数量的WAL日志，会自动触发checkpoint。 新版(9.6)使用min_wal_size, max_wal_size 来动态控制wal日志 checkpoint_timeout 系统自动执行checkpoint之间的最大时间间隔。系统默认值是5分钟。 checkpoint_completion_target 该参数表示checkpoint的完成时间占两次checkpoint时间间隔的比例，系统默认值是0.5,也就是说每个checkpoint需要在checkpoints间隔时间的50%内完成。 checkpoint_warning 系统默认值是30秒，如果checkpoints的实际发生间隔小于该参数，将会在server log中写入一条相关信息。可以通过设置为0禁用。  应用 预防wal写放大
如何判断是否需要优化WAL？ wal 文件名组成
 timeline 8位 逻辑号 8位 偏移量  与wal_lsn对应关系查看
postgres=# select pg_current_wal_lsn(); pg_current_wal_lsn -------------------- 5A/AD000000 (1 行记录) postgres=# select pg_walfile_name(pg_current_wal_lsn()); pg_walfile_name -------------------------- 000000020000005A000000AC 关于如何判断是否需要优化WAL，可以通过分析WAL，然后检查下面的条件，做一个粗略的判断：
 FPI比例高于70% HOT_UPDATE比例低于70%  FPI及HOT_UPDATE查看方法
/usr/pgsql-10/bin/pg_waldump --stats=record -p /var/lib/pgsql/10/data/pg_wal/ -t 2 -s 15/56098120 -e 15/56098200 -z 统计信息 -p wal path -t timeline -s sart lsn -e end lsn 获取wal lsn psql -c &amp;quot;checkpoint;select pg_current_wal_lsn&amp;quot; /usr/pgsql-10/bin/pg_waldump --stats=record -s 1095/90000000 -e 1098/70000000 -t 3 Type N (%) Record size (%) FPI size (%) Combined size (%) ---- - --- ----------- --- -------- --- ------------- --- XLOG/CHECKPOINT_ONLINE 107 ( 0.</description>
    </item>
    
    <item>
      <title>咨询锁 adlock</title>
      <link>https://zhangeamon.top/postgres/adlock/</link>
      <pubDate>Thu, 07 Mar 2019 16:20:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/adlock/</guid>
      <description>https://github.com/digoal/blog/blob/master/201805/20180524_02.md
行级锁 select .. for update select .. for update skip locked select .. for share </description>
    </item>
    
    <item>
      <title>pgpoolii 读写分离</title>
      <link>https://zhangeamon.top/postgres/pgpool2/</link>
      <pubDate>Wed, 30 Jan 2019 15:43:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgpool2/</guid>
      <description>https://www.pgpool.net/docs/pgpool-II-3.5.4/doc/tutorial-zh_cn.html#dist-def
https://www.xiaomastack.com/2019/08/16/postgresql集群/</description>
    </item>
    
    <item>
      <title>Logical Replication 逻辑复制</title>
      <link>https://zhangeamon.top/postgres/logical-replication/</link>
      <pubDate>Wed, 30 Jan 2019 15:42:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/logical-replication/</guid>
      <description>逻辑复制 Postgres 10 版本开始， 在内核层面支持基于REDO流的逻辑复制。
控制粒度为表级别
物理复制相同都是基于wal
可指定多个上游数据源
下游数据可读可写
可用于数据汇总，无停服数据迁移,大版本升级等。
基本概念 发布者（publication）， 上游数据 订阅者 (subscrition)， 下游数据 复制槽 (slot), 保存逻辑复制的信息 简单实践  将10中的一张表同步到12中  发布者服务器配置
postgresql.conf
wal_level = logical max_replication_slots = 10 # 每个slot 需要一个 max_wal_senders = 10 # 每个slot 需要一个 max_worker_processes = 128 pg_hba.conf
host replication postgres 10.1.0.0/16 md5 订阅者服务器配置
postgresql.conf
max_replication_slots = 10 # 每个slot 需要一个 max_logical_replication_workers = 10 # 每个slot 需要一个 max_worker_processes = 128 在发布端创建发布
create publication test01 for table test01 ; 在订阅端创建表结构</description>
    </item>
    
    <item>
      <title>cluster 聚族表</title>
      <link>https://zhangeamon.top/postgres/cluster/</link>
      <pubDate>Wed, 30 Jan 2019 15:19:41 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/cluster/</guid>
      <description>存储数据线性相关性 测试</description>
    </item>
    
    <item>
      <title>Archive wal归档</title>
      <link>https://zhangeamon.top/postgres/archive/</link>
      <pubDate>Wed, 30 Jan 2019 14:20:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/archive/</guid>
      <description>介绍 所谓WAL日志归档，其实就是把在线的WAL日志备份出来。
配置 vi postgresql.conf
wal_level=&#39;replica&#39; # - Archiving - archive_mode = on # enables archiving; off, on, or always # (change requires restart) archive_command = &#39;test ! -f /mnt/backup/%f &amp;amp;&amp;amp; cp %p /mnt/backup/%f&#39; # command to use to archive a logfile segment # placeholders: %p = path of file to archive # %f = file name only # e.g. &#39;test ! -f /mnt/server/archivedir/%f &amp;amp;&amp;amp; cp %p /mnt/server/archivedir/%f&#39; #archive_timeout = 0 # force a logfile segment switch after this # number of seconds; 0 disables 参数说明  wal_level archive 或更高级别 archive_mode on 开启归档模式，always 主从模式时，从库也开启归档模式。需要重启数据库 archive_command 归档时触发的命令或脚本， 不需要重新启动数据库。 systemctl reload postgresql-10 即可。 archive_timeout 可以理解为超过指定时间强制执行 select pg_switch_wal(); 场景， 数据库不是很活跃，数据库wal日志产生的过慢时。  归档触发条件说明： 1 手动执行 select pg_switch_wal();</description>
    </item>
    
    <item>
      <title>TimescaleDB 时序数据库</title>
      <link>https://zhangeamon.top/postgres/timescaledb/</link>
      <pubDate>Wed, 30 Jan 2019 10:20:51 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/timescaledb/</guid>
      <description>时序数据库 https://github.com/timescale/timescaledb
数据库配置 https://github.com/timescale/timescaledb-tune
copy并行导入数据 https://github.com/timescale/timescaledb-parallel-copy
常用方法 创建拓展
CREATE EXTENSION timescaledb; 创建一个普通的表
CREATE TABLE conditions ( time TIMESTAMPTZ NOT NULL, location TEXT NOT NULL, temperature DOUBLE PRECISION NULL, humidity DOUBLE PRECISION NULL ); 转换成时序数据库表
SELECT create_hypertable(&#39;conditions&#39;, &#39;time&#39;);  conditions 表名 time 时序字段  修改时序间隔 对新表生效
SELECT set_chunk_time_interval(&#39;conditions&#39;, INTERVAL &#39;24 hours&#39;); 查看分区
SELECT show_chunks(&#39;conditions&#39;); SELECT show_chunks(&#39;conditions&#39;, older_than =&amp;gt; INTERVAL &#39;3 months&#39;) SELECT show_chunks(&#39;conditions&#39;, older_than =&amp;gt; DATE &#39;2017-01-01&#39;); SELECT show_chunks(newer_than =&amp;gt; INTERVAL &#39;3 months&#39;); SELECT show_chunks(older_than =&amp;gt; INTERVAL &#39;3 months&#39;, newer_than =&amp;gt; INTERVAL &#39;4 months&#39;); 查看数据大小</description>
    </item>
    
    <item>
      <title>pg_rewind</title>
      <link>https://zhangeamon.top/postgres/pg_rewind/</link>
      <pubDate>Wed, 30 Jan 2019 10:16:17 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_rewind/</guid>
      <description>pg_rewind requires that the target server either has the wal_log_hints option enabled in postgresql.conf or data checksums enabled when the cluster was initialized with initdb. Neither of these are currently on by default. full_page_writes must also be set to on, but is enabled by default.
wal_log_hints
使用场景 在数据库主从结构中，从变成主易。但是由主变为从却需要一番周折。
如果是数据量少时重新使用pg_backup拉一份从即可，但是如果数据量大时，这个过程非常的耗时耗能。对线上业务也会有影响。 在实际的场景中主从之间的数据绝大部分时一致的，只有非常少量的近期产生的数据是不一致的。
有没有什么方式可以利用已有的数据，充分利用已有的数据呢？
pg_rewind登场 告别一下回到解放前。
基本原理 数据库每次的主从切换时，timeLine会增加1。 新老数据库在不同的时间线上运行。 使用pg_rewind 将数据拉回到时间线(timeLine)产生分裂的那个点上。重新选择时间线，重放新时间线上的wal日志，使两个数据库重新回到一个时间线，并且数据一致。
开始实验 背景:
主从数据库结构
10.1.88.71 主库
10.1.88.72 从库
目标
数据库主从兑换， 主降为从时使用pg_rewind校对时间线
实际操作 注意事项 :</description>
    </item>
    
    <item>
      <title>patroni auto ha</title>
      <link>https://zhangeamon.top/postgres/patroni/</link>
      <pubDate>Wed, 30 Jan 2019 10:14:55 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/patroni/</guid>
      <description>https://www.cnblogs.com/zhangeamon/p/9772118.html
https://www.linode.com/docs/databases/postgresql/create-a-highly-available-postgresql-cluster-using-patroni-and-haproxy
使用维护手册
ansible 管理
实践
其他HA 方案
repmgr PAF</description>
    </item>
    
    <item>
      <title>citus 数据库分库</title>
      <link>https://zhangeamon.top/postgres/pg_citus/</link>
      <pubDate>Tue, 29 Jan 2019 13:19:26 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_citus/</guid>
      <description>数据库分库调研  Greenplum 更适用于AP场景 PGXL PGXC 社区不活跃，沟通问题反馈时间长。没找到用户群体. 在此基础上发展的有亚信antdb，腾讯tbase。没有那个研发实力，算了吧。 citus 插件方式，无侵入。很多牛X的特性企业版才支持。主要强调多租户。 mycat mysql支派，阿里开源（抛弃）项目。主要是对sql语句的拦截，需要对业务理解透彻又要懂mycat，入侵太强。 bdr。 2ndquadrant 其他 由数据库触发器实现的直接略过  citus 开源社区版，如何分库及扩容，ha
主要思路是通过修改系统的分区表，手动进行分库。
ha 数据库自身的主从流复制。
实验目标  加入数据库几点进行扩容 删除数据库节点进行缩容 模拟任意节点宕机观察ha特性 压力测试判断增加主机节点与数据库整体处理能力之间的线形关系  </description>
    </item>
    
    <item>
      <title>pgwatch2 数据库指标监控查看</title>
      <link>https://zhangeamon.top/postgres/pgwatch2/</link>
      <pubDate>Tue, 29 Jan 2019 11:19:05 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgwatch2/</guid>
      <description>介绍 pgwatch2官方
架构 agent server
  agent 在被监控的pg上自定义方法，用于收集数据库信息。这些自定义的方法需要依赖需要数据库扩展如pg_stat_statements,plpythonu.
  server 负责存储收集过来的信息，可以存放在postgres或influxdb中. 并将收集的信息进行展示grafana.
  安装 客户端
依赖的拓展
yum install postgresql10-plpython.x86_64 -y 配置数据库,需要重启数据库生效，多个拓展之间用,号分割。
shared_preload_libraries = &#39;pg_stat_statements&#39; 连接到对应的数据库，创建拓展
CREATE EXTENSION pg_stat_statements; CREATE EXTENSION plpythonu; 创建自定义方法, 使用supper user 用户执行如下sql. 注意将下面的pql 信息中的用户信息替换成自己的数据库连接用户。
该目录下为所有的自定义方法 https://github.com/cybertec-postgresql/pgwatch2/tree/master/pgwatch2/sql/metric_fetching_helpers https://github.com/cybertec-postgresql/pgwatch2/blob/master/pgwatch2/sql/metric_fetching_helpers/stat_statements_wrapper.sql https://github.com/cybertec-postgresql/pgwatch2/blob/master/pgwatch2/sql/metric_fetching_helpers/cpu_load_plpythonu.sql 服务端
使用docker-compose 来管理服务，切都变得那么easy！
cat docker-compose.yaml version: &#39;2&#39; services: pgw2: restart: unless-stopped image: cybertec/pgwatch2 container_name: pw2 ports: - 3000:3000 - 8080:8080 volumes: - ./data/pg:/var/lib/postgresql - ./data/influx:/var/lib/influxdb - .</description>
    </item>
    
    <item>
      <title>锁机制</title>
      <link>https://zhangeamon.top/postgres/pg_lock/</link>
      <pubDate>Thu, 24 Jan 2019 11:26:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_lock/</guid>
      <description>https://blog.csdn.net/pg_hgdb/article/details/79403651
https://habr.com/en/company/postgrespro/blog/500714/
表锁 https://www.modb.pro/db/26462
查看被堵塞的任务 select * from pg_locks where not granted; locktype | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid | mode | granted | fastpath ----------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+-----+------+---------+---------- (0 行记录) 查看等待锁信息，是被谁堵塞了 select pg_blocking_pids(pid); pg_blocking_pids ------------------ {} 终止进程 select pg_cancel_backend(pid); # select select pg_terminate_backend(pid); # update insert delete 事务的隔离级别 Postgres 数据库共有三种数据隔离级别。
 Read Commit 读看提交 默认级别 在读开始的时候建立数据快照 Repeat Read 可重复读。在事务开始的时候建立数据快照 SSI Serializable 序列化 理解为只有一个用户使用的情况  使用举例</description>
    </item>
    
    <item>
      <title>时间点恢复</title>
      <link>https://zhangeamon.top/postgres/pitr/</link>
      <pubDate>Thu, 24 Jan 2019 11:08:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pitr/</guid>
      <description>PITR Point-in-time recovery
https://blog.csdn.net/a964921988/article/details/84957241
https://github.com/digoal/blog/blob/master/201608/20160823_03.md
https://github.com/digoal/blog/blob/master/201608/20160823_04.md
依赖条件  历史完整备份 不间断wal日志  以上都可有wal-g 备份系统提供支持
恢复到指定点  指定标签 具体时间点 具体事务  指定标签 recovery.conf recovery_target_action= &#39;pause&#39; # promote ,shutdown --- 打lable select pg_create_restore_point(&#39;my_daily_process_ended&#39;); --- 恢复到指定的lable recovery.conf recovery_target_name = &#39;my_daily_process_ended&#39; 具体时间 restore_command = &#39;cp /data/arch/%f %p&#39; # e.g. &#39;cp /mnt/server/archivedir/%f %p&#39; recovery_target_time = &#39;2020-12-23 09:37:17.010268&#39; recovery_target_inclusive = false recovery_target_timeline = &#39;latest&#39; 具体事务 restore_command = &#39;cp /data/arch/%f %p&#39; # e.g. &#39;cp /mnt/server/archivedir/%f %p&#39; recovery_target_xid = &#39;26897309&#39; recovery_target_inclusive = false recovery_target_timeline = &#39;latest wal内容解析具体位置，时间、事务 select pg_current_wal_lsn(); pg_current_wal_lsn -------------------- 59/15000090 (1 行记录) -- 当前wal位置 select pg_walfile_name(pg_current_wal_lsn()); pg_walfile_name -------------------------- 000000020000005900000015 (1 行记录) -- 00000002 TimeLine -- 00000059 逻辑位置 -- 00000015 偏移 -- 解析wal内容 /usr/pgsql-10/bin/pg_waldump .</description>
    </item>
    
    <item>
      <title>pg_pathman 分区表</title>
      <link>https://zhangeamon.top/postgres/pg_pathman/</link>
      <pubDate>Thu, 24 Jan 2019 10:56:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_pathman/</guid>
      <description>介绍 分区表的诉求在现实的生成中的意义不必多说，pg以前的实现方式多采用触发器，rules实现。数据量上来时性能明显不尽如意。
虽然pg10 ，11 版本在分区表的特性上不断发力。但是性能啥还是不够给力。
pg_pathman 分区表功能在目前的pg版本10.6 中优势还是非常明显的。
在期待pg自身分区表特性的同时，当前的pg10中还是使用pg_pathman来实现分区功能吧。
pathman与pg11 对比 优点: 支持HASH和RANGE分区，后续会支持LIST分区 支持自动和手动的分区维护
为分区表生成更有效的执行计划 通过引入两个自定义的执行计划节点RuntimeAppend &amp;amp; RuntimeMergeAppend，
实现运行时动态添加分区到执行计划中 为新插入数据自动创建分区(只对RANGE分区) 提供用户callbacks接口处理创建分区事件。
提供在线分区实施(在线重定义)，父表数据迁移到子表，拆分， 合并分区 不足:
不支持list分区;不支持二级分区;权限，索引，trigger等无法继承; 修改主键默认的seq需要重建分区。
PG11内置分区
优点:
支持hash，range，list分区 支持多字段组合分区，支持表达式分区 支持创建主键，外键，索引，分区表自动继承。 支持update分区键 支持分区表DETACH，ATTACH，支持二级分区 分区自动创建
Default partition Partition improvements
不足:
在主表添加权限，索引，trigger等无法继承 分区表不可以作为其他表的外键主表
分区表数量对插入数据的影响 https://www.jianshu.com/p/1cba77d18694
pathman 分区表 转换为原生分区表 https://github.com/digoal/blog/blob/master/201911/20191113_01.md
主要思路
1 创建一个与原来分区表一样的主表包括分区方式 。
2 将原来的主表上的分区都卸载为普通表，在重新按照原生分区表的方式挂载上去。
直接2 也行
拓展思考。 分区数据迁移使用pg_pathman，迁移后再转换到原生表。
注意事项 需要将pg_pathman放在后面注册，如pg_stat_statements。
shared_preload_libraries = &#39;pg_stat_statements,pg_pathman&#39; 创建拓展
CREATE SCHEMA pathman; GRANT USAGE ON SCHEMA pathman TO PUBLIC; CREATE EXTENSION pg_pathman WITH SCHEMA pathman; 参考 https://github.</description>
    </item>
    
    <item>
      <title>pgfincore</title>
      <link>https://zhangeamon.top/postgres/pgfincore/</link>
      <pubDate>Fri, 11 Jan 2019 13:17:12 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgfincore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>pgbench 压力测试</title>
      <link>https://zhangeamon.top/postgres/pgbench/</link>
      <pubDate>Wed, 09 Jan 2019 16:36:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgbench/</guid>
      <description>介绍 pgbench是一种在PostgreSQL上运行基准测试的简单程序。
官方文档
 默认测试 自定义测试  默认测试 pgbench中默认自带一套测试数据库和测试sql脚本。
初始化默认数据库 使用 -i 初始化数据库 #pgbench -U postgres -i -s 10 pgbenchdb NOTICE: table &amp;quot;pgbench_history&amp;quot; does not exist, skipping NOTICE: table &amp;quot;pgbench_tellers&amp;quot; does not exist, skipping NOTICE: table &amp;quot;pgbench_accounts&amp;quot; does not exist, skipping NOTICE: table &amp;quot;pgbench_branches&amp;quot; does not exist, skipping creating tables... 100000 of 1000000 tuples (10%) done (elapsed 0.14 s, remaining 1.23 s) 200000 of 1000000 tuples (20%) done (elapsed 0.27 s, remaining 1.</description>
    </item>
    
    <item>
      <title>pg_trgm的gist和gin索引加速字符匹配查询</title>
      <link>https://zhangeamon.top/postgres/pg_trgm/</link>
      <pubDate>Mon, 07 Jan 2019 09:37:23 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_trgm/</guid>
      <description>背景 对车牌号的记忆有时可能记住的是前几位，有时可能是后几位，不同的人记车牌号的习惯也不同。
通常是是容易记住首尾，中间不清楚。
那么如何在大量已有车牌数据中快速根据模糊的信息来进行查询呢？
模拟 数据库表中约有500w条车牌号记录，对表中的车牌号进行模糊查询。
即支持 car_id like &amp;lsquo;%XXXX%XXX%&amp;rsquo; 查询
---创建表 create table t_car (id int , car_id text); --插入500万车牌数据 insert into t_car select generate_series(1,5000000), (array[&#39;辽A&#39;,&#39;辽B&#39;,&#39;吉A&#39;,&#39;吉B&#39;,&#39;黑A&#39;,&#39;黑B&#39;])[floor(random()*6+1)] || substring(md5(random()::text),0,6); --查看数据 select * from t_car limit 5; id | car_id ----+---------- 1 | 吉A43bb9 2 | 吉B19b64 3 | 辽Afb04e 4 | 吉Bcf90c 5 | 辽Be67df (5 行记录) 索引  顺序扫描  explain analyze verbose select * from t_car where car_id = &#39;辽Be67df&#39;; QUERY PLAN ------------------------------------------------------------------------------------------------------------------------------ Gather (cost=1000.</description>
    </item>
    
    <item>
      <title>pgbouncer 连接池</title>
      <link>https://zhangeamon.top/postgres/pgbouncer/</link>
      <pubDate>Thu, 27 Dec 2018 09:00:49 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgbouncer/</guid>
      <description>背景介绍  Pgbouncer是一个针对PostgreSQL数据库的轻量级连接池 pgbouncer 的目标是降低因为新连接到 PostgreSQL 的连接而导致的性能损失  使用术语说明：
为了后面的描述更清晰，使用如下术语
 Client : 指访问者 Pgboucer: 指连接池 Postgres: 指数据库。 Connetions: 指彼此之间的连接  整体架构
原来: Client -&amp;gt; Postgres 现在: Client -&amp;gt; Pgbounce -&amp;gt; Postgres
优势 内存消耗低(默认为2k/连接)，因为Bouncer不需要每次都接受完整的数据包。
Postgres的连接是进程模型，pogbouncer 使用libevent进行socket 通信。
总结： 数据访问过程中建立连接很耗资源，pgboucer就是为了减少数据访问中的建立连接次数，重复利用已建立的连接进而缓解数据库压力。
三种连接池模型  session 会话级 ； 比较友好 transaction 事务级； 比较激进 statement 一个sql ； 客户端强制autocommit 模式  安装 查看当前系统中版本 yum list pgbouncer.x86_64 pgbouncer.x86_64 1.9.0-1.rhel7 升级到最新版 yum update pgbouncer.x86_64 安装 yum install pgbouncer.x86_64 -y 启动 systemctl start pgbouncer systemctl enable pgbouncer 简单配置 cat /etc/pgbouncer/pgbouncer.</description>
    </item>
    
    <item>
      <title>引起索引失效</title>
      <link>https://zhangeamon.top/postgres/index-invalid/</link>
      <pubDate>Thu, 20 Dec 2018 16:34:22 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/index-invalid/</guid>
      <description>简介 索引的作用，加速检索，排序，分组。
优点： 检索
缺点： 新增，更新时需要维护索引，占磁盘空间，创建时锁表。
维护： 根据统计表发生全表扫描次数，索引使用次数。合理添加删除索引。
索引失效的场景 如果where过滤条件设置不合理，即使索引存在，且where过滤条件中包含索引列，也会导致全表扫描，索引不起作用。什么条件下会导致索引失效呢？
1.任何计算、函数、类型转换
2.!=
3.NOT，相当于使用函数
4.模糊查询通配符在开头
5.索引字段在表中占比较高
6.多字段btree索引查询条件不包含第一列
7.多字段索引查询条件使用OR（有时也会走索引扫描，但查询效率不高）
8.表中数据量太少时
实例 测试表
创建表 postgres#=create table tbl_index(a bigint,b timestamp without time zone ,c varchar(12)); 插入1kw数据，打开计时器 对比创建索引对数据插入的影响。 postgres=# \timing Timing is on. postgres=# insert into tbl_index select generate_series(1,10000000),clock_timestamp()::timestamp without time zone,&#39;zhang&#39;; INSERT 0 10000000 Time: 25004.214 ms (00:25.004) postgres=# create index tbl_index_a ON tbl_index using btree (a); CREATE INDEX Time: 4119.733 ms (00:04.120) postgres=# create index tbl_index_b ON tbl_index using btree (b); CREATE INDEX Time: 6229.</description>
    </item>
    
    <item>
      <title>权限管理</title>
      <link>https://zhangeamon.top/postgres/role-manager/</link>
      <pubDate>Thu, 20 Dec 2018 09:54:28 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/role-manager/</guid>
      <description>创建用户 # user 与 role 区别 ， user 具有login权限 postgres=# create user tester with password &#39;123456&#39;; CREATE ROLE 创建数据库,并关联所有者 postgres=# create database test owner tester ; CREATE DATABASE 变更数据库用户所有者 postgres=# alter database test owner to tester; ALTER DATABASE 修改用户&amp;amp;数据库 #用户连接数 postgres=# alter user tester connection limit 100; ALTER ROLE #数据库连接数 postgres=# alter database test connection limit 100; ALTER DATABASE #用户其他属性修改 postgres=# alter user tester BYPASSRLS CREATEDB ENCRYPTED PASSWORD LOGIN NOCREATEDB NOINHERIT NOREPLICATION PASSWORD REPLICATION SET VALID UNTIL CONNECTION LIMIT CREATEROLE INHERIT NOBYPASSRLS NOCREATEROLE NOLOGIN NOSUPERUSER RENAME TO RESET SUPERUSER WITH #数据库其他属性修改 postgres=# alter database test ALLOW_CONNECTIONS CONNECTION LIMIT IS_TEMPLATE OWNER TO RENAME TO RESET SET sql批量修改table/view的owner DO $$DECLARE r record; BEGIN FOR r IN SELECT tablename/viewname FROM pg_tables/pg_views WHERE schemaname = &#39;public&#39; LOOP EXECUTE &#39;alter table &#39;|| r.</description>
    </item>
    
    <item>
      <title>DBA 日常</title>
      <link>https://zhangeamon.top/postgres/dba/</link>
      <pubDate>Wed, 19 Dec 2018 11:33:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/dba/</guid>
      <description>备份 恢复 时时热备
定期冷备
升级 每年大版本小版本升级，新特性调研，性能测试，稳定性。 可用当前最新的上一个版本。
HA 手动
自动
读写分离 sharding 多副本
安全 权限管理 资源隔离
审计 ddl
慢sql
锁长时间占用
巡检 定期巡检 awr 报告
监控 系统
数据库
诊断 优化 背景 应用程序的野蛮生长，由产品为驱动的开发，一切以快速上线为目标，在快速迭代的输出中很难有质量的保证。
运维人员和dba往往会充当救火队员，进入恶性循环。程序或架构设计不合理，导致数据库使用性能不佳，稍微来点业务量就导致数据库负载升高影响业务。
怎么办 梳理责任划分 必须有明确的责任划分，并不是程序上线后除了问题全部都是运维人员的责任，如果是程序的问题导致的故障，应该将责任追究到研发团队。
追责可以作为研发与运维的共同KPI考核指标，这样研发才有动力把程序开发好，而不是野蛮瞎搞。
建立程序交付标准 必须建立应用交付给运维的交付标准，程序上线前，必须要符合运行交付标准才允许上线。
必须包括试运行 商用前，必须有试运行阶段。建立约束机制，例如试运行阶段如果有N次应用引起的故障或已发现运行过程中的程序BUG，研发必须全部解决后，才允许商用。
变更制度 建立变更制度，操作规范，尽量避免变更带来的问题。
开发规约 事前防范，建立开发规约，避免开发阶段引入的问题。
培训 经常给开发培训，让他们熟悉数据库的最佳实践，避免踩坑。
SQL审核机制 建立自动化或人为的审核机制，涉及数据库变更，新增SQL都必须经过审核。
数据库生命周期管理 建立健全的生命周期管理制度。</description>
    </item>
    
    <item>
      <title>数据库三范式五约束</title>
      <link>https://zhangeamon.top/postgres/normal-form/</link>
      <pubDate>Mon, 17 Dec 2018 10:27:04 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/normal-form/</guid>
      <description>三范式  第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；  -- 1NF 第一范式 字段不能再分，就满足第一范式。 -- 2NF 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除联合主键可以避免部分依赖。增加单列关键字。 -- 3NF 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。 第二范式（2NF）和第三范式（3NF）的概念很容易混淆，区分它们的关键点在于，2NF：非主键列是否完全依赖于主键，还是依赖于主键的一部分；3NF：非主键列是直接依赖于主键，还是直接依赖于非主键列。
举例说明：
关系表（A，B，C，D）中A，B是候选键，那么：（A，B）→ C （A，B）→ D
2NF : 不能存在非主属性部分依赖主键 如: B → C 或 A → C 等。当主键为多值联合主键时可能会存在违反2NF
3NF : 不能存在非主属性之间的传递依赖 如: C → D 或 D → C
BCNF : 不能存在主属性之间的传递依赖 如 : A → B 或 B → A
五约束  primary KEY:设置主键约束； UNIQUE：设置唯一性约束，不能有重复值； DEFAULT 默认值约束 NOT NULL：设置非空约束，该字段不能为空； FOREIGN key :设置外键约束。  </description>
    </item>
    
    <item>
      <title>快速生成大量数据</title>
      <link>https://zhangeamon.top/postgres/insert01/</link>
      <pubDate>Fri, 14 Dec 2018 13:13:57 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/insert01/</guid>
      <description>在数据库中快速生成1w条数据，或测试数据库的写入性能。 创建数据库表 postgres=# create table tbl(id int, info text, crt_time timestamp); CREATE TABLE 方法一 generate_series 查看方法函数 postgres=# \df generate_series 函数列表 架构模式 | 名称 | 结果数据类型 | 参数数据类型 | 类型 ------------+-----------------+-----------------------------------+--------------------------------------------------------------------+------ pg_catalog | generate_series | SETOF bigint | bigint, bigint | 常规 pg_catalog | generate_series | SETOF bigint | bigint, bigint, bigint | 常规 pg_catalog | generate_series | SETOF integer | integer, integer | 常规 pg_catalog | generate_series | SETOF integer | integer, integer, integer | 常规 pg_catalog | generate_series | SETOF numeric | numeric, numeric | 常规 pg_catalog | generate_series | SETOF numeric | numeric, numeric, numeric | 常规 pg_catalog | generate_series | SETOF timestamp without time zone | timestamp without time zone, timestamp without time zone, interval | 常规 pg_catalog | generate_series | SETOF timestamp with time zone | timestamp with time zone, timestamp with time zone, interval | 常规 (8 行记录) postgres=# insert into tbl select id, md5(random()::text), clock_timestamp() from generate_series(1,10000) t(id); INSERT 0 10000 方法二 pgbench vi test.</description>
    </item>
    
    <item>
      <title>Pipelinedb 简介</title>
      <link>https://zhangeamon.top/postgres/pipelinedb02/</link>
      <pubDate>Wed, 12 Dec 2018 11:39:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pipelinedb02/</guid>
      <description>项目已经停止维护 适配支持版本
PostgreSQL 10: 10.1, 10.2, 10.3, 10.4, 10.5 PostgreSQL 11: 11.0 基本概念 流(Stream) 流是基础，Continuous Views和transform则是基于流中的数据进行处理的手段。 对于同一份数据，只需要定义一个流，写入一份即可。 如果对同一份数据有多个维度的统计，可以写在一条SQL完成的（如同一维度的运算或者可以支持窗口的多维度运算），只需定义一个Continuous Views或transform。如果不能在同一条SQL中完成计算，则定义多个Continuous Views或transform即可。 如果有多份数据来源（例如设计时就已经区分了不同的表）时，定义不同的流即可；
流视图 流视图，其实就是定义统计分析的QUERY， 例如select id, count(*), avg(x), &amp;hellip; from stream_1 group by &amp;hellip;; 就属于一个流视图。 定义好之后，数据插入流(stream_1)，这个流视图就会不断增量的进行统计，你只要查询这个流视图，就可以查看到实时的统计结果。 数据库中存储的是实时统计的结果（实际上是在内存中进行增量合并的，增量的方式持久化）。
Transforms 与流视图不同的是，transform是用来触发事件的，所以它可以不保留数据，但是可以设定条件，当记录满足条件时，就触发事件。 例如监视传感器的值，当值的范围超出时，触发报警（如通过REST接口发给指定的server），或者将报警记录下来（通过触发器函数）。
支持特性 pipelinedb继承了PostgreSQL很好的扩展性，例如支持了概率统计相关的功能，例如HLL等。用起来也非常的爽，例如统计网站的UV，或者红绿灯通过的汽车编号唯一值车流，通过手机信号统计基站辐射方圆多少公里的按时UV等。 Bloom Filter Count-Min Sketch Filtered-Space Saving Top-K HyperLogLog T-Digest
滑窗(Sliding Windows) 因为很多场景的数据有时效，或者有时间窗口的概念，所以pipelinedb提供了窗口分片的接口，允许用户对数据的时效进行定义。 例如仅仅统计最近一分钟的时间窗口内的统计数据。 比如热力图，展示最近一分钟的热度，对于旧的数据不关心，就可以适应SW进行定义，从而保留的数据少，对机器的要求低，效率还高。
安装 base on centos7&amp;amp;postgres10 add repository curl -s http://download.pipelinedb.com/yum.sh | sudo bash pipeline package sudo yum install pipelinedb-postgresql-10 修改数据库配置 # At the bottom of &amp;lt;data directory&amp;gt;/postgresql.</description>
    </item>
    
    <item>
      <title>Pipelinedb文档概览</title>
      <link>https://zhangeamon.top/postgres/pipelinedb01/</link>
      <pubDate>Wed, 12 Dec 2018 09:46:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pipelinedb01/</guid>
      <description>官方文档
介绍 What PipelineDB is What PipelineDB is not
QuitStart 一个统计wiki浏览的例子
安装 各种环境安装
Continuous Views 定义流视图，其实就是定义 统计分析的QUERY， 例如select id, count(*), avg(x), &amp;hellip; from table group by &amp;hellip;; 定义好之后，数据插入table，这个流视图就会不断增量的进行统计，你只要查询这个流视图，就可以查看到实时的统计结果。 数据库中存储的是实时统计的结果（实际上是在内存中进行增量合并的，增量的方式持久化）。
CREATE CONTINUOUS VIEW DROP CONTINUOUS VIEW TRUNCATE CONTINUOUS VIEW Viewing Continuous Views Data Retrieval Time-to-Live (TTL) Expiration Activation and Deactivation Examples
Continuous Transforms 与流视图不同的是，transform是用来转换数据流的，所以它可以不保留数据，但是可以设定条件，当记录满足条件时，就触发事件。
用途，将输入的数据流进行转换处理，过滤，加工等，用于复杂的业务逻辑，比如多个来源的数据流的合并加工。与现有的表进行joins操作,可以将结果传入其他流中，实现持续转换。
例如监视传感器的值，当值的范围超出时，触发报警（如通过REST接口发给指定的server），或者将报警记录下来（通过触发器函数）。
CREATE CONTINUOUS TRANSFORM DROP CONTINUOUS TRANSFORM Viewing Continuous Transforms Built-in Transform Triggers Creating Your Own Trigger</description>
    </item>
    
    <item>
      <title>Postgres 监控</title>
      <link>https://zhangeamon.top/postgres/monitor/</link>
      <pubDate>Thu, 06 Dec 2018 16:21:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/monitor/</guid>
      <description>各种监控方式   zabbix Monitor PostgreSQL with Zabbix
  postgres_exporter A PostgresSQL metric exporter for Prometheus
  pgwatch2 PostgreSQL metrics monitor/dashboard
  pgmetrics Collect and display information and stats from a running PostgreSQL server
  pgdash (收费)
  pganalyze PostgreSQL Performance Monitoring
  参考自己实现
  状态查看 pgcenter
pgcenter top pgcenter: 2018-12-20 11:10:25, load average: 0.94, 0.84, 0.86 state [ok]: ::1:5432 postgres@postgres (ver: 10.6, up 8 days 19:57:54, recovery: f) %cpu: 15.</description>
    </item>
    
    <item>
      <title>tablespace 表空间</title>
      <link>https://zhangeamon.top/postgres/tablespace/</link>
      <pubDate>Thu, 06 Dec 2018 11:17:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/tablespace/</guid>
      <description>原文
注意主从架构时，主从软连接位置需要对应一致。
思考： 冷热数据分离 冷数据对热数据的影响，垃圾回收机制。</description>
    </item>
    
    <item>
      <title>TOAST 技术</title>
      <link>https://zhangeamon.top/postgres/toast/</link>
      <pubDate>Thu, 06 Dec 2018 11:14:20 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/toast/</guid>
      <description>原文</description>
    </item>
    
    <item>
      <title>fillfactor 填充因子</title>
      <link>https://zhangeamon.top/postgres/fillfactor/</link>
      <pubDate>Thu, 06 Dec 2018 11:01:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/fillfactor/</guid>
      <description>介绍 PostgreSQL每个表和索引的数据都是由很多个固定尺寸的页面存储（通常是 8kB，不过在编译服务器时[–with-blocksize]可以选择其他不同的尺寸） 一个表的填充因子(fillfactor)是一个介于 10 和 100 之间的百分数。100(完全填充)是默认值。如果指定了较小的填充因子，INSERT 操作仅按照填充因子指定的百分率填充表页。每个页上的剩余空间将用于在该页上更新行，这就使得 UPDATE 有机会在同一页上放置同一条记录的新版本，这比把新版本放置在其它页上更有效。对于一个从不更新的表将填充因子设为 100 是最佳选择，但是对于频繁更新的表，较小的填充因子则更加有效。
PostgresSQL 使用Heap-Only Tuple 技术 会在旧行与新行之间建立一个链表，这样一来就不需要更新索引了，索引项仍会指向旧行，通过链表可以找到新行。因此Heap-Only Tuple 的链表不能跨数据块。
示例 create table t_fillfactor01(id int ,name varchar , blog text ) WITH (fillfactor=70); CREATE TABLE new_test=# \d+ t_fillfactor01 Table &amp;quot;public.t_fillfactor01&amp;quot; Column | Type | Modifiers | Storage | Stats target | Description --------+-------------------+-----------+----------+--------------+------------- id | integer | | plain | | name | character varying | | extended | | blog | text | | extended | | Options: fillfactor=70 测试 /**************************************************************************************** 创建测试表 test1设置fillfactor=100 test2设置fillfactor=80 drop table if exists test1; drop table if exists test2; ****************************************************************************************/ create table test1( objectid bigserial not null, --唯一编号，主键 name text not null, --名称 describe text, --备注 generate timestamptz default now() not null,--创建日期 constraint pk_test1_objectid primary key(objectid) )with (fillfactor=100); create table test2( objectid bigserial not null, --唯一编号，主键 name text not null, --名称 describe text, --备注 generate timestamptz default now() not null,--创建日期 constraint pk_test2_objectid primary key(objectid) )with (fillfactor=80); /**************************************************************************************** 创建随机生成中文字符函数 drop function if exists gen_random_zh(int,int); ****************************************************************************************/ create or replace function gen_random_zh(int,int) returns text as $$ select string_agg(chr((random()*(20901-19968)+19968 )::integer) , &#39;&#39;) from generate_series(1,(random()*($2-$1)+$1)::integer); $$ language sql; /**************************************************************************************** 导入测试数据 ****************************************************************************************/ insert into test1(name) select gen_random_zh(8,32) from generate_series(1,10000); insert into test2(name) select gen_random_zh(8,32) from generate_series(1,10000); /**************************************************************************************** 查看test1数据在页中的布局 ****************************************************************************************/ select ctid,objectid from test1 limit 500; 略 select ctid,objectid from test2 limit 500; 略 ---test1 --- fillfactor = 100 select ctid from test1 where objectid = 93; ctid -------- (1,18) (1 row) update test1 set name=gen_random_zh(8,32) where objectid = 93; select ctid from test1 where objectid = 93; ctid ---------- (133,31) (1 row) --test2 --- fillfactor = 80 select ctid from test2 where objectid = 93; ctid -------- (1,32) (1 row) update test2 set name=gen_random_zh(8,32) where objectid = 93; select ctid from test2 where objectid = 93; ctid -------- (1,58) (1 row) --------------------- 可以看到test1中因为填充率为100%,update后第一页中没有位置存储新的数据了,所以检查最大的页文件是否还有位置,如果有直接插入,如果没有则再新建一页后插入,在本例中跳过了132个页文件.</description>
    </item>
    
    <item>
      <title>vacuum 垃圾回收器</title>
      <link>https://zhangeamon.top/postgres/vacuum/</link>
      <pubDate>Wed, 05 Dec 2018 16:48:00 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/vacuum/</guid>
      <description>介绍 数据库总是不断地在执行删除，更新等操作。良好的空间管理非常重要，能够对性能带来大幅提高。在postgresql中用于维护数据库磁盘空间的工具是VACUUM，其重要的作用是删除那些已经标示为删除的数据并释放空间。 postgresql中执行delete,update操作后，表中的记录只是被标示为删除状态，并没有释放空间，在以后的update或insert操作中该部分的空间是不能够被重用的。经过vacuum清理后，空间才能得到释放。
意义 PostgreSQL每个表和索引的数据都是由很多个固定尺寸的页面存储（通常是 8kB，不过在编译服务器时[–with-blocksize]可以选择其他不同的尺寸）
PostgreSQL中数据操作永远是Append操作,具体含义如下:
 insert 时向页中添加一条数据 update 将历史数据标记为无效,然后向页中添加新数据 delete 将历史数据标记为无效  因为这个特性,所以需要定期对数据库vacuum,否则会导致数据库膨胀,建议打开autovacuum.
文法 VACUUM [ ( { FULL | FREEZE | VERBOSE | ANALYZE | DISABLE_PAGE_SKIPPING } [, ...] ) ] [ table_name [ (column_name [, ...] ) ] ] VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ table_name ] VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] ANALYZE [ table_name [ (column_name [, .</description>
    </item>
    
    <item>
      <title>Explain 执行计划</title>
      <link>https://zhangeamon.top/postgres/explain/</link>
      <pubDate>Wed, 05 Dec 2018 15:27:30 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/explain/</guid>
      <description>文法 EXPLAIN [ ( option [, ...] ) ] statement EXPLAIN [ ANALYZE ] [ VERBOSE ] statement 这里 option可以是： ANALYZE [ boolean ] VERBOSE [ boolean ] COSTS [ boolean ] BUFFERS [ boolean ] TIMING [ boolean ] SUMMARY [ boolean ] FORMAT { TEXT | XML | JSON | YAML } 注意事项 记住当使用了ANALYZE选项时语句会被实际执行. 如执行dml 时将对数据库进行实际的操作。
避免污染数据的方式
BEGIN; EXPLAIN ANALYZE ...; ROLLBACK; 一个例子 postgres=# explain analyze select * from tbl; QUERY PLAN ------------------------------------------------------------------------------------------------------------------ Seq Scan on tbl (cost=0.</description>
    </item>
    
    <item>
      <title>数据库日志</title>
      <link>https://zhangeamon.top/postgres/log/</link>
      <pubDate>Tue, 04 Dec 2018 15:45:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/log/</guid>
      <description>介绍 PostgreSQL有3种日志，分别是pg_log（数据库运行日志）、pg_xlog（WAL 日志，即重做日志）、pg_clog（事务提交日志，记录的是事务的元数据） postgres 10 版本将文件目录结构改为 log，pg_wal，pg_xact log默认是关闭的，需要设置其参数。wal和xact都是强制打开的，无法关闭。 本文主要介绍　log 能
配置 语法: 修改　ALTER SYSTEM SET 参数=值; 查看　show 参数;
重新启动数据库生效;
启用pg_log并配置日志参数
ALTER SYSTEM SET log_destination = &#39;csvlog&#39;; ALTER SYSTEM SET logging_collector = on; ALTER SYSTEM SET log_filename = &#39;postgresql-%Y-%m-%d_%H%M%S.log&#39;; ALTER SYSTEM SET log_rotation_age = &#39;1d&#39;; ALTER SYSTEM SET log_rotation_size = &#39;100MB&#39;; ALTER SYSTEM SET log_min_messages = &#39;info&#39;; 记录日志信息
ALTER SYSTEM SET log_checkpoints = on; ALTER SYSTEM SET log_connections = on; ALTER SYSTEM SET log_disconnections = on; ALTER SYSTEM SET log_duration = on; ALTER SYSTEM SET log_line_prefix = &#39;%m&#39;; 记录执行慢的SQL 记录超过该时长的所有SQL，对找出当前数据库的慢查询很有效。时间单位ms</description>
    </item>
    
    <item>
      <title>模板数据库</title>
      <link>https://zhangeamon.top/postgres/template/</link>
      <pubDate>Fri, 30 Nov 2018 09:52:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/template/</guid>
      <description>模板数据库 模板数据库就是创建新database时，PostgreSQL会基于模板数据库制作一份副本，其中会包含所有的数据库设置和数据文件。 PostgreSQL安装好以后会默认附带两个模板数据库：template0和template1。
 template0 干净版，任何时候不要修改 template1 默认版，如果创建数据库时不指定模板将默认模板指定为template1  区别   template1 可以连接并创建对象，template0 不可以连接
  使用 template1 模板库建库时不可指定新的 encoding 和 locale，而 template0 可以
  使用 使用方法　 create database mytemplate template template1; create database mydatabase template mytemplate; 设置自己的模板　mytemplate
在自己的模板中需改信息，比如　添加必备的扩展，统计函数库等。
其他数据库在创建时使用自定的模板</description>
    </item>
    
    <item>
      <title>pg_stat_statements 数据库统计信息</title>
      <link>https://zhangeamon.top/postgres/pg_stat_statements/</link>
      <pubDate>Thu, 29 Nov 2018 11:08:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_stat_statements/</guid>
      <description>pg_stat_statements 扩展 安装　 yum install postgresql10-contrib.x86_64 修改配置参数 vi $PGDATA/postgresql.conf shared_preload_libraries=&#39;pg_stat_statements&#39; # 加载模块　需要重启 , 近期测试不需要添加也可以。自带扩展 track_io_timing = on # 跟踪IO耗时 (可选) track_activity_query_size = 2048 # 设置单条SQL的最长长度，超过被截断显示（可选) pg_stat_statements.max = 10000 #在pg_stat_statements中最多保留多少条统计信息，通过LRU算法，覆盖老的记录。 pg_stat_statements.track = all # all - (所有SQL包括函数内嵌套的SQL), top - 直接执行的SQL(函数内的sql不被跟踪), none - (不跟踪) pg_stat_statements.track_utility = off #是否跟踪非DML语句 (例如DDL，DCL)，on表示跟踪, off表示不跟踪 pg_stat_statements.save = on #重启后是否保留统计信息 重启数据库 systemctl restart postgresql-10 创建扩展 create extension pg_stat_statements; \d pg_stat_statements View &amp;quot;public.pg_stat_statements&amp;quot; Column | Type | Collation | Nullable | Description ---------------------+------------------+-----------+----------+--------- userid | oid | | | 执行该语句的用户的 OID dbid | oid | | | 在其中执行该语句的数据库的 OID queryid | bigint | | | 内部哈希码，从语句的解析树计算得来 query | text | | | 语句的文本形式 calls | bigint | | | 被执行的次数 total_time | double precision | | | 在该语句中花费的总时间，以毫秒计 min_time | double precision | | | 在该语句中花费的最小时间，以毫秒计 max_time | double precision | | | 在该语句中花费的最大时间，以毫秒计 mean_time | double precision | | | 在该语句中花费的平均时间，以毫秒计 stddev_time | double precision | | | 在该语句中花费时间的总体标准偏差，以毫秒计 rows | bigint | | | 该语句检索或影响的行总数 shared_blks_hit | bigint | | | 该语句造成的共享块缓冲命中总数 shared_blks_read | bigint | | | 该语句读取的共享块的总数 shared_blks_dirtied | bigint | | | 该语句弄脏的共享块的总数 shared_blks_written | bigint | | | local_blks_hit | bigint | | | local_blks_read | bigint | | | 该语句读取的本地块的总数 local_blks_dirtied | bigint | | | 该语句弄脏的本地块的总数 local_blks_written | bigint | | | 该语句写入的本地块的总数 temp_blks_read | bigint | | | temp_blks_written | bigint | | | blk_read_time | double precision | | | 该语句花在读取块上的总时间，以毫秒计（如果track_io_timing被启用，否则为零) blk_write_time | double precision | | | 该语句花在写入块上的总时间，以毫秒计（如果track_io_timing被启用，否则为零) 在数据库中生成了一个名为 pg_stat_statements 的视图,对数据库的跟踪也是基于这个视图展开。</description>
    </item>
    
    <item>
      <title>数据库拓展</title>
      <link>https://zhangeamon.top/postgres/extention/</link>
      <pubDate>Tue, 27 Nov 2018 15:20:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/extention/</guid>
      <description>  流计算数据库产品 pipelineDB *
  推荐数据库产品 recDB
  时序数据库 timescaleDB *
  分布式数据库插件 citus *
  列存储插件 IMCS, cstore等
  面向OLAP的codegen数据库 pg_LLVM
  向量计算插件 vops
  数据库性能分析 pg_stat_statements pg_buffercache
  直接访问数据库文件系统 adminpack
  加密数据 pgcrypto
  预热缓存 pg_prewarm
  检查存储，特别是表膨胀 pgstattuple
  模糊搜索 pg_trgm
  连接到远程服务器 postgres_fdw
  k近邻（KNN）搜索 btree_gist
  比如检索10左右的数据，价格在100左右的数据。
create index idx_value_001 on t_talbe01 USING gist(value); select * from t_table01 where value &amp;lt;-&amp;gt; 100 limit 10; </description>
    </item>
    
    <item>
      <title>数据库参数</title>
      <link>https://zhangeamon.top/postgres/params/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/params/</guid>
      <description>postgres 数据库参数该如何设置 性能参数pgtune pgconfig 日志参数 更多参数详解 管理 listen_addresses = &amp;quot;*&amp;quot; # 连接访问控制，哪些ip可以访问， * 全部。 结合pg_hba.conf , iptables设置。 superuser_reserved_connections = 3 # 预留给超级管理员的连接数。 port = 5432 # 默认访问端口 wal_keep_segments = 1024 # wal 日志保存数量 wal日志 wal_log_hints = on full_page_writes = on 成本因子 # - Planner Cost Constants - #seq_page_cost = 1.0 # measured on an arbitrary scale 顺序扫描 random_page_cost = 1.1 # same scale as above 随机扫描。HDD 4 ;SSD 1.1; 由于SSD没有磁盘寻道时间，顺序扫描和随机扫描的差距不是那么大。比例设置的相近即可。 #cpu_tuple_cost = 0.</description>
    </item>
    
    <item>
      <title>数据库索引类型及使用场景</title>
      <link>https://zhangeamon.top/postgres/index01/</link>
      <pubDate>Mon, 19 Nov 2018 09:00:44 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/index01/</guid>
      <description>用途 优点
 主键唯一约束 加速检索 排序  缺点
 更新数据时需要同时维护对应索引 占用磁盘空间，甚至比表数据本身还要多  使用场景利弊分析
 TP与AP应用 读写使用比例 点查询批量查询  创建索引 \h create index 命令： CREATE INDEX 描述： 建立新的索引 语法： CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] 名称 ] ON 表名 [ USING 方法 ] ( { 列名称 | ( 表达式 ) } [ COLLATE 校对规则 ] [ 操作符类型的名称 ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, .</description>
    </item>
    
    <item>
      <title>PostgreSQL 无法kill(pg_terminate_backend, pg_cancel_backend)的情况分析 - 进程hang strace,pstack</title>
      <link>https://zhangeamon.top/postgres/kill/</link>
      <pubDate>Wed, 14 Nov 2018 22:09:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/kill/</guid>
      <description>先 mark 下 https://yq.aliyun.com/articles/647468</description>
    </item>
    
    <item>
      <title>Postgresql指标查看&amp;stat统计信息</title>
      <link>https://zhangeamon.top/postgres/stat/</link>
      <pubDate>Tue, 06 Nov 2018 10:53:52 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/stat/</guid>
      <description>当前连接数  SELECT count(*) FROM pg_stat_activity WHERE NOT pid=pg_backend_pid(); count ------- 3 (1 row)  数据库占用空间  select pg_size_pretty(pg_database_size(&#39;postgres&#39;)); pg_size_pretty ---------------- 14 MB (1 row) or \l+  数据库表(不包括索引)或单条索引占用空间  select pg_size_pretty(pg_relation_size(&#39;t_name&#39;)); pg_size_pretty ---------------- 24 kB (1 行记录) or \d+  表中所有索引占有的空间  select pg_size_pretty(pg_indexes_size(&#39;t_name&#39;)); pg_size_pretty ---------------- 280 kB (1 行记录)  表和索引占用总空间  select pg_size_pretty(pg_total_relation_size(&#39;t_name&#39;)); pg_size_pretty ---------------- 380 kB (1 行记录)  查看一条数据在数据库占用的空间  select pg_column_size(&#39;Let us go !</description>
    </item>
    
    <item>
      <title>数据库备份和恢复</title>
      <link>https://zhangeamon.top/postgres/backup_restore/</link>
      <pubDate>Tue, 30 Oct 2018 10:18:57 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/backup_restore/</guid>
      <description>Postgres 数据库备份恢复命令
备份：pg_dump -U postgres -v -F c -Z 4 -f ***.backup dbname 9压缩率最狠 恢复：pg_restore -U postgres -v -j 8 -d dbname ***.backup 8是采用8个线程 备份表：pg_dump -U postgres -t tablename dbname &amp;gt; 33.sql 恢复表：psql -U postgres -d dbname &amp;lt; 33.sql 只备份表结构 pg_dump -U postgres -s -t tablename dbname &amp;gt; 33.sql 只备份数据 pg_dump -U postgres -a -t tablename dbname &amp;gt; 33.sql copy 拷贝数据
数据拷贝到本地： psql -U postgres -d databasename -p 5432 -h 10.</description>
    </item>
    
    <item>
      <title>主从流复制</title>
      <link>https://zhangeamon.top/postgres/replication01/</link>
      <pubDate>Wed, 17 Oct 2018 14:55:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/replication01/</guid>
      <description>历史演变
replication
主库配置 根据实际情况分配流复制权限 vi pg_hba.conf host replication all 10.2.0.0/0 trust vi postgresql.conf max_wal_senders = 10 wal_level = logical # minimal, replica, or logical hot_standby = on # 正常在从库配置，如果在主库配置完毕，因为从库复制主库配置不需要再修改从库配置。 wal_log_hints = on 从库配置 1 数据库安装
2 从主库复制数据
pg_basebackup -h 10.2.0.14 -U postgres -F p -P -R -D /var/lib/pgsql/10/data/ --checkpoint=fast -l postgresback20181219 pg_basebackup支持两种全量备份的方式，
  以fetch的方式，先备份数据在备份日志
  以stream的方式，并行的备份数据和日志
  pg_basebackup对于全量备份的数据和日志，提供了串行备份和并行备份的方式。fetch模式也就是串行备份需要保证在备份数据的过程中，备份开始时刻的日志需要一直保存下来， 也就说pg的wal_keep_segments需要足够大去保存日志文件，如果备份数据期间，日志开始时刻的日志已经被移除，那么备份就会失败。而stream模式，也就是并行备份过程中wal_max_sender必须保证不小于2。 而stream模式不支持，将数据和日志以流的方式输出到标准输出
限速，在生产系统中防止对正常业务的影响
-r, --max-rate=RATE maximum transfer rate to transfer data directory (in kB/s, or use suffix &amp;quot;k&amp;quot; or &amp;quot;M&amp;quot;) 注意新拷贝数据的权限</description>
    </item>
    
    <item>
      <title>安装 Postgresql</title>
      <link>https://zhangeamon.top/postgres/install01/</link>
      <pubDate>Wed, 17 Oct 2018 14:37:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/install01/</guid>
      <description>官网
1.准备源
清除历史残余，有些是系统自带的旧版本数据库 rpm -qa | grep postgres rpm -r **** 安装新数据源 yum install https://download.postgresql.org/pub/repos/yum/10/redhat/rhel-7-x86_64/pgdg-centos10-10-2.noarch.rpm yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 可将所有的软件更新到最新版本如 ， postgresql-10.2 更新到当前最新的postgresql-10.6 yum update -y 2.安装
yum install -y postgresql10-server postgresql10 postgresql10-contrib 3.初始化
默认 /usr/pgsql-10/bin/postgresql-10-setup initdb 自定义 /usr/pgsql-10/bin/initdb -D $PGDATA -U postgres -E UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8 -k -D 数据存放位置 -U 超级用户 -E 默认编码 --lc-collate 区域 Collate会影响中文的排序，在zh_CN的区域下中文按拼音排序，其它区域按字符编码排序。 --lc-ctype 字符类型Ctype会影响pg_trgm和部分正则匹配的结果，比如Ctype为&#39;C&#39;时，pg_trgm将无法支持中文。 -k 使用 data checksums 可将数据存放到其他目录下，使用软连接的方式。
为什么会使用软连接而不是更改PGDATA环境变量，因为升级数据库的时 PGDATA 被指回默认值。
通过软连接的方式不改变初始值:
1 升级的时候不用修改PGDATA
2 数据位置存放固定，便于以后管理。</description>
    </item>
    
  </channel>
</rss>