<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Let&#39;s Go!</title>
    <link>https://zhangeamon.top/</link>
    <description>Recent content on Let&#39;s Go!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Mar 2021 17:23:59 +0800</lastBuildDate>
    
	<atom:link href="https://zhangeamon.top/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Redis 应用场景</title>
      <link>https://zhangeamon.top/redis/redis-scence/</link>
      <pubDate>Tue, 09 Mar 2021 17:23:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/redis/redis-scence/</guid>
      <description> 应用场景 作为一名匠人，当熟悉手里各样工具的特点。用起来才能得心应手。什么时候使用锯子，什么时候当用斧子。
同理熟知产品的技术特性，方可灵活运用。
在面对不同的业务需求时才能提供具有针对性的解决方案。
不求十八般兵器样样精通，但求不置斧锯于一旁只顾轮打锤。
Redis 都能干点啥  缓存 消息队列 循环列表 排行榜 计数器 SET 集合操作 分布式锁 跳表  </description>
    </item>
    
    <item>
      <title>云存储同步 rclone</title>
      <link>https://zhangeamon.top/storage/rclone/</link>
      <pubDate>Tue, 09 Mar 2021 16:40:29 +0800</pubDate>
      
      <guid>https://zhangeamon.top/storage/rclone/</guid>
      <description>云端对象同步 Rclone (&amp;ldquo;rsync for cloud storage&amp;rdquo;) is a command line program to sync files and directories to and from different cloud storage providers.
https://github.com/rclone/rclone</description>
    </item>
    
    <item>
      <title>pg_rman 备份恢复数据库</title>
      <link>https://zhangeamon.top/postgres/pg_rman/</link>
      <pubDate>Tue, 09 Mar 2021 13:35:31 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_rman/</guid>
      <description>适用场景 PG_RMAN 基于本地数据拷贝的方式，要求与数据库需要安装在同一个机器节点上。
适用于项目初期，对数据库的规划处于初级阶段。实体机不充分的情况是个很好的选择。
数据库使用ssd盘，备份磁盘采用企业sata大盘。或nfs网盘等。
PG_RMAN 支持全备份，增量备份，备份验证，保留策略等
应用软件包地址 https://github.com/ossc-db/pg_rman/releases
基本用法 -- 初始化 /usr/pgsql-13/bin/pg_rman -D /var/lib/pgsql/13/data/ -B /data/backup/ init -- 在/data/backup 目录下会产生如下目录结构 backup pg_rman.ini system_identifier timeline_history -- 全备份 pg_rman backup -B /pgdata/backup -D /var/lib/pgsql/13/data/ -b full -h 127.0.0.1 -p 5432 -U backup -d postgres -- 验证 pg_rman validate -- 详情查看 pg_rman show detail -- 增量备份 pg_rman backup -B /pgdata/backup -D /var/lib/pgsql/13/data/ -b incremental -h 127.0.0.1 -p 5432 -U backup -d postgres  设置保留策略</description>
    </item>
    
    <item>
      <title>Patroni 高可用管理进阶</title>
      <link>https://zhangeamon.top/postgres/patroni02/</link>
      <pubDate>Fri, 05 Mar 2021 17:06:18 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/patroni02/</guid>
      <description>完成目标  主从同步策略 异地多机房策略 failover 触发详情 访问认证 watch-dog 配置文件详情 fencing DCS 失效处理 加入节点复制数据限流 主从切换流量,避免重新拉取 级联复制 callback 日志&amp;amp;监控  主从同步策略 数据库主从之间同步类型
Synchronous state of this standby server. Possible values are: async: This standby server is asynchronous. potential: This standby server is now asynchronous, but can potentially become synchronous if one of current synchronous ones fails. sync: This standby server is synchronous. quorum: This standby server is considered as a candidate for quorum standbys.</description>
    </item>
    
    <item>
      <title>数据库优化思考-性能优化</title>
      <link>https://zhangeamon.top/postgres/thinking_in_db_performance/</link>
      <pubDate>Fri, 26 Feb 2021 13:33:23 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/thinking_in_db_performance/</guid>
      <description>为什么要优化 首先了解一个概念，什么是·熵增·
物理定义：熵增过程是一个自发的由有序向无序发展的过程(Bortz, 1986; Roth, 1993)
在一个孤立的系统里，如果没有外力做工，其总混乱度（即熵）会不断增大，直至系统彻底变得无序
从系统软件的角度： 从应用系统上线那一刻开始，随着用户量的增加、业务功能的持续迭代，系统会面临各种不同程度的挑战，如果不及时采取优化措施，我们会发现诸多问题
比如：系统怎么越来越慢了，流量一高系统就卡顿、甚至宕机等等。
可以说，性能优化是贯穿在整个软件生命周期之中的
通常有哪些优化方法  结构优化 性能优化 模块优化  在算法领域，评价一个算法的效率如何，主要会看它的时间复杂度和空间复杂度情况。
引用在数据库的优化中，
时间复杂度： 着重考量的是时间成本，效率。 通常理解成性能优化，如何让我的访问更快
空间复杂度： 着重考量的是资源成本。可对应结构优化，如果组织数据的存放。
那么，在做优化时，本质上也是从“优化时间”、“优化空间”、“时空互换（用时间换空间或用空间换时间）”三个方向去思考，然后在空间、时间上不停地做取舍。
优化衡量指标 系统优化的目标提高系统的吞吐量：单位时间内能够处理的请求数量
举个例子。把系统比作一个银行营业网点。 有多个窗口对外提供服务。 如何能够提高整体的处理量呢？
 空间 增加营业窗口
 时间 提高每个窗口的效率
  关于空间的优化参见数据库优化思考 - 结构设计, 本篇更多思考的是性能（时间）的优化。
性能优化的衡量指标 响应时间(RT), 包括
 平均响应时间(AVG)  接口的平均处理能力， 但什么东西一平均很多就被平均了，如人均收入！😓。 不能很好反应真实情况。另一种类似中位数的指标。
 百分位数(Top Percentile)  一种统计学术语，反映的是超过n%的请求都在m时间内返回，一般用TPn=m来描述，比如：TP99=5，表示超过99%的请求都能在5ms内返回。
优化如何具体做 开发端：
 实现方法 条条大路通罗马，实现的功能是否只满足业务功能的需求，而没有考虑性能。
 索引 索引用的好，性能没烦恼。大部分应用端的性能问题都可以通过索引来改善。
  索引本身也是一种空间换时间的手段。索引本身也是需要额外的代价。
 锁等待 最漫长的莫过于等待。  运维端：</description>
    </item>
    
    <item>
      <title>Smapler</title>
      <link>https://zhangeamon.top/monitor/smapler/</link>
      <pubDate>Wed, 10 Feb 2021 09:31:44 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/smapler/</guid>
      <description>一款轻量级的一体化监控工具 https://github.com/sqshq/sample</description>
    </item>
    
    <item>
      <title>Git 文件过大清理</title>
      <link>https://zhangeamon.top/linux/git-objects-clean/</link>
      <pubDate>Mon, 08 Feb 2021 14:30:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/git-objects-clean/</guid>
      <description>git目录下object文件过大清理
一、删除仓库上的项目，重新提交代码。
二、彻底清除历史记录
查询大文件的文件名 git rev-list --objects --all | grep &amp;quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk &#39;{print$1}&#39;)&amp;quot; 删除历史记录 git filter-branch --force --index-filter &#39;git rm -rf --cached --ignore-unmatch 你的大文件名&#39; --prune-empty --tag-name-filter cat -- --all rm -rf .git/refs/original/ git reflog expire --expire=now --all git fsck --full --unreachable git repack -A -d 本地空间变小 git gc --aggressive --prune=now 推送远端 ，本地远端空间都变小 git push --force  git 还是尽量不保存大文件，及时删除了遗留历史包袱。</description>
    </item>
    
    <item>
      <title>Postgres  数据库</title>
      <link>https://zhangeamon.top/content/postgres/</link>
      <pubDate>Mon, 08 Feb 2021 10:10:01 +0800</pubDate>
      
      <guid>https://zhangeamon.top/content/postgres/</guid>
      <description> 关于优化思考  数据库优化思考 - 性能优化 数据库优化思考 - 结构设计 数据库优化思考 - 模块调优  基础知识  模板数据库 数据库日志 Explain 执行计划 vacuum 垃圾回收器 表空间膨胀 fillfactor 填充因子 TOAST 技术 hot update checkpoint tablespace 表空间 锁机制 锁等待 cluster 聚族表 咨询锁 adlock 数据库视图之 pg_stat_activity 数据库年龄 方法和函数 高级SQL 数据库 OOM 预防 跨库操作 auto vacuum 触发机制 unlogged table  安装维护  安装 Postgres 主从流复制 Logical Replication 逻辑复制 数据库参数 指标查看&amp;amp;stat统计信息 拓展插件 pg_stat_statements统计信息 pg-pool2 pgbouncer 连接池 postgres 12 Untunu18安装Postgres12 数据预加载 kylin系统postgresql编译安装  管理  pg_pathman 分区表 范式约束 DBA 日常 数据库日常管理 应用实战 创建只读用户 找回supper user 权限 分区表  备份恢复  备份&amp;amp;恢复 Archive wal归档 时间点恢复 误操作闪回 使用PG_RMAN管理备份恢复  索引  索引类型及使用场景 引起索引失效 pg_trgm的gist和gin索引加速字符匹配查询 Bloom 索引  流数据库  Pipelinedb文档概览 Pipelinedb 简介  时序数据库  TimescaleDB 时序数据库  数据库测试  快速生成大量数据 pgbench 压力测试 tpch AP测试  监控系统  监控工具 pgwatch2 数据库指标监控查看 数据库监控指标  日志系统  ELK  高可用  主从流复制 PG主从切换 pg_rewind PG高可用Patroni搭建 PG高可用Patroni管理进阶  分布式  citus 数据库分库 citus 简单应用  安全管理  数据库 ssl认证  </description>
    </item>
    
    <item>
      <title>etcd 访问控制</title>
      <link>https://zhangeamon.top/middleware/etcd_auth/</link>
      <pubDate>Fri, 29 Jan 2021 09:37:26 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/etcd_auth/</guid>
      <description>介绍 etcd 默认没有开启访问控制。 在生产环境中使用属于裸奔。
开启访问控制有两种方式
 密钥证书验证
 用户名密码验证
  本篇实验用户名密码验证方式
用户 开启访问认证需要创建root 用户，root 用户默认自动拥有root角色的权限，及超级管理员。
角色 角色理解为指定权限的集合，权限包括 read 、write、 readwrite
角色用于对访问权限的管理控制。
系统默认拥有角色root 、guest。
系统通过授权用户不同权限的角色，实现对用户的访问控制。
用户管理  etcdctl user --help NAME: etcdctl user - user add, grant and revoke subcommands USAGE: etcdctl user command [command options] [arguments...] COMMANDS: add add a new user for the etcd cluster get get details for a user list list all current users remove remove a user for the etcd cluster grant grant roles to an etcd user revoke revoke roles for an etcd user passwd change password for a user OPTIONS: --help, -h show help  角色管理 etcdctl role --help NAME: etcdctl role - role add, grant and revoke subcommands USAGE: etcdctl role command [command options] [arguments.</description>
    </item>
    
    <item>
      <title>hot update</title>
      <link>https://zhangeamon.top/postgres/hotupdate/</link>
      <pubDate>Thu, 14 Jan 2021 13:49:11 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/hotupdate/</guid>
      <description>What is HOT HOT是“Heap Only Tuple”（仅元组堆）的缩写, 用来提高update效率。
行的新版本和旧版本位于同一块中时，该行的外部地址（原始行指针）保持不变，利用hot link指针进行转发地址。索引不需要任何改动。
前提条件  包含更新行的块中必须有足够的空间
 在已修改值的任何列上均未定义索引
  生产应用 使用fillfactor以获取HOT更新
例子 建表
CREATE TABLE mytable ( id integer PRIMARY KEY, val integer NOT NULL ) WITH (autovacuum_enabled = off); INSERT INTO mytable SELECT *, 0 FROM generate_series(1, 235) AS n;  8k page 物理分布
SELECT ctid, id, val FROM mytable; ctid | id | val ---------+-----+----- (0,1) | 1 | 0 (0,2) | 2 | 0 (0,3) | 3 | 0 (0,4) | 4 | 0 (0,5) | 5 | 0 .</description>
    </item>
    
    <item>
      <title>数据库优化思考 - 模块调优</title>
      <link>https://zhangeamon.top/postgres/thinking_in_db_tune/</link>
      <pubDate>Wed, 13 Jan 2021 09:04:35 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/thinking_in_db_tune/</guid>
      <description>开始乱说 主要是结合postgres数据库自身特点，根据具体的业务场景，作出相应调整，使其更加合理。
数据库作为一个整体对外提供服务，单是其内部是由不同的功能模块组成，相互协调来共同完成任务。
各个功能模块完成不同的功能，每个模块的特点也不同，在调整的时候至少需要理解各个模块实现的基本原理（属于内功需修炼）才好下手。
各个功能模块又相互影响，共享资源，也就是他们之间会存在竞争资源。比如当系统发生gc时对几乎各个模块都会产生影响。
有些问题可能是多个模块共同产生的。 最常见的如一条慢sql，可能引起的原因可能是索引不合理，执行计划跑偏，sql本身问题，lock, 当时系统正在gc。等等。
数据库作为一个产品，为了适应更广泛的场景，通常情况下默认设置都比较保守。默认的设置能够在大多数情况下满足的的需求，但是在对性能用所要求的生产环境下需必要的调整，甚至会私人定制。
不同场景区别对待 场景主要分为TP、AP两种场景。
不同的使用场景优化的方向应该是不同的，侧重点也会不同。
TP 强调的短平快，注重TPS。相当于跑车追求速度，效率。
AP 强调的吞吐量，相当于大卡车。
针对不同车辆设计不同的道路才合理。
在跑车的赛道上开来一辆大卡车，彼此伤害。TP如果不幸就此挂掉，真的不能说是系统不够健壮。
补充： 慢Sql可视为TP系统性能上的bug , 高速运行的列车，飞机任何碰撞都是致命的。
TP 系统中一条慢Sql的伤害  伤磁盘IO 伤系统CUP 伤系统内存 伤数据库MVCC LOCK VACUUM 伤系统统计信息、temp 伤数据库缓存 伤数据库连接数  监测很重要 你是我的眼 👀
作用
 早期发现问题
 评估调整后效果
  工具
 监控系统
 日志系统
  功能模块概览  vacuum  避免在高峰时发生，又能及时处理，避免表膨胀。调整触发条件及手动触发
 checkpoint  频率，IO平滑度
 sql  满足功能同时是否考虑性能
 wal  输出量，FPI</description>
    </item>
    
    <item>
      <title>unlogged table</title>
      <link>https://zhangeamon.top/postgres/unlogged_table/</link>
      <pubDate>Tue, 12 Jan 2021 10:21:36 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/unlogged_table/</guid>
      <description>介绍 在写数据的时候不记录wal的表。
在意外发生时表中的数据被trunce 。如断电、 主进程kill 、scrash 等。
正常关闭重启数据库时数据不会丢失。
优点： 提高写入效率
不足： 数据安全性不能得到保障。 由于没有wal 流复制从库不能同步
应用场景：
数据可丢失，如频繁更新，只保留最后状态信息的表。
导入表数据，后将表改为正常表。
使用 -- 创建unlogged table,与创建普通的表类似。加个unlogged 关键字 postgres=# create unlogged table ult (id int,name text); CREATE TABLE postgres=# \d+ ult 不记录日志的表 &amp;quot;public.ult&amp;quot; 栏位 | 类型 | 校对规则 | 可空的 | 预设 | 存储 | 统计目标 | 描述 ------+---------+----------+--------+------+----------+----------+------ id | integer | | | | plain | | name | text | | | | extended | | -- 将普通表与unlogged table 之间转换 postgres=# alter table ult set logged ; ALTER TABLE postgres=# \d+ ult 数据表 &amp;quot;public.</description>
    </item>
    
    <item>
      <title>误操作闪回</title>
      <link>https://zhangeamon.top/postgres/reback/</link>
      <pubDate>Mon, 11 Jan 2021 17:19:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/reback/</guid>
      <description>原理 利用mvcc原理，数据在删除或更新时只是标记为删除。当没有发生过gc时历史数据仍然存在。只是对当前事务不可见。
通过修改当前事务号为误操作前的事务号就可以看到历史数据。
例如 T1 （添加数据） T2 - T8（其他操作） T9（删除了T1加入的数据）T10&amp;hellip; (其他操作)。 自需要将当前事务号修改为T1之后T9之前的任何时刻都可以看到T1 加入的数据。
前提：误操作表在误操作后没有发生过gc
select last_vacuum , last_autovacuum from pg_stat_all_tables where = ?;  修改方法：利用pg_resetwal工具重置当前事务号
注意： 尽快将找到的数据导出，随着当前数据库事务号增加，数据将再次不可见，T10 也会同样不可见。
示例 通过pg_xlogdump找到误删的事务号（xid），停止数据库，然后重置xlog，启动数据库，数据就是重置的xid位置可见
模拟事故现场
-- 创建测试表 postgres=# create table reback_t (i int); postgres=# select txid_current(); txid_current -------------- 26913040 (1 行记录) -- 模拟业务插入数据 postgres=# insert into reback_t values (1); INSERT 0 1 postgres=# insert into reback_t values (2); INSERT 0 1 postgres=# insert into reback_t values (3); INSERT 0 1 postgres=# insert into reback_t values (4); INSERT 0 1 postgres=# select txid_current(); txid_current -------------- 26913045 (1 行记录) postgres=# insert into reback_t values (5); INSERT 0 1 postgres=# insert into reback_t values (6); INSERT 0 1 postgres=# insert into reback_t values (7); INSERT 0 1 postgres=# insert into reback_t values (8); INSERT 0 1 postgres=# insert into reback_t values (9); INSERT 0 1 postgres=# insert into reback_t values (10); INSERT 0 1 postgres=# select txid_current(); txid_current -------------- 26913052 (1 行记录) -- 误删除数据,事故点 postgres=# delete from reback_t where i &amp;lt; 4; DELETE 3 -- 在线业务继续 postgres=# insert into reback_t values (11); INSERT 0 1 postgres=# insert into reback_t values (12); INSERT 0 1 postgres=# insert into reback_t values (13); INSERT 0 1 postgres=# select * from reback_t ; i ---- 4 5 6 7 8 9 10 11 12 13 (10 行记录) postgres=# \q  停服闪退 [root@pg-d data]# systemctl stop postgresql-10 回退到指定事务号 [root@pg-d data]# su postgres -c &amp;quot;/usr/pgsql-10/bin/pg_resetwal -x 26913047 -D /var/lib/pgsql/10/data/&amp;quot; Write-ahead log reset 建议使用 --single 维护模式启动数据库  查看回退效果, 1,2 又可见 postgres=# select * from reback_t ; i --- 1 2 3 4 5 (5 行记录) 事务号 +1 postgres=# select txid_current(); txid_current -------------- 26913047 (1 行记录) postgres=# select * from reback_t ; i --- 1 2 3 4 5 6 (6 行记录) -- 其他操作 , 事务继续向前。。。 postgres=# insert into reback_t values (21); INSERT 0 1 postgres=# select * from reback_t ; i ---- 1 2 3 4 5 6 7 8 21 (9 行记录) -- 当事务号增长到事故点26913053时，事故再次重现 postgres=# select * from reback_t ; i ---- 3 4 5 6 7 8 21 (7 行记录)  -- 事务真相 postgres=# select xmin,xmax,* from reback_t ; xmin | xmax | i ----------+------+---- 26913044 | 0 | 4 26913046 | 0 | 5 26913047 | 0 | 6 26913048 | 0 | 7 26913049 | 0 | 8 26913050 | 0 | 9 26913051 | 0 | 10 26913054 | 0 | 11 26913055 | 0 | 12 26913049 | 0 | 21  思考 trunce 后是否能够闪回</description>
    </item>
    
    <item>
      <title>高级SQL</title>
      <link>https://zhangeamon.top/postgres/high_level_sql/</link>
      <pubDate>Mon, 11 Jan 2021 17:05:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/high_level_sql/</guid>
      <description>分组集 排序集 假象集 窗口函数 递归  递归应用 递归加速count(distint) 查询。 使用场景，数据分布：大数据集但其中的类型却很少
-- 创建表 test1=# create table recurive_t(user_id int,free float,info text); CREATE TABLE -- 加入数据 test1=# insert into recurive_t select 1 ,generate_series(0,1000000),&#39;user 1 pay !!!&#39;; test1=# insert into recurive_t select 2 ,generate_series(0,2000000),&#39;user 2 pay !!!&#39;; test1=# insert into recurive_t select 3 ,generate_series(0,3000000),&#39;user 3 pay !!!&#39;; test1=# insert into recurive_t select 4 ,generate_series(0,4000000),&#39;user 4 pay !!!&#39;; test1=# insert into recurive_t select 5 ,generate_series(0,4000000),&#39;user 5 pay !</description>
    </item>
    
    <item>
      <title>数据库优化思考 - 结构设计</title>
      <link>https://zhangeamon.top/postgres/thinking_in_db_fd/</link>
      <pubDate>Mon, 11 Jan 2021 10:10:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/thinking_in_db_fd/</guid>
      <description>DB 与 APP 的不同 有无状态 无状态应用，每个实例提供的服务都是等价、对等的。APP 应用为无状态应用，DB应用为有状态应用。
数据库正是因为有状态，所以维护起来更有挑战。
APP 在面对大量高并发请求时可以无所顾及的增加实例，加机器进行扩容。处理能里也会将得到线性提升。简单粗暴又有效。
DB 面对同样的压力挑战时正因为其有状态，扩容起来就没有那么从容。因为当前的请求携带的信息需要与已有的数据进行融合累积。
状态不仅要考虑当前状态，还需要考虑历史状态。因为数据是累积的。
 当前状态 历史状态  如交易订单，当前订单信息，累积账单信息
同样面临的挑战还有比如高可用（当前状态），迁移（历史状态）。在线扩容、不停机迁移，升级,维护（当前状态+历史状态）。
比如电脑新装系统、新购置手机，有一个顾虑就是里面的数据需要拷贝到新系统里。搬家头疼的也是东西太多了。
综上所述，由于DB应用具有当前状态、历史状态属性，DB在高压下面临的真正挑战，
可归结为吞吐量（QPS）挑战，存储量（SIZE）挑战。
认清DB真正面对的挑战 QPS（QPS+TPS） + SIZE (历史累积 + 增长速度)。要缓解数据库压力，下面将从qps、size两个方面来进一步思考解决之道。
进一步思考，QPS 与 SIZE 之间亦相互影响。
tps 加速SIZE 增长
SIZE 增大QPS下降
取舍策略： 时间换空间，空间换时间。
多Master方案 多master，即可多写。能够解决以上两个问题吗？
tps 表面来看将写的压力分散到多个实例来处理，分担了总体压力。但是要保持多个实例数据的一致性。强一致性下多个实例都要处理完成才返回结果。
tps的角度来分析，单个实例的处理量并没有减少，反而可能产生相互等待。即使是最终一致性，tps总量也没有没减少。
可以降低的是单机所承担的qps。
可能多个实例之间由协议来完成实例间的数据同步，但是对tps性能来说影响也是负面的。对size来说也没带来好处。
多master带来的优势更多的是高可用，或类似CDN多机房本地优先处理。
总结： 多master方案 在tps和size 两个方面都不能做到缓解服务压力的作用
伪命题。随着机器增加复杂难度指数上升。mysql 最新8.0 多master方案官方不建议生产环境中使用。
现有方案： bucardo 同步通过触发器来记录变化 、 自身逻辑复制。
注意问题，多写造成多实例之间的写循环。
读写分离 读写分离的核心是将读请求与写请求分开来处理，请求=qps+tps。master只处理写请求，由slave来处理读请求。
通常在现实的TP生产环境中，读请求往往是写请求的数倍或数十倍。这样通过一主多从的方式可以非常有效的将请求分散到多个实例，增加从库也比较容易实现。
将数据库的读请求分离开来对写的影响也会产生积极的作用，因为读写都会占有IO资源，CPU资源。将读请求分到其他实例，资源完全交给写处理，写的性能进而会得到极大的提升。
总结： 读写分离解决的是并发请求量qps，对SIZE方面的问题没有得到解决
现有方案： 数据库流复制，应用层通常框架自带读写路由功能。 如jdbc不仅有路由功能，还可以自动识别主从</description>
    </item>
    
    <item>
      <title>auto vacuum 触发机制</title>
      <link>https://zhangeamon.top/postgres/auto_vacuum_trigger/</link>
      <pubDate>Fri, 08 Jan 2021 09:20:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/auto_vacuum_trigger/</guid>
      <description>数据库自动垃圾回收触发条件分析 在postgres 中 垃圾回收的重要意义及在执行垃圾回收时具体都做了些什么很多地方都有介绍。
但是何时触发垃圾回收，即垃圾回收的触发条件是什么。
官网的介绍一般是有如下几个参数决定
#autovacuum = on # Enable autovacuum subprocess? &#39;on&#39; #autovacuum_vacuum_threshold = 50 # min number of row updates before vacuum #autovacuum_analyze_threshold = 50 # min number of row updates before analyze #autovacuum_vacuum_scale_factor = 0.2 # fraction of table size before vacuum #autovacuum_analyze_scale_factor = 0.1 # fraction of table size before analyze #autovacuum_freeze_max_age = 200000000 # maximum XID age before forced vacuum  大概意思 当表中的数据更新为总数量的20% 是触发垃圾回收，但是当表中总数量小于50的时候20%来的太容易了，</description>
    </item>
    
    <item>
      <title>分区表</title>
      <link>https://zhangeamon.top/postgres/partition/</link>
      <pubDate>Thu, 31 Dec 2020 10:17:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/partition/</guid>
      <description>分区表 数据库分区是一种将数据做物理分片的数据库设计技术，虽然分区技术可以有多种实现方法，
但其主要目的是为了在特定的SQL操作中减少数据读取的总量以缩减响应时间。
分区方式  水平分区
  订单按时间维度
 垂直分区  范式规范 ： 订单数据 （客户表，商品表，订单表）
优点  性能 ，范围或点查询。 管理 归档，删除 统计信息，vacuum  注意事项  默认分区 索引操作，对字表无效 分区键更新 主键，唯一键约束。 全局还是子表有效。(唯一键+分区键)  普通表转换为分区表  pg 版本 &amp;lt; 12 利用pathman 可在线平滑转换 pg 版本 &amp;gt;=12 原始方式 思路：1 新建一张结构完全相同的表，2 将原表作为新表子表 ，3 修改对换表名 （过程加锁）  更多 PPT 下载</description>
    </item>
    
    <item>
      <title>跨库操作</title>
      <link>https://zhangeamon.top/postgres/pg_fdw/</link>
      <pubDate>Thu, 24 Dec 2020 09:11:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_fdw/</guid>
      <description>dblink
https://www.cnblogs.com/lottu/p/13331387.html
fdw
https://www.cnblogs.com/lottu/p/13345187.html
注意事项
 查询条件下推，新版本功能更全
 ddl 操作 , fdw 如果用于历史归档
  </description>
    </item>
    
    <item>
      <title>找回supper user 权限</title>
      <link>https://zhangeamon.top/postgres/reback_supper_user/</link>
      <pubDate>Tue, 22 Dec 2020 17:12:53 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/reback_supper_user/</guid>
      <description> 背景 意外删除postgres supper user 权限
找回方法 关闭数据库 用单用户模式重新启动
/usr/lib/postgresql/xxxx/bin/postgres --single -D $PGDATA  重新设置supper user 权限
alter user postgres with superuser;  </description>
    </item>
    
    <item>
      <title>数据库监控指标</title>
      <link>https://zhangeamon.top/postgres/monitor_explain/</link>
      <pubDate>Fri, 20 Nov 2020 14:46:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/monitor_explain/</guid>
      <description>实体机  硬盘空间 cup利用率 内存利用率 IO 网络带宽 tcp连接情况 温度  数据库年龄  -- 数据库database 年龄 select datname,age(datfrozenxid),pg_size_pretty(pg_database_size(oid)) from pg_database order by age(datfrozenxid) desc limit 10 ; -- 表年龄 select relname,age(relfrozenxid), pg_size_pretty(pg_table_size(oid)) from pg_class where relkind in (&#39;t&#39;,&#39;r&#39;) order by age(relfrozenxid) desc limit 10; 说明： 当age到达2亿（默认）时触发自动回卷，期间会大量占用系统资源。提前做好监控避免在业务高峰时发生。可在库级别操作，也可在表基本操作。 VACUUM ANALYZE VERBOSE ;  垃圾回收 -- 表空间膨胀率, 死元组 select relname,size,ratio from monitor.pg_table_bloat;  视图定义 -见
-- 垃圾回收开始时间结束时间 进程数  WAL --- 过去5分钟内生成wal个数 select count(1) from pg_catalog.</description>
    </item>
    
    <item>
      <title>kylin系统postgresql编译安装</title>
      <link>https://zhangeamon.top/postgres/compile_kylin/</link>
      <pubDate>Mon, 16 Nov 2020 15:26:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/compile_kylin/</guid>
      <description>背景 麒麟系统默认自带postgresql10.5
安装过程与centos基本相同 ,
注意事项
1 安装postgresql-dev
2 编译 postgis 时./configure &amp;ndash;with-pgconfig=/usr/bin/pg_config
但是如果想安装其他版本的postgres 需一番周折
首先第一个问题麒麟系统对openssl过进行改造。在编译postgres支持ssl时不能通过。
其次安装postgres其他拓展也需要解决好各个安装包之间的依赖关系。编译的过程也比较漫长。
银河麒麟V10编译安装postgresql12.5 安装openssl 麒麟v10 版操作系统openssl 被指定义安装在内核中。在安装postgresql时支持openssl编译不能通过。
解决思路，独立安装openssl,postgres对ssl 的依赖指向独立安装的openssl
查看原有版本 openssl version 下载并安装对应版本的openssl wget https://www.openssl.org/source/openssl-1.1.1d.tar.gz tar -zxf openssl-1.1.1d.tar.gz cd openssl-1.1.1d/ ./config --prefix=/usr/local/openssl no-zlib  依赖包安装 yum install openldap-devel yum install systemd-devel -y  安装postgres tar -zxf postgresql-12.5.tar.gz 指定openssl 路径 ./configure --with-openssl --with-includes=/usr/local/openssl/include/openssl --with-libraries=/usr/local/openssl/lib/ --with-systemd ./configure &#39;--enable-rpath&#39; &#39;--prefix=/usr/pgsql-12&#39; &#39;--includedir=/usr/pgsql-12/include&#39; &#39;--libdir=/usr/pgsql-12/lib&#39; &#39;--mandir=/usr/pgsql-12/share/man&#39; &#39;--datadir=/usr/pgsql-12/share&#39; &#39;--with-icu&#39; &#39;--with-llvm&#39; &#39;--with-perl&#39; &#39;--with-python&#39; &#39;--with-tcl&#39; &#39;--with-tclconfig=/usr/lib64&#39; &#39;--with-openssl&#39; &#39;--with-pam&#39; &#39;--with-gssapi&#39; &#39;--with-includes=/usr/include:/usr/local/openssl/include/openssl&#39; &#39;--with-libraries=/usr/lib64:/usr/local/openssl/lib&#39; &#39;--enable-nls&#39; &#39;--enable-dtrace&#39; &#39;--with-uuid=e2fs&#39; &#39;--with-libxml&#39; &#39;--with-libxslt&#39; &#39;--with-ldap&#39; &#39;--with-selinux&#39; &#39;--with-systemd&#39; &#39;--with-system-tzdata=/usr/share/zoneinfo&#39; &#39;--sysconfdir=/etc/sysconfig/pgsql&#39; &#39;--docdir=/usr/pgsql-12/doc&#39; &#39;--htmldir=/usr/pgsql-12/doc/html&#39; &#39;CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic&#39; &#39;LDFLAGS=-Wl,--as-needed&#39; &#39;LLVM_CONFIG=/usr/lib64/llvm5.</description>
    </item>
    
    <item>
      <title>Ubuntu 20.04 网络配置</title>
      <link>https://zhangeamon.top/linux/ubuntu2004-network/</link>
      <pubDate>Mon, 21 Sep 2020 16:48:24 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/ubuntu2004-network/</guid>
      <description> 配置 vim /etc/netplan/00-installer-config.yaml
# This is the network config written by &#39;subiquity&#39; network: ethernets: enp2s0: addresses: - 192.168.6.111/24 gateway4: 192.168.6.1 nameservers: addresses: [119.29.29.29] version: 2  生效 netplan apply  </description>
    </item>
    
    <item>
      <title>创建只读用户</title>
      <link>https://zhangeamon.top/postgres/readonly/</link>
      <pubDate>Tue, 08 Sep 2020 09:28:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/readonly/</guid>
      <description>1.创建一个用户名为readonly密码为ropass的用户 CREATE USER readonly WITH ENCRYPTED PASSWORD &#39;ropass&#39;; 2.用户只读事务 alter user readonly set default_transaction_read_only=on; 3.把所有库的语言的USAGE权限给到readonly GRANT USAGE ON SCHEMA public to readonly; 4.授予select权限(这句要进入具体数据库操作在哪个db环境执行就授予那个db的权) grant select on all tables in schema public to readonly;  </description>
    </item>
    
    <item>
      <title>文档</title>
      <link>https://zhangeamon.top/dw/document/</link>
      <pubDate>Tue, 25 Aug 2020 10:25:55 +0800</pubDate>
      
      <guid>https://zhangeamon.top/dw/document/</guid>
      <description>https://ask.greenplum.cn</description>
    </item>
    
    <item>
      <title>go grpc</title>
      <link>https://zhangeamon.top/go/grpc/</link>
      <pubDate>Thu, 13 Aug 2020 10:06:19 +0800</pubDate>
      
      <guid>https://zhangeamon.top/go/grpc/</guid>
      <description>python 实现
cat Server.py
from SimpleXMLRPCServer import SimpleXMLRPCServer def fun_add(a,b): total = a+b return total if __name__==&#39;__main__&#39;: s = SimpleXMLRPCServer((&#39;0.0.0.0&#39;,8081)) s.register_function(fun_add) print &amp;quot;server in on line&amp;quot; s.serve_forever()  cat Client.py
from xmlrpclib import ServerProxy s = ServerProxy(&amp;quot;http://xx.xxx.xxx.xxx:8081&amp;quot;) print s.fun_add(1,2)  go 实现</description>
    </item>
    
    <item>
      <title>API 自动化测试</title>
      <link>https://zhangeamon.top/istio/auto-api-test/</link>
      <pubDate>Tue, 21 Jul 2020 15:22:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/istio/auto-api-test/</guid>
      <description>简介 主要用于Restful风格接口测试,指针对模块或系统间接口进行的测试
 单一接口测试
 多接口组合逻辑测试
 定时自动，生成测试报告
 失败通知
  测试用例断言
 返回状态码
 返回结果
 超时时间
  基础应用需求  Postman 测试用例编写
 Newman 执行测试用例命令行工具
 Jenkins 自动化集成
 Git 测试用例成果物管理
 Allure 生成测试报告
 TestLink 测试用例管理
  目标  定时自动或手动触发测试,并生成测试报告
 测试结果有异常情况通知相关人员
 通过环境变量自适配生产或测试环境
 可自定义批量传入参数
  具体测试 接口测试经常遇到的bug和问题 （1）传入参数处理不当，导致程序crash； n/0; 参数边界
（2）类型溢出，导致数据读出和写入不一致；
（3）因对象权限未进行校验，可以访问其他用户敏感信息；
（4）状态处理不当，导致逻辑出现错乱；
（5）逻辑校验不完善，可利用漏洞获取非正当利益等。
接口测试设计 1)、通用接口用例设计
①、通过性验证：首先肯定要保证这个接口功能是好使的，也就是正常的通过性测试，按照接口文档上的参数，正常传入，是否可以返回正确的结果。
②、参数组合：
③、接口安全：
1、绕过验证，比如说购买了一个商品，它的价格是300元，那我在提交订单时候，我把这个商品的价格改成3元，后端有没有做验证，更狠点，我把钱改成-3，是不是我的余额还要增加?
2、绕过身份授权，比如说修改商品信息接口，那必须得是卖家才能修改，那我传一个普通用户，能不能修改成功，我传一个其他的卖家能不能修改成功</description>
    </item>
    
    <item>
      <title>vagrant</title>
      <link>https://zhangeamon.top/kvm/vagrant/</link>
      <pubDate>Mon, 13 Jul 2020 09:32:49 +0800</pubDate>
      
      <guid>https://zhangeamon.top/kvm/vagrant/</guid>
      <description>介绍 通常用vagrant 来管理VirtualBox ,VMWare，方便测试环境的创建，销毁。不常折腾用virtualbox, 反复折腾用vagrant。
简单使用 安装 下载virtualbox
下载vagrant
-- 安装依赖 #yum --enablerepo=epel -y install fuse-sshfs #yum install bsdtar #yum -y install gcc kernel kernel-devel  常用方法 --- 镜像管理 添加镜像 #vagrant box add centos/7 查看镜像 #vagrant box list centos/7 (virtualbox, 2004.01) -- 配置管理 初始化默认Vagrantfile #vagrant init 配置Vagrantfile定义虚拟机 , 启动虚拟机 #vagrant up 查看状态 #vagrant status Current machine states: node0 running (virtualbox) node1 running (virtualbox) node2 running (virtualbox) node3 running (virtualbox) 登录虚拟机 #vagrant ssh node0 关闭 #vagrant halt 停止并销毁 #vagrant destroy 重新加载,重启 #vagrant reload  注意事项 将当前路径的所有内容同步到虚拟机内 Rsyncing folder: /当前路径 =&amp;gt; /vagrant   box manages boxes: installation, removal, etc.</description>
    </item>
    
    <item>
      <title>数据库 OOM 预防</title>
      <link>https://zhangeamon.top/postgres/oom/</link>
      <pubDate>Tue, 30 Jun 2020 09:26:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/oom/</guid>
      <description>降低主进程被OOM kill 掉的风险 1. restart_after_crash 默认崩溃重启
postgres=# show restart_after_crash; restart_after_crash --------------------- on (1 row)  2. vm.overcommit # vi /etc/sysctl.conf # 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程 # 1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何 # 2 表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 2 vm.overcommit_ratio = 90 # overcommit_memory= 2 时生效 vm.swappiness = 1 # 交换分区 # sysctl -p  3. oom_score_adj oom_score_adj 的取值范围为 -1000 到 1000，值越大，被os干掉的风险越大。
启动前设置
#vi /usr/lib/systemd/system/postgresql-10.service # Disable OOM kill on the postmaster OOMScoreAdjust=-1000 Environment=PG_OOM_ADJUST_FILE=/proc/self/oom_score_adj Environment=PG_OOM_ADJUST_VALUE=0  启动后设置</description>
    </item>
    
    <item>
      <title>Consul DNS 服务发现</title>
      <link>https://zhangeamon.top/middleware/consul/</link>
      <pubDate>Mon, 29 Jun 2020 11:09:52 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/consul/</guid>
      <description>实现目标  多IP解析，负载轮询 自动检查后端服务状态，自动剔除不可用后端 别名配置 上游DNS支持 ttl cache 支持  前两点由cousul实现
后两点由dnsmasq实现
别名配置未实现
简单应用 集群配置
10.1.88.84
10.1.88.85
10.1.88.86
consul agent -server -bootstrap-expect=3 -data-dir=/tmp/consul -node=10.1.88.84 -bind=10.1.88.84 -client=0.0.0.0 -datacenter=bj -domain=zhangeamon.com -config-dir=/etc/consul.d -ui consul agent -server -bootstrap-expect=3 -data-dir=/tmp/consul -node=10.1.88.85 -bind=10.1.88.85 -client=0.0.0.0 -datacenter=bj -domain=zhangeamon.com -join=10.1.88.84 -config-dir=/etc/consul.d -ui consul agent -server -bootstrap-expect=3 -data-dir=/tmp/consul -node=10.1.88.86 -bind=10.1.88.86 -client=0.0.0.0 -datacenter=bj -domain=zhangeamon.com -join=10.1.88.84 -config-dir=/etc/consul.d -ui  服务发现配置
cat /etc/consul.d/web/json
{ &amp;quot;services&amp;quot;:[ { &amp;quot;id&amp;quot;: &amp;quot;web01&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;web&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;10.1.88.84&amp;quot;, &amp;quot;tags&amp;quot;: [ &amp;quot;rails&amp;quot; ], &amp;quot;check&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;SSH&amp;quot;, &amp;quot;tcp&amp;quot;: &amp;quot;10.</description>
    </item>
    
    <item>
      <title>coredns</title>
      <link>https://zhangeamon.top/middleware/coredns/</link>
      <pubDate>Mon, 22 Jun 2020 13:25:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/coredns/</guid>
      <description>背景 致力于打造云原生中的dns服务和服务发现。
各种功能都是通过插件方式实现
简单例子 服务
cat /usr/lib/systemd/system/coredns.service
[Unit] Description=CoreDNS DNS server Documentation=https://coredns.io After=network.target [Service] PermissionsStartOnly=true LimitNOFILE=1048576 LimitNPROC=512 CapabilityBoundingSet=CAP_NET_BIND_SERVICE AmbientCapabilities=CAP_NET_BIND_SERVICE NoNewPrivileges=true User=coredns WorkingDirectory=~ ExecStart=/usr/local/bin/coredns -conf=/etc/coredns/Corefile ExecReload=/bin/kill -SIGUSR1 $MAINPID Restart=on-failure [Install] WantedBy=multi-user.target  配置文件 cat /etc/coredns/Corefile
.:53 { # 绑定interface ip bind 127.0.0.1 # 先走本机的hosts # https://coredns.io/plugins/hosts/ hosts { # 自定义sms.service search.service 的解析 # 因为解析的域名少我们这里直接用hosts插件即可完成需求 # 如果有大量自定义域名解析那么建议用file插件使用 符合RFC 1035规范的DNS解析配置文件 10.6.6.2 sms.service 10.6.6.3 search.service # ttl ttl 60 # 重载hosts配置 reload 1m # 继续执行 fallthrough } # 通过 curl localhost:9253/metrics 获取监控指标 # 插件 prometheus localhost:9253 # file enables serving zone data from an RFC 1035-style master file.</description>
    </item>
    
    <item>
      <title>Redis 6.0安装配置管理</title>
      <link>https://zhangeamon.top/redis/install/</link>
      <pubDate>Fri, 12 Jun 2020 14:48:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/redis/install/</guid>
      <description>安装 yum 方式
yum install -y http://rpms.famillecollet.com/enterprise/remi-release-7.rpm yum --enablerepo=remi install redis  make 方式
升级gcc 版本临时生效,否则编译错误 yum -y install centos-release-scl yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils scl enable devtoolset-9 bash  wget http://download.redis.io/releases/redis-6.0.1.tar.gz tar -xvf redis-6.0.1.tar.gz cd /usr/local/redis-6.0.1/ make PREFIX=/usr/local/redis install  启动 systemctl start redis systemctl enalbe redis  配置 系统参数 vi /etc/sysctl.conf
net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 kernel.shmmax = 68719476736 kernel.shmall = 4294967296 net.core.netdev_max_backlog = 262144 net.</description>
    </item>
    
    <item>
      <title>服务发现</title>
      <link>https://zhangeamon.top/istio/servicediscovery/</link>
      <pubDate>Fri, 05 Jun 2020 10:19:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/istio/servicediscovery/</guid>
      <description>为什么需要服务发现 在传统的服务架构中，服务之间的依赖关系较为简单，服务部署的位置也通常不会变化。
前段的服务通常配置来发现后端服务具体的IP或端口。比如后端的服务原来部署在10.1.10.2的5522端口上，现在如果想把服务部署在10.1.10.3的5523端口上。
前段和后端都不许要修改，只修改对应的配置文件就可以了。通过管理配置文件就可以很容易实现运维管理。
而现在的微服务中一切都变得复杂些。 提供一个服务后端可能是大量的实例，往往还需要扩容，缩容等。版本的滚动升级等。变化成为一种常态。甚至具体部署在那个机器上都部署固定的，
甚至需要与机器的负载程度，资源利用情况等有关。
如果还使用手动的方式通过修改配置文件来管理就显得繁琐，且容易出错。
服务发现用来做什么 传统方式通过配置来实现前后端的解耦，路由。 频繁大量的对配置的更改已很难满足现在的架构，业务及迭代需求。
服务发现帮你解放双手，后端服务只需在启动的时候注册自己就可以了。服务发现会自动帮你加入到业务复杂中。
结合健康检测，如果后端服务异常可自动剔除。
结合轮询调度实现负载均衡，对前段调度者来说无需关心具体有多少个后端提供服务。逻辑上只有一个，调就完了。</description>
    </item>
    
    <item>
      <title>Firewall</title>
      <link>https://zhangeamon.top/network-security/firewalld/</link>
      <pubDate>Wed, 03 Jun 2020 16:15:35 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/firewalld/</guid>
      <description>简单应用 服务管理 # 查看全部支持的服务 $ firewall-cmd --get-service # 查看开放的服务 $ firewall-cmd --list-service # 开放服务 $ firewall-cmd --add-service=postgresql --permanent # 关闭服务 $ firewall-cmd --remove-service=postgresql --permanent  permanent 参数修改对应的配置文件 /etc/firewalld/zones/public.xml
端口管理 # 查看开放的端口 $ firewall-cmd --zone=public --list-ports # 开放指导端口 $ firewall-cmd --zone=public --add-port=80/tcp --permanent # 开放端口段 $ firewall-cmd --zone=public --add-port=8388-8389/tcp --permanent # 关闭端口 $ firewall-cmd --zone=public --remove-port=80/tcp --permanent  规则管理 # 对 147.152.139.197 开放10000端口 $ firewall-cmd --permanent --zone=public --add-rich-rule=&#39; rule family=&amp;quot;ipv4&amp;quot; source address=&amp;quot;147.</description>
    </item>
    
    <item>
      <title>数据库 ssl认证</title>
      <link>https://zhangeamon.top/postgres/ssl/</link>
      <pubDate>Wed, 03 Jun 2020 15:06:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/ssl/</guid>
      <description>SSL双向认证和SSL单向认证的区别 双向认证 SSL 协议要求服务器和用户双方都有证书。单向认证 SSL 协议不需要客户拥有CA证书，服务器端不会验证客户证书，以及在协商对称密码方案，对称通话密钥时，服务器发送给客户的是没有加过密的(这并不影响 SSL 过程的安全性)密码方案。
这样，双方具体的通讯内容，都是加过密的数据，如果有第三方攻击，获得的只是加密的数据，第三方要获得有用的信息，就需要对加密的数据进行解密，这时候的安全就依赖于密码方案的安全。
而幸运的是，目前所用的密码方案，只要通讯密钥长度足够的长，就足够的安全。这也是我们强调要求使用128位加密通讯的原因。
一般Web应用都是采用SSL单向认证的，原因很简单，用户数目广泛，且无需在通讯层对用户身份进行验证，一般都在应用逻辑层来保证用户的合法登入。但如果是企业应用对接，情况就不一样，可能会要求对客户端(相对而言)做身份验证。这时就需要做SSL双向认证。
由于单向认证和双向认证的区别仅在于创建连接阶段，数据的传输均为加密的，因此客户端与PG服务端的连接采取SSL单向认证即可，即仅在PG Server端配置SSL证书。
生成自签名证书  server.key – 私钥 server.crt – 服务器证书 root.crt – 受信任的根证书  创建私钥 ， 需要密码，随意输入 openssl genrsa -des3 -out server.key 1024 删除密码 openssl rsa -in server.key -out server.key 修改权限 chmod 400 server.key  创建基于server.key文件的服务器证书 有效期十年 openssl req -new -key server.key -days 3650 -out server.crt -x509  查看证书 openssl x509 -in server.crt -text -noout  为了得到自己签名的证书，把生成的服务器证书作为受信任的根证书，只需要复制并取一个合适的名字 cp server.</description>
    </item>
    
    <item>
      <title>工作中所使用的postgres</title>
      <link>https://zhangeamon.top/postgres/awsome-postgres/</link>
      <pubDate>Wed, 27 May 2020 11:34:24 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/awsome-postgres/</guid>
      <description>Postgres 实际应用概览
 MVCC 多版本控制  一个绕不开的话题， 主要是对抗表空间的膨胀。解决垃圾回收问题，主从库之间从库查询冲突问题。
目前方法每日低峰期定时 vaccum ，gocron自定定时任务 。 根据pgstattuple对磁盘空间利用率进行分析。决定是否vaccum full ,pg_repack
 流复制  主从复制，读写分离的基础。五种同步方式
 逻辑订阅  大版本升级，数据并归。迁移
 执行计划调优  调节成本因子比例，如不同的磁盘类型比例有所区别
 参数调优  主机 和 服务
 分区表  采用pg_pathman ,因为都是根据业务数据量来决定是否分区。pg_pathman 能够不停服的前提下自动分区数据。
 高可用  patroni
 分表  citus 注意亲和性 和表之间的join ddl 等限制。
 监控，日志  promethues 套件，自定义监控项 。 filebeat elasticsearch kibana 日志收集
 统计  结合数据库自带的统计信息及pg_stat_statements 插件生产报表
 压测  pg_bench ,自定义sql</description>
    </item>
    
    <item>
      <title>数据预加载</title>
      <link>https://zhangeamon.top/postgres/pg_prewarm/</link>
      <pubDate>Wed, 27 May 2020 10:26:10 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_prewarm/</guid>
      <description>https://blog.csdn.net/Hehuyi_In/article/details/102653909</description>
    </item>
    
    <item>
      <title>Centos7 私有源搭建</title>
      <link>https://zhangeamon.top/linux/repo/</link>
      <pubDate>Tue, 19 May 2020 10:32:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/repo/</guid>
      <description> 介绍 为了保证IDC内所有主机版本一致。
目前问题， 当主机执行yum update 时，软件版本不可控。每个主机版本完全取决于更新的时机。
造成了同一个IDC内的版本的差异，比如有的数据库的版本为10.06,有的为10.13。尤其是使用了如postgis等拓展的时候。版本混乱，甚至主从之间都不一致。
实现方法 思路 一台机器做源服务统一管理所有软件的版本，更新策略（私有源服务中心）。其他主机指向私有源。
方法  reposync , yumdownloader 下载源，将远程服务源下载到本地 nginx 将本地源对外提供服务 createrepo 生成本地源  </description>
    </item>
    
    <item>
      <title>带宽检测 - iperf</title>
      <link>https://zhangeamon.top/linux/iperf/</link>
      <pubDate>Tue, 12 May 2020 16:37:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/iperf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jdango 多数据库读写配置</title>
      <link>https://zhangeamon.top/python/django-ndb/</link>
      <pubDate>Tue, 12 May 2020 11:28:53 +0800</pubDate>
      
      <guid>https://zhangeamon.top/python/django-ndb/</guid>
      <description>https://www.cnblogs.com/thismyblogs/p/9855801.html</description>
    </item>
    
    <item>
      <title>Centos 登陆安全管理</title>
      <link>https://zhangeamon.top/network-security/linux-user-passw/</link>
      <pubDate>Sat, 09 May 2020 16:20:05 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/linux-user-passw/</guid>
      <description>禁用root登陆 注意： 创建一个非root用户 并加入wheel用户组（拥有sudo权限）
useradd NewUser passwd NewUser gpasswd -a NewUser wheel  本地禁用root登陆 修改/etc/pam.d/login文件增加下面一行
auth required pam_succeed_if.so user != root quiet  远程禁用root登陆 修改 /etc/ssh/sshd_config
#PermitRootLogin yes PermitRootLogin no  修改ssh默认端口 修改 /etc/ssh/sshd_config
#Port 22 Port 46608  安全认证 LoginGraceTime 2m PermitRootLogin no #StrictModes yes #MaxAuthTries 6 #MaxSessions 10  超时退出 例如客户端60秒无操作自动退出
export TMOUT=60  加入系统环境变量中 如：/etc/profile
密码过期时间 修改 /etc/login.defs
PASS_MAX_DAYS 90 #密码最长过期天数 PASS_MIN_DAYS 80 #密码最小过期天数 PASS_MIN_LEN 10 #密码最小长度 PASS_WARN_AGE 7 #密码过期警告天数  登陆错误锁定 使用方式直接使用ssh 密钥登陆 ， 后面的方法自找麻烦 ssh-keygen 生成钥匙 ssh-copy-id 将公钥上传到被访问的服务器 PermitRootLogin without-password 修改sshd_config文件设置禁止root密码登陆 PasswordAuthentication no 修改sshd_config文件禁止普通用户密码登陆  连续密码错误3次锁定账户，普通用户5分钟后解锁，root用户10分钟后解锁</description>
    </item>
    
    <item>
      <title>系统日志 syslog</title>
      <link>https://zhangeamon.top/linux/syslog/</link>
      <pubDate>Sat, 09 May 2020 11:43:18 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/syslog/</guid>
      <description></description>
    </item>
    
    <item>
      <title>日志审计 audit</title>
      <link>https://zhangeamon.top/network-security/audit/</link>
      <pubDate>Fri, 08 May 2020 08:52:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/audit/</guid>
      <description>介绍 auditd是Linux审计系统中用户空间的一个组件，负责将审计记录写到磁盘中。在CentOS7上默认就会有安装这个服务。
如果被卸载，可以直接使用yum进行安装：
yum -y install audit auditd-libs  常用命令 1、auditctl : 即时控制审计守护进程的行为的工具，比如如添加规则等等。 audtitctl -l #查看规则 auditctl -D #清空规则 2、aureport : 查看和生成审计报告的工具。 aureport -l #生成登录审计报告 3、ausearch : 查找审计事件的工具 ausearch -i -p 4096 4、autrace : 一个用于跟踪进程的命令。 autrace -r /usr/sbin/anacron  简单应用 监控文件或者目录的更改 auditctl -w /etc/passwd -p rwxa -k passwd -w path : 指定要监控的路径，上面的命令指定了监控的文件路径 /etc/passwd -p : 指定触发审计的文件或者目录的访问权限 rwxa ： 指定的触发条件，r 读取权限，w 写入权限，x 执行权限，a 属性（attr）  运行这条命令之后就开始监控了，但是机器重启之后就失效了，因此要永久生效就需要写到规则文件里面。 vim /etc/auditd/rules.d/auditd.rules 将auditctl的命令参数写到这个文件里面即可。
重启服务 service auditd restart  systemctl restart auditd 不可用</description>
    </item>
    
    <item>
      <title>等保三指南</title>
      <link>https://zhangeamon.top/network-security/dengbao3/</link>
      <pubDate>Fri, 08 May 2020 08:40:31 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/dengbao3/</guid>
      <description>等保三指南-上
等保三指南-下</description>
    </item>
    
    <item>
      <title>Linux 获取CPU温度</title>
      <link>https://zhangeamon.top/linux/cpu_temp/</link>
      <pubDate>Thu, 07 May 2020 14:02:02 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cpu_temp/</guid>
      <description>直接读取系统信息 可以通过读取如下路径中的数据来获取cpu的温度信息，不过读取的数据没有经过处理。
cpu0： cat /sys/class/thermal/thermal_zone0/temp cpu1： cat /sys/class/thermal/thermal_zone1/temp  通过命令行的方式获取 安装 lm_sensors 软件包：
# rpm yum install lm_sensors  # deb apt-get install lm-sensors  执行命令sensors-detect，进行简单配置，此命令执行后会出现一系列选项，一直yes即可；
执行命令sensors，查看cpu的温度。
sensors i350bb-pci-0200 Adapter: PCI adapter loc1: +42.0°C (high = +120.0°C, crit = +110.0°C)
i350bb-pci-0300 Adapter: PCI adapter loc1: +38.0°C (high = +120.0°C, crit = +110.0°C)
power_meter-acpi-0 Adapter: ACPI interface power1: 4.29 MW (interval = 1.00 s)
coretemp-isa-0000 Adapter: ISA adapter Physical id 0: +31.</description>
    </item>
    
    <item>
      <title>依赖管理工具go module</title>
      <link>https://zhangeamon.top/go/go_mod/</link>
      <pubDate>Thu, 30 Apr 2020 13:25:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/go/go_mod/</guid>
      <description>背景 大多数语言都会有包管理工具，像Node有npm，PHP有composer，Java有Maven和Gradle。
在go1.11 版本中，新增了module管理模块功能，用来管理依赖包
开启module特性 要开始使用 go module 的特性， 需要先设置 GO111MODULE 环境变量。
开启 GO111MODULE
要使用go module,首先要设置GO111MODULE=on
这是因为，默认设置的GO111MODULE=auto, 导致 modules 默认在 GOPATH/src 路径下是不启用的。
如果需要在 GOPATH/src 也能使用modules, 需要把 GO111MODULE 环境变量设置为 on.
export GO111MODULE=on  Goland 中可独立配置，GOPATH GOMOD 使用module Usage: go mod &amp;lt;command&amp;gt; [arguments] The commands are: download download modules to local cache edit edit go.mod from tools or scripts graph print module requirement graph init initialize new module in current directory tidy add missing and remove unused modules vendor make vendored copy of dependencies verify verify dependencies have expected content why explain why packages or modules are needed Use &amp;quot;go help mod &amp;lt;command&amp;gt;&amp;quot; for more information about a command.</description>
    </item>
    
    <item>
      <title>Bloom 索引</title>
      <link>https://zhangeamon.top/postgres/index-bloom/</link>
      <pubDate>Thu, 23 Apr 2020 15:37:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/index-bloom/</guid>
      <description>Bloom 索引 Bloom 过滤器代表的是一组值。它的作用是检测一个元素是否可能属于集合，它可以允许有一些false positive，但是不允许存在false negative。也就是说，尽管某个元素不在集合中，测试也可能返回true。然而，如果元素在集合中，就不可能返回false。 创建在一组列中的Bloom索引可以被用来加速在这些列的子集上用AND相连的等式的查询。
当表具有很多属性并且查询可能会测试其中任意组合时，这种类型的索引最有用。传统的 btree 索引比布鲁姆索引更快，但是需要很多 btree 索引来支持所有可能的查询，而对于布鲁姆索引来说只需要一个即可。
注意: bloom 索引只支持等值查询，而 btree 索引还能执行不等和范围搜索。 创建一个索引 CREATE INDEX bloomidx ON tbloom USING bloom (i1,i2,i3) WITH (length=80, col1=2, col2=2, col3=4);  with 部分可省略
length 每个签名（索引项）的长度位数。默认是80位，最长是4096位。
col1 — col32 从每一个索引列产生的位数。每个参数的名字表示它所控制的索引列的编号。默认是2位，最大是4095位。没有实际使用的索引列的参数会被忽略。
使用例子 http://postgres.cn/docs/10/bloom.html</description>
    </item>
    
    <item>
      <title>Nginx 状态监控</title>
      <link>https://zhangeamon.top/monitor/nginx-status/</link>
      <pubDate>Mon, 20 Apr 2020 11:12:28 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/nginx-status/</guid>
      <description>Nginx 开启status用以监控状态信息 Nginx 可以通过with-http_stub_status_module模块来监控nginx的一些状态信息。
通过nginx -V来查看是否有with-http_stub_status_module该模块。 # nginx -V nginx version: nginx/1.16.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/usr/share/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/var/lib/nginx/tmp/client_body --http-proxy-temp-path=/var/lib/nginx/tmp/proxy --http-fastcgi-temp-path=/var/lib/nginx/tmp/fastcgi --http-uwsgi-temp-path=/var/lib/nginx/tmp/uwsgi --http-scgi-temp-path=/var/lib/nginx/tmp/scgi --pid-path=/run/nginx.pid --lock-path=/run/lock/subsys/nginx --user=nginx --group=nginx --with-file-aio --with-ipv6 --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-stream_ssl_preread_module --with-http_addition_module --with-http_xslt_module=dynamic --with-http_image_filter_module=dynamic --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_slice_module --with-http_stub_status_module --with-http_perl_module=dynamic --with-http_auth_request_module --with-mail=dynamic --with-mail_ssl_module --with-pcre --with-pcre-jit --with-stream=dynamic --with-stream_ssl_module --with-google_perftools_module --with-debug --with-cc-opt=&#39;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic&#39; --with-ld-opt=&#39;-Wl,-z,relro -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -Wl,-E&#39;  修改nginx.</description>
    </item>
    
    <item>
      <title>django 默认创建第二索引</title>
      <link>https://zhangeamon.top/python/django-index-ops/</link>
      <pubDate>Thu, 16 Apr 2020 11:40:02 +0800</pubDate>
      
      <guid>https://zhangeamon.top/python/django-index-ops/</guid>
      <description>Django使用postgresql做数据库 db_index创建索引时会创建第二个索引varchar_pattern_ops问题 创建默认索引 minion_id = models.CharField(max_length=100, db_index=True, blank=True, null=False, default=&amp;quot;&amp;quot;)  当字段类型是 models.CharField 或者 models.TextField 时 使用 db_index=True创建索引 会创建第二索引
django.db.backends.postgresql.schema
class DatabaseSchemaEditor(BaseDatabaseSchemaEditor): sql_alter_column_type = &amp;quot;ALTER COLUMN %(column)s TYPE %(type)s USING %(column)s::%(type)s&amp;quot; sql_create_sequence = &amp;quot;CREATE SEQUENCE %(sequence)s&amp;quot; sql_delete_sequence = &amp;quot;DROP SEQUENCE IF EXISTS %(sequence)s CASCADE&amp;quot; sql_set_sequence_max = &amp;quot;SELECT setval(&#39;%(sequence)s&#39;, MAX(%(column)s)) FROM %(table)s&amp;quot; sql_create_varchar_index = &amp;quot;CREATE INDEX %(name)s ON %(table)s (%(columns)s varchar_pattern_ops)%(extra)s&amp;quot; sql_create_text_index = &amp;quot;CREATE INDEX %(name)s ON %(table)s (%(columns)s text_pattern_ops)%(extra)s&amp;quot; def quote_value(self, value): return psycopg2.</description>
    </item>
    
    <item>
      <title>方法和函数</title>
      <link>https://zhangeamon.top/postgres/functionsandoperators/</link>
      <pubDate>Mon, 13 Apr 2020 16:15:51 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/functionsandoperators/</guid>
      <description>条件表达式 https://www.postgresql.org/docs/10/functions-conditional.html
postgresql支持CASE,COALESCE,NULLIF,GREATEST,LEAST条件表达式，使用它们有时候可以简化许多功能实现。
CASE CASE类似其他语言中的if/else等，当符合不同条件时则进行不同的运算
tbl_001表
create table tbl_001(id int,name varchar(32),sex varchar(1)); insert into tbl_001 values(1,&#39;张三&#39;,&#39;m&#39;),(2,&#39;李四&#39;,&#39;m&#39;),(3,&#39;王五&#39;,&#39;f&#39;);  测试
简单应用 postgres=# select case when sex = &#39;m&#39; then &#39;男&#39; when sex = &#39;f&#39; then &#39;女&#39; else &#39;O&#39; end as sex from tbl_001 ; sex ----- 男 男 女 (3 rows) 统计男女人数 postgres=# select count(sex) as 男 from tbl_001 where sex = &#39;m&#39;; 男 ---- 2 (1 row) postgres=# select count(sex) as 女 from tbl_001 where sex = &#39;f&#39;; 女 ---- 1 (1 row) 使用case 一条搞定 select sum(case when sex = &#39;m&#39; then 1 else 0 end) as 男, sum(case when sex = &#39;f&#39; then 1 else 0 end) as 女 from tbl_001 ; 男 | 女 ----+---- 2 | 1 (1 row)  COALESCE COALESCE(value [, .</description>
    </item>
    
    <item>
      <title>数据库日常管理</title>
      <link>https://zhangeamon.top/postgres/daily_management/</link>
      <pubDate>Tue, 07 Apr 2020 10:38:45 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/daily_management/</guid>
      <description>日常管理  可用性 监测项  可用性  主从 HA 全量备份 增量备份 恢复  监测项 磁盘空间  全库  select pg_size_pretty(sum(pg_database_size(oid))) from pg_database;   数据库  select datname, pg_size_pretty(pg_database_size(oid)) from pg_database order by pg_database_size(oid) desc limit 10;   表总   SELECT table_schema || &#39;.&#39; || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size(&#39;&amp;quot;&#39; || table_schema || &#39;&amp;quot;.&amp;quot;&#39; || table_name || &#39;&amp;quot;&#39;)) AS size FROM information_schema.tables where table_schema = &#39;public&#39; ORDER BY pg_total_relation_size(&#39;&amp;quot;&#39; || table_schema || &#39;&amp;quot;.</description>
    </item>
    
    <item>
      <title>锁等待</title>
      <link>https://zhangeamon.top/postgres/lock_wait/</link>
      <pubDate>Fri, 27 Mar 2020 16:27:02 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/lock_wait/</guid>
      <description>锁等待场景 一个事务尚未执行提交时持有锁，当另一个事务需要持有改行的锁时则需要等待。
Session 1
postgres=# \d+ wt Table &amp;quot;public.wt&amp;quot; Column | Type | Collation | Nullable | Default | Storage | Stats target | Description --------+---------+-----------+----------+---------+----------+--------------+------------- id | integer | | | | plain | | t | text | | | | extended | | postgres=# begin; BEGIN postgres=# update wt set t = &#39;aaaa&#39; where id = 1; UPDATE 1 postgres=# select pg_backend_pid(); pg_backend_pid ---------------- 20034 (1 row)  Session 2</description>
    </item>
    
    <item>
      <title>软件安装</title>
      <link>https://zhangeamon.top/linux/install-cmd/</link>
      <pubDate>Fri, 20 Mar 2020 09:35:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/install-cmd/</guid>
      <description> Centos7 查看是否存在需要安装的软件 yum search xxxx 查看具体版本详情 yum list xxxx 查看已安装 rpm -qa | grep xxxx  安装 yum install xxxx rpm -i xxxx.rpm  删除 yum erase xxxx rpm -r xxxx  Unbuntu 查看是否存在需要安装的软件 apt-cache search xxxx 查看具体版本及信息 apt show xxxx 查看已安装 dpkg -l 安装 apt-get install xxxx dpkg -l 删除 apt-get remove xxxx  </description>
    </item>
    
    <item>
      <title>数据库安装 Postgres12 Ubuntu18</title>
      <link>https://zhangeamon.top/postgres/install02/</link>
      <pubDate>Thu, 19 Mar 2020 15:22:09 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/install02/</guid>
      <description>软件源
echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main&amp;quot; &amp;gt;&amp;gt; /etc/apt/sources.list.d/pgdg.list  wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -  sudo apt-get update -y  安装
apt-get install postgresql-12 postgresql-client-12 postgresql-12-postgis-2.5 postgresql-contrib -y  初始化
/usr/pgsql-12/bin/postgresql-12-setup initdb  启动
systemctl start postgresql systemctl stop postgresql systemctl status postgresql systemctl enable postgresql  配置
cd /etc/postgresql/12/main/ vi postgres.conf vi pg_hba.conf  </description>
    </item>
    
    <item>
      <title>Git 免输入密码</title>
      <link>https://zhangeamon.top/linux/git-nopassword/</link>
      <pubDate>Thu, 19 Mar 2020 15:10:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/git-nopassword/</guid>
      <description>一、配置Git的
git config --global user.name [userName] git config --global user.email [userEmail]  二、配置存储模式
git config --global credential.helper store  执行之后会在linux用户主目录下的.gitconfig文件中多加 helper = store
[user] name = eamonzhang email = xxxx@xxxx.com [credential] helper = store  之后cd到项目目录，执行git pull命令，会提示输入账号密码。输完这一次以后就不再需要，并且会在根目录生成一个.git-credentials文件
三、注意事项
git config --global 全局设置生效  </description>
    </item>
    
    <item>
      <title>数据库年龄</title>
      <link>https://zhangeamon.top/postgres/pgage/</link>
      <pubDate>Tue, 07 Jan 2020 09:47:18 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgage/</guid>
      <description>背景 数据库的事务标识符使用的是32位的,最大可表示42个亿。当前事务的数据在20亿个事务之后将变的不可见。为了解决这个问题（回卷），Postgres引入了一个冻结事务标识的概念。 并实现了名为freeze的冻结过程。
冻结过程 两种模式
 惰性模式
 迫切模式
  惰性模式回跳过页中所有的数据都位可见的数据库块（由数据库中的vm可见性映射）
迫切模式会扫描所有的页，检查表中的所有元组。并可能删除不必要的clog文件与页面。
改进的迫切模式，会跳过页面中所有的元组都已被冻结过的页面
首先介绍几个数据库值
 -- 当前事务号 select txid_current(); -- 记录事务号 select xmax,xmin ,* from table_name where xxxx; -- 表年龄， 表中最老行的事务号 select age(relfrozenxid) from pg_class where relname = table_name; -- database 年龄 select datname , age(datfrozenxid) from pg_database ; -- 数据配置 show vacuum_freeze_min_age ; -- 默认值5千万 show vacuum_freeze_table_age ; -- 默认值1.5亿 show autovacuum_freeze_max_age ; -- 默认值2亿 show autovacuum_naptime ; -- 默认值1 分钟  触发条件 当前年龄大于5千万时 惰性模式 当前库年龄大于1.</description>
    </item>
    
    <item>
      <title>Linux 禁Ping</title>
      <link>https://zhangeamon.top/network-security/reject-ping/</link>
      <pubDate>Thu, 02 Jan 2020 09:26:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/reject-ping/</guid>
      <description> 修改配置文件/etc/sysctl.conf 在这个文件的最后添加一行:
net.ipv4.icmp_echo_ignore_all=1 （0 代表允许 1 代表禁止）  执行sysctl -p 使新配置生效 </description>
    </item>
    
    <item>
      <title>linux分区命令parted的用法</title>
      <link>https://zhangeamon.top/linux/parted/</link>
      <pubDate>Fri, 27 Dec 2019 17:13:00 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/parted/</guid>
      <description>linux分区命令parted的用法 parted的适用场景 创建操作大于2T的分区 一般情况下，我们都是选择使用fdisk工具来进行分区，但是目前在实际生产环境中使用的磁盘空间越来越大，呈TiB级别增长；而常用的fdisk这个工具对分区是有大小限制的，它只能划分小于2T的磁盘，所以在划大于2T磁盘分区的时候fdisk就无法满足要求了；这个时候有2个方法，其一是通过卷管理来实现，其二就是通过parted工具来实现对GPT磁盘进行分区操作；这里我们采用parted的方法来实现管理。
环境 操作系统 CentOS 7.5 磁盘信息 待管理磁盘 /dev/sdb 磁盘总大小 18T 分区需求 将整个/dev/sdb划分到同一个分区里，并挂载到**/gfsdata01目录下。
选择操作磁盘 parted命令后跟上欲操作磁盘的名字即可选择此设备进行操作。
[root@kvm ~]# parted /dev/sdb GNU Parted 3.1 Using /dev/sdb Welcome to GNU Parted! Type &#39;help&#39; to view a list of commands.  新建磁盘标签类型为GPT
因为parted命令只能针对gpt格式的磁盘进行操作，所以这里必须将新建的磁盘标签格式设为gpt。
(parted) mklabel gpt  分区 命令格式
mkpart PART-TYPE [FS-TYPE] START END PART-TYPE(分区类型) primary 主分区 logical 逻辑分区 extended 扩展分区 FS-TYPE(文件系统类型) ext4 ext3 ext2 xfs 其他...... START 设定磁盘分区起始点；可以为0，numberMiB/GiB/TiB； 0 设定当前分区的起始点为磁盘的第一个扇区； 1G 设定当前分区的起始点为磁盘的1G处开始； END 设定磁盘分区结束点； -1 设定当前分区的结束点为磁盘的最后一个扇区； 10G 设定当前分区的结束点为磁盘的10G处； 将/dev/sdb整个空间分给同一个分区  (parted) mkpart primary 0 -1 Warning: The resulting partition is not properly aligned for best performance.</description>
    </item>
    
    <item>
      <title>linux time 命令</title>
      <link>https://zhangeamon.top/linux/time-cmd/</link>
      <pubDate>Tue, 10 Dec 2019 09:04:09 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/time-cmd/</guid>
      <description>Linux time命令的用途，在于量测特定指令执行时所需消耗的时间及系统资源等资讯。
例如 CPU 时间、记忆体、输入输出等等。需要特别注意的是，部分资讯在 Linux 上显示不出来。这是因为在 Linux 上部分资源的分配函式与 time 指令所预设的方式并不相同，以致于 time 指令无法取得这些资料。
语法
time [options] COMMAND [arguments]  参数：
-o 或 &amp;ndash;output=FILE：设定结果输出档。这个选项会将 time 的输出写入 所指定的档案中。如果档案已经存在，系统将覆写其内容。
-a 或 &amp;ndash;append：配合 -o 使用，会将结果写到档案的末端，而不会覆盖掉原来的内容。
-f FORMAT 或 &amp;ndash;format=FORMAT：以 FORMAT 字串设定显示方式。当这个选项没有被设定的时候，会用系统预设的格式。不过你可以用环境变数 time 来设定这个格式，如此一来就不必每次登入系统都要设定一次。
time 指令可以显示的资源有四大项，分别是：
 Time resources
 Memory resources
 IO resources
 Command info
  举例 # time date Sun Mar 26 22:45:34 GMT-8 2006 real 0m0.136s user 0m0.010s sys 0m0.</description>
    </item>
    
    <item>
      <title>Greenplum6 安装</title>
      <link>https://zhangeamon.top/dw/greenplum-install/</link>
      <pubDate>Fri, 06 Dec 2019 14:29:04 +0800</pubDate>
      
      <guid>https://zhangeamon.top/dw/greenplum-install/</guid>
      <description>环境准备 /ect/hosts groupadd gpadmin useradd gpadmin -r -m -g gpadmin passwd gpadmin su gpadmin ssh-keygen -t rsa -b 4096 visudo %wheel ALL=(ALL) NOPASSWD: ALL usermod -aG wheel gpadmin  软件安装 wget https://github.com/greenplum-db/gpdb/releases/download/6.1.0/greenplum-db-6.1.0-rhel7-x86_64.rpm sudo yum install ./greenplum-db-&amp;lt;version&amp;gt;-&amp;lt;platform&amp;gt;.rpm sudo chown -R gpadmin:gpadmin /usr/local/greenplum* source /usr/local/greenplum-db-&amp;lt;version&amp;gt;/greenplum_path.sh vi /home/gpadmin/.bashrc  ssh 免密打通
1-n
ssh-copy-id mdw
n-n
vi /home/gpadmin/hostfile_exkeys
mdw smdw sdw1 sdw2 sdw3 sdw4 sdw5 sdw6
gpssh-exkeys -f hostfile_exkeys
创建存储目录 master mkdir -p /data/master</description>
    </item>
    
    <item>
      <title>内核设置</title>
      <link>https://zhangeamon.top/linux/vm-config/</link>
      <pubDate>Tue, 26 Nov 2019 10:14:41 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/vm-config/</guid>
      <description>参数vm.dirty_ratio和vm.dirty_background_ratio https://lonesysadmin.net/2013/12/22/better-linux-disk-caching-performance-vm-dirty_ratio/
文件缓存是一项重要的性能改进，在大多数情况下，读缓存在绝大多数情况下是有益无害的（程序可以直接从RAM中读取数据）。写缓存比较复杂，Linux内核将磁盘写入缓存，过段时间再异步将它们刷新到磁盘。这对加速磁盘I/O有很好的效果，但是当数据未写入磁盘时，丢失数据的可能性会增加。
当然，也存在缓存被写爆的情况。还可能出现一次性往磁盘写入过多数据，以致使系统卡顿。这些卡顿是因为系统认为，缓存太大用异步的方式来不及把它们都写进磁盘，于是切换到同步的方式写入。
这些都是可控制的选项，根据工作负载和数据，你可以决定如何设置它们：
$ sysctl -a | grep dirty vm.dirty_background_bytes = 0 vm.dirty_background_ratio = 10 vm.dirty_bytes = 0 vm.dirty_ratio = 20 vm.dirty_writeback_centisecs = 500 vm.dirty_expire_centisecs = 3000 vm.dirtytime_expire_seconds = 43200  vm.dirty_background_ratio 是内存可以填充脏数据的百分比。这些脏数据稍后会写入磁盘，pdflush/flush/kdmflush这些后台进程会稍后清理脏数据。比如，我有32G内存，那么有3.2G的脏数据可以待着内存里，超过3.2G的话就会有后台进程来清理。
vm.dirty_ratio是可以用脏数据填充的绝对最大系统内存量，当系统到达此点时，必须将所有脏数据提交到磁盘，同时所有新的I/O块都会被阻塞，直到脏数据被写入磁盘。这通常是长I/O卡顿的原因，但这也是保证内存中不会存在过量脏数据的保护机制。
vm.dirty_background_bytes和vm.dirty_bytes是另一种指定这些参数的方法。如果设置_bytes版本，则_ratio版本将变为0，反之亦然。
vm.dirty_expire_centisecs 指定脏数据能存活的时间。在这里它的值是30秒。当 pdflush/flush/kdmflush 在运行的时候，他们会检查是否有数据超过这个时限，如果有则会把它异步地写到磁盘中。毕竟数据在内存里待太久也会有丢失风险。
vm.dirty_writeback_centisecs 指定多长时间 pdflush/flush/kdmflush 这些进程会唤醒一次，然后检查是否有缓存需要清理。
可以通过下面方式看内存中有多少脏数据：一共有106页的脏数据
$ cat /proc/vmstat | egrep &amp;quot;dirty|writeback&amp;quot; nr_dirty 106 nr_writeback 0 nr_writeback_temp 0 nr_dirty_threshold 3934012 nr_dirty_background_threshold 1964604  方法1：减少缓存 在很多情况下，我们有快速的磁盘子系统，它们有自己的大电池支持的NVRAM缓存，所以将东西保存在系统页面缓存中是有风险的。让我们尝试以更及时的方式向磁盘发送I/O，并减少本地操作系统(借用服务行业的话)“陷入困境”的机会。为了做到这一点，我们减小/etc/sysctl.conf中vm.dirty_background_ratio和vm.dirty_ratio的数值，并执行sysctl -p命令:
vm.dirty_background_ratio = 5 vm.</description>
    </item>
    
    <item>
      <title>postgres 12</title>
      <link>https://zhangeamon.top/postgres/postgres12/</link>
      <pubDate>Tue, 19 Nov 2019 08:43:36 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/postgres12/</guid>
      <description>安装&amp;amp;启动 #下载源 yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm #安装服务 yum install postgresql12 postgresql12-server postgresql12-contrib #初始化 /usr/pgsql-12/bin/postgresql-12-setup initdb #启动服务 systemctl enable postgresql-12 systemctl start postgresql-12  流复制 #从机 建立从库 pg_basebackup -h 10.1.30.13 -U postgres -F p -P -R -D /var/lib/pgsql/12/data/ --checkpoint=fast -l postgresback #从库升级为主库 sudo su postgres -c &amp;quot;/usr/pgsql-12/bin/pg_ctl promote -D /var/lib/pgsql/12/data/&amp;quot;   recovery.conf 配置文件不再支持，此文件中的参数合并到 postgresql.conf(postgresql.auto.conf) Recovery Target, 若 recovery.conf 存在，数据库无法启动 新增 recovery.signal 标识文件，表示数据库处于 recovery 模式 新增加 standby.signal 标识文件，表示数据库处于 standby 模式 trigger_file 参数更名为 promote_trigger_file standby_mode 参数不再支持  在postgres 12 版本中新增一个激活从库为主库的方式。pg_promote 函数，相比原有的两种方式，这种方法的优点在于不需要登陆到实体机上，可远程通过sql进行操作。 pg_promote() 函数有两个参数:</description>
    </item>
    
    <item>
      <title>DNS</title>
      <link>https://zhangeamon.top/network-security/dns/</link>
      <pubDate>Mon, 28 Oct 2019 09:23:00 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/dns/</guid>
      <description>DNS：Domain Name System 域名管理系统
A记录 A（Address）记录是用来指定主机名（或域名）对应的IP地址记录
NS记录 NS（Name Server）记录是域名服务器记录，用来指定该域名由哪个DNS服务器来进行解析
MX记录 MX（Mail Exchanger）记录是邮件交换记录，它指向一个邮件服务器，用于电子邮件系统发邮件时根据收信人的地址后缀来定位邮件服务器。
CNAME记录 CNAME（Canonical Name ）别名记录，允许您将多个名字映射到同一台计算机。
TXT记录，一般指某个主机名或域名的说明
TTL值 TTL（Time-To-Live）
PTR值 PTR是pointer的简写，用于将一个IP地址映射到对应的域名，也可以看成是A记录的反向，IP地址的反向解析
skydns 软件安装 skydns rpm 下载 for centos 7
etcd 使用 centos7 官方自带软件
skydns 配置 /etc/skydns/skydns.conf
ETCD_MACHINES=&amp;quot;http://127.0.0.01:2379&amp;quot; SKYDNS_ADDR=&amp;quot;0.0.0.0:53&amp;quot; SKYDNS_NAMESERVERS=&amp;quot;119.29.29.29:53&amp;quot;  说明
ETCD_MACHINES 指定当前 etcd 集群地址
SKYDNS_ADDR 本地 dns 监听地址
SKYDNS_NAMESERVERS 上层 DNS 服务器
etcd 配置方法 另一种配置方法, 只需要在 skydns.conf 中配置对应的 etcd 连接地址即可.
其他配置选项在 etcd 中进行配置
 etcdctl set /skydns/config &#39;{&amp;quot;dns_addr&amp;quot;:&amp;quot;0.0.0.0:53&amp;quot;,&amp;quot;ttl&amp;quot;:30, &amp;quot;nameservers&amp;quot;: [&amp;quot;119.</description>
    </item>
    
    <item>
      <title>vi 编辑</title>
      <link>https://zhangeamon.top/linux/cmd-vim/</link>
      <pubDate>Tue, 22 Oct 2019 10:01:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cmd-vim/</guid>
      <description>字符串查找 a.查找一个字符串使用：“/你要查询的内容”
b.查找下一个 ：“/你要查询的内容” 再输入”n“跳到下一个
字符串替换 a. 文件内全部替换：
%s#abc#def#g（用def替换文件中所有的abc）
 例如把一个文本文件里面的“linuxidc.com”全部替换成“linuxidc.net”：  :%s#linuxidc.com#xwen.net#g (如文件内有#，可用/替换,比如:%s/linuxidc.com/xwen.net/g)
b. 文件内局部替换：
 把10行到50行内的“abc”全部替换成“def”  :10,50s#abc#def#g（如文件内有#，可用/替换,:%s/abc/def/g）
 以上命令如果在g后面再加上c，则会在替换之前显示提示符给用户确认（conform）是否需要替换。 比如  :%s#linuxidc.com#linuxidc.net#gc</description>
    </item>
    
    <item>
      <title>使用curl命令操作elasticsearch</title>
      <link>https://zhangeamon.top/es/curl-es/</link>
      <pubDate>Wed, 16 Oct 2019 08:49:46 +0800</pubDate>
      
      <guid>https://zhangeamon.top/es/curl-es/</guid>
      <description>第一：_cat系列
_cat系列提供了一系列查询elasticsearch集群状态的接口。你可以通过执行 curl -XGET localhost:9200/_cat 获取所有_cat系列的操作 =^.^= /_cat/allocation /_cat/shards /_cat/shards/{index} /_cat/master /_cat/nodes /_cat/indices /_cat/indices/{index} /_cat/segments /_cat/segments/{index} /_cat/count /_cat/count/{index} /_cat/recovery /_cat/recovery/{index} /_cat/health /_cat/pending_tasks /_cat/aliases /_cat/aliases/{alias} /_cat/thread_pool /_cat/plugins /_cat/fielddata /_cat/fielddata/{fields} 你也可以后面加一个v，让输出内容表格显示表头，举例 curl -XGET http://10.1.80.85:9200/_cat/indices?v health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open filebeat-7.3.2-2019.09.27 agrhjW7KR_ObgdwrUOpJMA 1 1 218974 0 181.8mb 91mb  第二：_cluster系列
1、查询设置集群状态 curl -XGET localhost:9200/_cluster/health?pretty=true pretty=true表示格式化输出 level=indices 表示显示索引状态 level=shards 表示显示分片信息 2、curl -XGET localhost:9200/_cluster/stats?pretty=true 显示集群系统信息，包括CPU JVM等等 3、curl -XGET localhost:9200/_cluster/state?</description>
    </item>
    
    <item>
      <title>Postgres 10 监控指标</title>
      <link>https://zhangeamon.top/monitor/postgres-indicators/</link>
      <pubDate>Fri, 27 Sep 2019 15:13:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/postgres-indicators/</guid>
      <description> 实体机  Cpu 内存 IO 网络 磁盘大小  数据库基本信息 服务启动时间 select pg_postmaster_start_time();  版本信息 select current_setting(&#39;server_version&#39;);  主从角色 select pg_is_in_recovery();  </description>
    </item>
    
    <item>
      <title>wget</title>
      <link>https://zhangeamon.top/linux/wget/</link>
      <pubDate>Thu, 19 Sep 2019 14:07:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/wget/</guid>
      <description> 断点续传 后台运行 限速  wget -cb --limit-rate=300k &amp;quot;http://...&amp;quot;  </description>
    </item>
    
    <item>
      <title>ElasticAlert</title>
      <link>https://zhangeamon.top/es/elasticalert/</link>
      <pubDate>Thu, 19 Sep 2019 09:52:34 +0800</pubDate>
      
      <guid>https://zhangeamon.top/es/elasticalert/</guid>
      <description>https://github.com/Yelp/elastalert</description>
    </item>
    
    <item>
      <title>Discovery 7.0&#43; 集群协调</title>
      <link>https://zhangeamon.top/es/discovery/</link>
      <pubDate>Tue, 17 Sep 2019 15:17:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/es/discovery/</guid>
      <description>https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch</description>
    </item>
    
    <item>
      <title>设置密码</title>
      <link>https://zhangeamon.top/es/password/</link>
      <pubDate>Thu, 12 Sep 2019 15:31:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/es/password/</guid>
      <description>ElasticSearch 设置密码 以前在使用es的时候基本是裸，没有任何的权限管理。用户名密码设置。
配置 elasticsearch.yaml 添加，重启服务
xpack.security.enabled: true xpack.security.transport.ssl.enabled: true  设置用户密码
/usr/share/elasticsearch/elasticsearch-setup-passwords interactive Initiating the setup of passwords for reserved users elastic,kibana,logstash_system,beats_system. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: passwords must be at least [6] characters long Try again. Enter password for [elastic]: Reenter password for [elastic]: Passwords do not match. Try again.</description>
    </item>
    
    <item>
      <title>数据库视图之 pg_stat_activity</title>
      <link>https://zhangeamon.top/postgres/t_pg_stat_activity/</link>
      <pubDate>Fri, 23 Aug 2019 13:47:12 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/t_pg_stat_activity/</guid>
      <description>介绍 当需要了解数据库当前运行状态或需要排查问题时，首先需要查看的就是pg_stat_activity。该视图中包含了你想知道的数据库连接信息，正在执行的有哪些sql，并处于何状态。
One row per server process, showing information related to the current activity of that process, such as state and current query.
每一行都表示一个系统进程，显示与当前会话的活动进程的一些信息，比如当前回话的状态和查询等。
字段解读    Column Type Description     datid oid OID of the database this backend is connected to   datname name Name of the database this backend is connected to   pid integer Process ID of this backend   usesysid oid OID of the user logged into this backend   usename name Name of the user logged into this backend   application_name text Name of the application that is connected to this backend   client_addr inet IP address of the client connected to this backend.</description>
    </item>
    
    <item>
      <title>Jumpserver 跳板机</title>
      <link>https://zhangeamon.top/network-security/jumpserver/</link>
      <pubDate>Mon, 17 Jun 2019 15:17:29 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/jumpserver/</guid>
      <description>http://docs.jumpserver.org/zh/docs/index.html</description>
    </item>
    
    <item>
      <title>citus 简单应用</title>
      <link>https://zhangeamon.top/postgres/citus01/</link>
      <pubDate>Wed, 05 Jun 2019 10:40:09 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/citus01/</guid>
      <description>常用方法 集群管理
加入节点 SELECT * from master_add_node(&#39;worker-101&#39;, 5432); 查看节点状态 SELECT * FROM master_get_active_worker_nodes(); select * from pg_dist_node;  数据库管理
 分片表(distributed table ， hash | append ) 参考表(reference table 数据量小) 本地表(原生表，没有任何处理.兼容性高)  对表进行分片 SELECT create_distributed_table(&#39;companies&#39;, &#39;id&#39;); 分片查看 SELECT * from pg_dist_shard;  元数据表
pg_dist_shard pg_dist_placement pg_dist_node  参数
更多参考
sql 限制
1 非亲和性表之间的outer join
方案： CTE 广播 、临时表、fdw
2 本地表参与的join 不支持
3 postgis 支持的限制，复杂计算
注意事项
1 max_adptive_executor_pool_size 防止但库负载过大
2 参考表默认查询每次都是访问一个数据库的分布。 设置 task_assigment_policy TO &amp;lsquo;rond &amp;rsquo; 轮询使用</description>
    </item>
    
    <item>
      <title>tpch AP测试</title>
      <link>https://zhangeamon.top/postgres/tpch/</link>
      <pubDate>Wed, 05 Jun 2019 09:36:21 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/tpch/</guid>
      <description>背景介绍 24sql
TPC-H 基准测试 下载安装 tpch-tools安装包
修改makefile.suite 模版
CC=gcc DATABASE-TDAT MACHINE=LINUX WORKLOAD=TPCH  执行 make 进行编译
生成测试数据 生成20G测试数据
./dbgen -s 20 ls -lrth *.tbl  自动生成的测试数据每行的结尾多余一个 &amp;lsquo;|&amp;rsquo; 需要处理
for i in `ls *.tbl`; do sed &#39;s/|$//&#39; $i &amp;gt; ${i/tbl/csv}; echo $i; done;  创建表及索引 在下面的文件中分别是创建表和对应索引的sql
dss.ddl
dss.ri
导入数据 copy customer from &#39;/opt/tpch-tools/dbgen/customer.csv&#39; with DELIMITER &#39;|&#39;; copy lineitem from &#39;/opt/tpch-tools/dbgen/lineitem.csv&#39; with DELIMITER &#39;|&#39;; copy nation from &#39;/opt/tpch-tools/dbgen/nation.csv&#39; with DELIMITER &#39;|&#39;; copy orders from &#39;/opt/tpch-tools/dbgen/orders.</description>
    </item>
    
    <item>
      <title>表空间膨胀</title>
      <link>https://zhangeamon.top/postgres/pgstattuple/</link>
      <pubDate>Wed, 22 May 2019 17:26:45 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgstattuple/</guid>
      <description>背景介绍 由于mvcc机制，数据被删除后只是被标记为删除，实际空间没有被释放，这是表空间膨胀的根本原因。
目前用于解决表空间膨胀方式有如下方式
1 删除dead tuple
 vacuum ,tuple被清理。数据库可以自动执行autovacuum vacuum full ,tuple被清理并且空间连续紧凑。弊端，在执行过程中会锁表。应用不可用 为了避免锁表的影响，提供的pg_squeeze拓展,使用逻辑复制。pg_repack拓展，使用了触发器，影响业务的性能。  2 fillfactor
3 vacuum_defer_cleanup_age &amp;gt; 0, 是以事务为单位。配合pg_resetwal 可以做到flashback
代价1，主库膨胀，因为垃圾版本要延迟若干个事务后才能被回收。 代价2，重复扫描垃圾版本，重复耗费垃圾回收进程的CPU资源。（n_dead_tup会一直处于超过垃圾回收阈值的状态，从而autovacuum 不断唤醒worker进行回收动作）。 当主库的 autovacuum_naptime=很小的值，同时autovacuum_vacuum_scale_factor=很小的值时，尤为明显。 代价3，如果期间发生大量垃圾，垃圾版本可能会在事务到达并解禁后，爆炸性的被回收，产生大量的WAL日志，从而造成WAL的写IO尖刺。  4 reindex 从新建立索引，不要忽略表膨胀中索引的影响，通常来说索引所占的空间和维护成本要高于数据表，在pg version 12版本中预计reindex时不需要锁表。
处理完毕后需要重新生成统计信息  ANALYZE;  在执行以上操作时建议设置
set maintenance_work_mem = &#39;10GB&#39;;  监控表空间膨胀 pgstattuple提供了pgstatetuple()和pgstatindex()两个统计表和索引的方法，较PostgreSQL系统表pg_class的表统计信息，pgstatetuple()还统计了表中的dead tuples。
https://www.postgresql.org/docs/current/pgstattuple.html
创建拓展
create extension pgstattuple ;  表 test=&amp;gt; SELECT * FROM pgstattuple(&#39;tablename&#39;); -[ RECORD 1 ]------+------- table_len | 458752 tuple_count | 1470 tuple_len | 438896 tuple_percent | 95.</description>
    </item>
    
    <item>
      <title>nginx</title>
      <link>https://zhangeamon.top/middleware/nginx/</link>
      <pubDate>Tue, 09 Apr 2019 15:42:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/nginx/</guid>
      <description>性能优化
 错误码 502 ， error.log 中错误信息 [error] 236#236: *8371899 upstream sent too big header while reading response header from upstream,  问题 header 过大
proxy_buffer_size 64k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k;  官网说明
利用nginx设置用户登陆认证 如下举例设置用户访问kibana时登陆认证
server { listen 80; server_name kibana.×××.com; location / { auth_basic &amp;quot;secret&amp;quot;; auth_basic_user_file /etc/nginx/db/passwd.db; proxy_pass http://****:5601; proxy_set_header Host $host:5601; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Via &amp;quot;nginx&amp;quot;; } access_log off; }  2、配置登录用户名(admin)，密码</description>
    </item>
    
    <item>
      <title>DNS Bind9 &amp; NamedManager </title>
      <link>https://zhangeamon.top/middleware/bind9/</link>
      <pubDate>Thu, 04 Apr 2019 15:14:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/bind9/</guid>
      <description></description>
    </item>
    
    <item>
      <title>关于设计、划分</title>
      <link>https://zhangeamon.top/about/design/</link>
      <pubDate>Sat, 30 Mar 2019 21:44:14 +0800</pubDate>
      
      <guid>https://zhangeamon.top/about/design/</guid>
      <description> 在设计系统时，应该多考虑 墨菲定律：  任何事物都没有表面看起来那么简单。 所有的事都会比你预计的时间长。 可能出错的事总会出错。 如果你担心某种情况发生，那么他就更有可能发生。  在划分系统时，应该多考虑 康威定律：  系统架构是公司组织架构的反映。 应该按照业务闭环进行系统拆分／组织架构划分，实现闭环／高内聚／低耦合，减少沟通成本。 如果沟通出现问题，那么应该考虑进行系统和组织架构的调整。 在合适时机进行系统拆分，不要一开始就把系统／服务拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高。  </description>
    </item>
    
    <item>
      <title>tcpdump 网络抓包工具</title>
      <link>https://zhangeamon.top/linux/tcpdump/</link>
      <pubDate>Tue, 19 Mar 2019 13:25:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/tcpdump/</guid>
      <description>http://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html</description>
    </item>
    
    <item>
      <title>pmap Linux 进程内存分析</title>
      <link>https://zhangeamon.top/linux/pmap/</link>
      <pubDate>Tue, 19 Mar 2019 08:58:40 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/pmap/</guid>
      <description>介绍 pmap - report memory map of a process(查看进程的内存映像信息)
参数说明  - x extended Show the extended format. 显示扩展格式
 - d device Show the deviceformat. 显示设备格式  结果查看说明  Address: start address ofmap 映像起始地址
 Kbytes: size of map in kilobytes 映像大小
 RSS: resident set size inkilobytes 驻留集大小
 Dirty: dirty pages (both sharedand private) in kilobytes 脏页大小
 Mode: permissions on map 映像权限: r=read,w=write, x=execute, s=shared, p=private (copy on write)</description>
    </item>
    
    <item>
      <title>minio 轻量级对象存储</title>
      <link>https://zhangeamon.top/storage/minio/</link>
      <pubDate>Mon, 18 Mar 2019 16:59:48 +0800</pubDate>
      
      <guid>https://zhangeamon.top/storage/minio/</guid>
      <description>简单了解 minio 完全实现了s3协议，使用简单方便。 支持多机模式，提高数据可用性和整体容量。
限制， 最多5T存储。 单个文件最大5T。
缺点， 不能在线扩容。开发者认为扩容应该是开发人员需要解决的问题。
安装及简单使用 服务端
#下载 wget https://dl.minio.io/server/minio/release/linux-amd64/minio mv minio /usr/local/bin/ chmod 777 /usr/local/bin/minio #启动服务 minio server minidata/ Endpoint: http://10.1.88.74:9000 http://172.17.0.1:9000 http://172.19.0.1:9000 http://172.21.0.1:9000 http://172.22.0.1:9000 http://172.23.0.1:9000 http://127.0.0.1:9000 AccessKey: ZSYLNWA109W0Q4DWDS73 SecretKey: kuqn+i1MpR0yoE9RoT59gYjRuB5IJdz8IhIZOqP9 Browser Access: http://10.1.88.74:9000 http://172.17.0.1:9000 http://172.19.0.1:9000 http://172.21.0.1:9000 http://172.22.0.1:9000 http://172.23.0.1:9000 http://127.0.0.1:9000 Command-line Access: https://docs.minio.io/docs/minio-client-quickstart-guide $ mc config host add myminio http://10.1.88.74:9000 ZSYLNWA109W0Q4DWDS73 kuqn+i1MpR0yoE9RoT59gYjRuB5IJdz8IhIZOqP9 Object API (Amazon S3 compatible): Go: https://docs.minio.io/docs/golang-client-quickstart-guide Java: https://docs.minio.io/docs/java-client-quickstart-guide Python: https://docs.minio.io/docs/python-client-quickstart-guide JavaScript: https://docs.</description>
    </item>
    
    <item>
      <title>docker 磁盘空间管理</title>
      <link>https://zhangeamon.top/docker/manager/</link>
      <pubDate>Mon, 18 Mar 2019 08:58:07 +0800</pubDate>
      
      <guid>https://zhangeamon.top/docker/manager/</guid>
      <description>查看docker占用的空间情况 # docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 58 36 6.091GB 2.119GB (34%) Containers 90 89 232.3MB 0B (0%) Local Volumes 137 16 232.7MB 194.2MB (83%) Build Cache 0 0 0B 0B  四大资源尽收眼底，可回收多少资源也了然于胸
清除不在需要的资源 This will remove: - all stopped containers - all networks not used by at least one container - all dangling images - all build cach # docker system prune -f  清除一切非活跃状态，将资源还给系统</description>
    </item>
    
    <item>
      <title>checkpoint 检查点</title>
      <link>https://zhangeamon.top/postgres/checkpoint/</link>
      <pubDate>Wed, 13 Mar 2019 15:57:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/checkpoint/</guid>
      <description>作用 一般checkpoint会将某个时间点之前的脏数据全部刷新到磁盘，以实现数据的一致性与完整性。其主要目的是为了缩短崩溃恢复时间。
触发  超级用户（其他用户不可）执行CHECKPOINT命令 数据库shutdown 数据库recovery完成 XLOG日志量达到了触发checkpoint阈值 周期性地进行checkpoint 需要刷新所有脏页  相关参数  checkpoint_segments WAL log的最大数量，系统默认值是3。超过该数量的WAL日志，会自动触发checkpoint。 新版(9.6)使用min_wal_size, max_wal_size 来动态控制wal日志 checkpoint_timeout 系统自动执行checkpoint之间的最大时间间隔。系统默认值是5分钟。 checkpoint_completion_target 该参数表示checkpoint的完成时间占两次checkpoint时间间隔的比例，系统默认值是0.5,也就是说每个checkpoint需要在checkpoints间隔时间的50%内完成。 checkpoint_warning 系统默认值是30秒，如果checkpoints的实际发生间隔小于该参数，将会在server log中写入一条相关信息。可以通过设置为0禁用。  应用 预防wal写放大
如何判断是否需要优化WAL？ wal 文件名组成
 timeline 8位 逻辑号 8位 偏移量  与wal_lsn对应关系查看
postgres=# select pg_current_wal_lsn(); pg_current_wal_lsn -------------------- 5A/AD000000 (1 行记录) postgres=# select pg_walfile_name(pg_current_wal_lsn()); pg_walfile_name -------------------------- 000000020000005A000000AC  关于如何判断是否需要优化WAL，可以通过分析WAL，然后检查下面的条件，做一个粗略的判断：
 FPI比例高于70% HOT_UPDATE比例低于70%  FPI及HOT_UPDATE查看方法
/usr/pgsql-10/bin/pg_waldump --stats=record -p /var/lib/pgsql/10/data/pg_wal/ -t 2 -s 15/56098120 -e 15/56098200 -z 统计信息 -p wal path -t timeline -s sart lsn -e end lsn 获取wal lsn psql -c &amp;quot;checkpoint;select pg_current_wal_lsn&amp;quot;  /usr/pgsql-10/bin/pg_waldump --stats=record -s 1095/90000000 -e 1098/70000000 -t 3 Type N (%) Record size (%) FPI size (%) Combined size (%) ---- - --- ----------- --- -------- --- ------------- --- XLOG/CHECKPOINT_ONLINE 107 ( 0.</description>
    </item>
    
    <item>
      <title>咨询锁 adlock</title>
      <link>https://zhangeamon.top/postgres/adlock/</link>
      <pubDate>Thu, 07 Mar 2019 16:20:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/adlock/</guid>
      <description> https://github.com/digoal/blog/blob/master/201805/20180524_02.md
行级锁 select .. for update select .. for update skip locked select .. for share  </description>
    </item>
    
    <item>
      <title>rabbitmq 简单应用</title>
      <link>https://zhangeamon.top/rabbitmq/manager01/</link>
      <pubDate>Tue, 26 Feb 2019 14:57:21 +0800</pubDate>
      
      <guid>https://zhangeamon.top/rabbitmq/manager01/</guid>
      <description>启动 rabbitmq-server &amp;amp;  队列重置（清空队列、用户等） rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl stop  关闭 rabbitmqctl stop  列举所有用户 rabbitmqctl list_users  列举所有队列 rabbitmqctl list_queues  添加用户 rabbitmqctl add_user user_name user_passwd  设置用户角色为管理员 rabbitmqctl set_user_tags user_name administrator  权限设置 rabbitmqctl set_permissions -p / user_name &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot;  操作举例（添加用户admin）
sudo rabbitmqctl add_user admin admin sudo rabbitmqctl set_user_tags admin administrator sudo rabbitmqctl set_permissions -p / admin &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot;  查看状态 rabbitmqctl status  安装 RabbitMQWeb管理插件 rabbitmq-plugins enable rabbitmq_management 可以利用http://ip:15672查看界面状态  Rabbitmq的mnesia数据地址 1.</description>
    </item>
    
    <item>
      <title>Telegraf&#43;Influxdb&#43;Grafana</title>
      <link>https://zhangeamon.top/monitor/influxdb01/</link>
      <pubDate>Tue, 26 Feb 2019 09:42:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/influxdb01/</guid>
      <description> 架构组建介绍  telegraf 数据采集 Agent for collecting and Reporting Metrics and Events. influxdb 时序数据库存储 Purpose Buid time series databases. granafa 数据展现  </description>
    </item>
    
    <item>
      <title>iptables查看、添加、删除规则</title>
      <link>https://zhangeamon.top/network-security/iptables01/</link>
      <pubDate>Mon, 25 Feb 2019 17:23:44 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/iptables01/</guid>
      <description>查看 iptables -nvL –line-number
-L 查看当前表的所有规则，默认查看的是filter表，如果要查看NAT表，可以加上-t NAT参数
-n 不对ip地址进行反查，加上这个参数显示速度会快很多
-v 输出详细信息，包含通过该规则的数据包数量，总字节数及相应的网络接口
–line-number 显示规则的序列号，这个参数在删除或修改规则时会用到
添加 添加规则有两个参数：-A和-I。其中-A是添加到规则的末尾；-I可以插入到指定位置，没有指定位置的话默认插入到规则的首部。
当前规则： [root@test ~]# iptables -nL --line-number Chain INPUT (policy ACCEPT) num target prot opt source destination 1 DROP all -- 192.168.1.1 0.0.0.0/0 2 DROP all -- 192.168.1.2 0.0.0.0/0 3 DROP all -- 192.168.1.4 0.0.0.0/0 添加一条规则到尾部： [root@test ~]# iptables -A INPUT -s 192.168.1.5 -j DROP 再插入一条规则到第三行，将行数直接写到规则链的后面： [root@test ~]# iptables -I INPUT 3 -s 192.168.1.3 -j DROP 查看： [root@test ~]# iptables -nL --line-number Chain INPUT (policy ACCEPT) num target prot opt source destination 1 DROP all -- 192.</description>
    </item>
    
    <item>
      <title>dos 常用命令</title>
      <link>https://zhangeamon.top/linux/wind-run/</link>
      <pubDate>Mon, 25 Feb 2019 10:45:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/wind-run/</guid>
      <description> 运行  cmd command regedit 注册表 calc 计算器 notepad 笔记本 mspaint 图画板 winver window版本 shutdown 60秒关机  cmd  ipconfig/all ip信息 cd 切换目录 D: 切换到D目录 dir 当前目录下文件信息  </description>
    </item>
    
    <item>
      <title>Mysql 入门</title>
      <link>https://zhangeamon.top/mysql/over-view/</link>
      <pubDate>Thu, 21 Feb 2019 14:31:26 +0800</pubDate>
      
      <guid>https://zhangeamon.top/mysql/over-view/</guid>
      <description>安装 &amp;amp; 启动 安装 rpm -i https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm yum install mysql-community-server.x86_64  启动 systemctl start mysqld systemctl enable mysqld  查看临时密码 sudo grep &#39;temporary password&#39; /var/log/mysqld.log 2019-05-15T06:42:54.826106Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: DVjSsl-ZX5f7  修改密码 mysql -uroot -p ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass4!&#39;;  常用命令 连接 mysql -h127.0.0.1 -P 3306 -uroot -p  权限管理 mysql登陆用户权限校验主要是通过用户名密码+访问来源主机方式
创建用户 CREATE USER &#39;finley&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;password&#39;;  赋权限 GRANT ALL ON *.</description>
    </item>
    
    <item>
      <title>二叉树、B-Tree、B&#43;Tree、B*Tree</title>
      <link>https://zhangeamon.top/tidb/tree/</link>
      <pubDate>Mon, 18 Feb 2019 14:00:58 +0800</pubDate>
      
      <guid>https://zhangeamon.top/tidb/tree/</guid>
      <description> 二叉树：二叉树，每个结点只存储一个关键字，等于则命中，小于走左边，大于走右边；
 B-Tree：多路搜索树，每个结点存储【M/2-1，M-1]个关键字，非叶子结点存储指向关键字范围的子节点；所有关键字在整棵树中出现【且只出现一次】，非叶子结点可以命中。
 B+Tree：在B-Tree基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+Tree总是到叶子结点才命中。
 B*Tree：在B+Tree的基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3;
  </description>
    </item>
    
    <item>
      <title>Linux 常用命令</title>
      <link>https://zhangeamon.top/linux/fu-cmd/</link>
      <pubDate>Mon, 18 Feb 2019 11:17:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/fu-cmd/</guid>
      <description>线上查询及帮助命令  man 查看命令帮助，命令的词典，更复杂的还有info，但不常用。
 help 查看Linux内置命令的帮助，比如cd命令。
  文件和目录操作命令  ls 全拼list，功能是列出目录的内容及其内容属性信息。
 cd 全拼change directory，功能是从当前工作目录切换到指定的工作目录。
  cp 全拼copy，其功能为复制文件或目录。 find 查找的意思，用于查找目录及目录下的文件。 mkdir 全拼make directories，其功能是创建目录。 mv 全拼move，其功能是移动或重命名文件。 pwd 全拼print working directory，其功能是显示当前工作目录的绝对路径。 rename 用于重命名文件。 rm 全拼remove，其功能是删除一个或多个文件或目录。 rmdir 全拼remove empty directories，功能是删除空目录。 touch 创建新的空文件，改变已有文件的时间戳属性。 tree 功能是以树形结构显示目录下的内容。 basename 显示文件名或目录名。 dirname 显示文件或目录路径。 chattr 改变文件的扩展属性。 lsattr 查看文件扩展属性。 file 显示文件的类型。 md5sum 计算和校验文件的MD5值。 查看文件及内容处理命令（21个） cat 全拼concatenate，功能是用于连接多个文件并且打印到屏幕输出或重定向到指定文件中。 tac tac是cat的反向拼写，因此命令的功能为反向显示文件内容。 more 分页显示文件内容。 less 分页显示文件内容，more命令的相反用法。 head 显示文件内容的头部。 tail 显示文件内容的尾部。 cut 将文件的每一行按指定分隔符分割并输出。 split 分割文件为不同的小片段。 paste 按行合并文件内容。 sort 对文件的文本内容排序。 uniq 去除重复行。oldboy wc 统计文件的行数、单词数或字节数。 iconv 转换文件的编码格式。 dos2unix 将DOS格式文件转换成UNIX格式。 diff 全拼difference，比较文件的差异，常用于文本文件。 vimdiff 命令行可视化文件比较工具，常用于文本文件。 rev 反向输出文件内容。 grep/egrep 过滤字符串，三剑客老三。 join 按两个文件的相同字段合并。 tr 替换或删除字符。 vi/vim 命令行文本编辑器。 文件压缩及解压缩命令（4个） tar 打包压缩。oldboy unzip 解压文件。 gzip gzip压缩工具。 zip 压缩工具。 信息显示命令（11个） uname 显示操作系统相关信息的命令。 hostname 显示或者设置当前系统的主机名。 dmesg 显示开机信息，用于诊断系统故障。 uptime 显示系统运行时间及负载。 stat 显示文件或文件系统的状态。 du 计算磁盘空间使用情况。 df 报告文件系统磁盘空间的使用情况。 top 实时显示系统资源使用情况。 free 查看系统内存。 date 显示与设置系统时间。 cal 查看日历等时间信息。 搜索文件命令（4个） which 查找二进制命令，按环境变量PATH路径查找。 find 从磁盘遍历查找文件或目录。 whereis 查找二进制命令，按环境变量PATH路径查找。 locate 从数据库 (/var/lib/mlocate/mlocate.</description>
    </item>
    
    <item>
      <title>Mysql 书单</title>
      <link>https://zhangeamon.top/mysql/book-list/</link>
      <pubDate>Wed, 13 Feb 2019 15:20:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/mysql/book-list/</guid>
      <description>入门：
《涂抹MySQL：跟着三思一步一步学MySQL》
《MySQL数据库应用从入门到精通（第2版）》
《MySQL核心技术手册》
《MySQL技术内幕（第5版）》
运维实践：
《高性能MySQL》 经典必读
《MySQL管理之道：性能调优、高可用与监控（第2版） 》贺春旸
《深入理解MySQL核心技术》帕奇维
《MySQL运维内参》 周彦伟、王竹峰、强昌金
《高可用MySQL》
内核：
《MySQL技术内幕：InnoDB存储引擎（第2版）》姜承尧
《InnoDB - A journey to the core》Jeremy Cole
学习笔记文档:
https://notes.diguage.com/mysql/
视频
https://edu.aliyun.com/course/1762?spm=5176.10731542.0.0.311e6ac8weevK5
视频对应笔记
https://www.cnblogs.com/developer_chan/p/9205401.html</description>
    </item>
    
    <item>
      <title>Redis 常用数据结构</title>
      <link>https://zhangeamon.top/redis/data-type/</link>
      <pubDate>Wed, 13 Feb 2019 14:41:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/redis/data-type/</guid>
      <description>String： 字符串。整数，浮点数
 Hash：健值对的无序散列列表
 List：链表 Set：无序集合 Zset：有序集合  https://www.cnblogs.com/knowledgesea/category/722602.html</description>
    </item>
    
    <item>
      <title>八种进程通信</title>
      <link>https://zhangeamon.top/linux/process-comm/</link>
      <pubDate>Wed, 13 Feb 2019 14:07:39 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/process-comm/</guid>
      <description>1.无名管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2.高级管道(popen)：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。
3.有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
4.消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5.信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6.信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
7.共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
8.套接字( socket ) ： 套解字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。</description>
    </item>
    
    <item>
      <title>进程管理</title>
      <link>https://zhangeamon.top/linux/pid_m/</link>
      <pubDate>Thu, 31 Jan 2019 10:56:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/pid_m/</guid>
      <description>监控进程 查看系统TOP(f进入field选择)
top  打印系统进程
ps -efwL  统计每个进程的开销
pidstat -d -r -u -w -l -h -p ALL 5 1  打印进程stack
pstack -p pid  打印进程系统调用
strace -p pid  结束和管理进程 结束进程
kill pid  强制结束进程(用户进程无法捕获-9信号，可能崩溃. -15信号稳妥些)
kill -9 pid  管理周期进程
任务调度进程的管理
查看当前用户的当前调度任务
crontab -l  配置当前用户的调度任务(命令一定要有user:x权限，否则不会被执行)
crontab -e # * 表示所有，支持-号范围，支持,号枚举 # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .</description>
    </item>
    
    <item>
      <title>pgpoolii 读写分离</title>
      <link>https://zhangeamon.top/postgres/pgpool2/</link>
      <pubDate>Wed, 30 Jan 2019 15:43:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgpool2/</guid>
      <description>https://www.pgpool.net/docs/pgpool-II-3.5.4/doc/tutorial-zh_cn.html#dist-def
https://www.xiaomastack.com/2019/08/16/postgresql集群/</description>
    </item>
    
    <item>
      <title>Logical Replication 逻辑复制</title>
      <link>https://zhangeamon.top/postgres/logical-replication/</link>
      <pubDate>Wed, 30 Jan 2019 15:42:25 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/logical-replication/</guid>
      <description>逻辑复制 Postgres 10 版本开始， 在内核层面支持基于REDO流的逻辑复制。
控制粒度为表级别
物理复制相同都是基于wal
可指定多个上游数据源
下游数据可读可写
可用于数据汇总，无停服数据迁移,大版本升级等。
基本概念 发布者（publication）， 上游数据 订阅者 (subscrition)， 下游数据 复制槽 (slot), 保存逻辑复制的信息 简单实践  将10中的一张表同步到12中  发布者服务器配置
postgresql.conf
wal_level = logical max_replication_slots = 10 # 每个slot 需要一个 max_wal_senders = 10 # 每个slot 需要一个 max_worker_processes = 128  pg_hba.conf
host replication postgres 10.1.0.0/16 md5  订阅者服务器配置
postgresql.conf
max_replication_slots = 10 # 每个slot 需要一个 max_logical_replication_workers = 10 # 每个slot 需要一个 max_worker_processes = 128  在发布端创建发布</description>
    </item>
    
    <item>
      <title>cluster 聚族表</title>
      <link>https://zhangeamon.top/postgres/cluster/</link>
      <pubDate>Wed, 30 Jan 2019 15:19:41 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/cluster/</guid>
      <description>存储数据线性相关性 测试</description>
    </item>
    
    <item>
      <title>Archive wal归档</title>
      <link>https://zhangeamon.top/postgres/archive/</link>
      <pubDate>Wed, 30 Jan 2019 14:20:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/archive/</guid>
      <description>介绍 所谓WAL日志归档，其实就是把在线的WAL日志备份出来。
配置 vi postgresql.conf
wal_level=&#39;replica&#39; # - Archiving - archive_mode = on # enables archiving; off, on, or always # (change requires restart) archive_command = &#39;test ! -f /mnt/backup/%f &amp;amp;&amp;amp; cp %p /mnt/backup/%f&#39; # command to use to archive a logfile segment # placeholders: %p = path of file to archive # %f = file name only # e.g. &#39;test ! -f /mnt/server/archivedir/%f &amp;amp;&amp;amp; cp %p /mnt/server/archivedir/%f&#39; #archive_timeout = 0 # force a logfile segment switch after this # number of seconds; 0 disables  参数说明  wal_level archive 或更高级别 archive_mode on 开启归档模式，always 主从模式时，从库也开启归档模式。需要重启数据库 archive_command 归档时触发的命令或脚本， 不需要重新启动数据库。 systemctl reload postgresql-10 即可。 archive_timeout 可以理解为超过指定时间强制执行 select pg_switch_wal(); 场景， 数据库不是很活跃，数据库wal日志产生的过慢时。  归档触发条件说明： 1 手动执行 select pg_switch_wal();</description>
    </item>
    
    <item>
      <title>TimescaleDB 时序数据库</title>
      <link>https://zhangeamon.top/postgres/timescaledb/</link>
      <pubDate>Wed, 30 Jan 2019 10:20:51 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/timescaledb/</guid>
      <description>时序数据库 https://github.com/timescale/timescaledb
数据库配置 https://github.com/timescale/timescaledb-tune
copy并行导入数据 https://github.com/timescale/timescaledb-parallel-copy
常用方法 创建拓展
CREATE EXTENSION timescaledb;  创建一个普通的表
CREATE TABLE conditions ( time TIMESTAMPTZ NOT NULL, location TEXT NOT NULL, temperature DOUBLE PRECISION NULL, humidity DOUBLE PRECISION NULL );  转换成时序数据库表
SELECT create_hypertable(&#39;conditions&#39;, &#39;time&#39;);   conditions 表名 time 时序字段  修改时序间隔 对新表生效
SELECT set_chunk_time_interval(&#39;conditions&#39;, INTERVAL &#39;24 hours&#39;);  查看分区
SELECT show_chunks(&#39;conditions&#39;); SELECT show_chunks(&#39;conditions&#39;, older_than =&amp;gt; INTERVAL &#39;3 months&#39;) SELECT show_chunks(&#39;conditions&#39;, older_than =&amp;gt; DATE &#39;2017-01-01&#39;); SELECT show_chunks(newer_than =&amp;gt; INTERVAL &#39;3 months&#39;); SELECT show_chunks(older_than =&amp;gt; INTERVAL &#39;3 months&#39;, newer_than =&amp;gt; INTERVAL &#39;4 months&#39;);  查看数据大小</description>
    </item>
    
    <item>
      <title>PG主从切换 pg_rewind</title>
      <link>https://zhangeamon.top/postgres/pg_rewind/</link>
      <pubDate>Wed, 30 Jan 2019 10:16:17 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_rewind/</guid>
      <description>pg_rewind requires that the target server either has the wal_log_hints option enabled in postgresql.conf or data checksums enabled when the cluster was initialized with initdb. Neither of these are currently on by default. full_page_writes must also be set to on, but is enabled by default.
wal_log_hints
使用场景 在数据库主从结构中，从变成主易。但是由主变为从却需要一番周折。
如果是数据量少时重新使用pg_backup拉一份从即可，但是如果数据量大时，这个过程非常的耗时耗能。对线上业务也会有影响。
在实际的场景中主从之间的数据绝大部分时一致的，只有非常少量的近期产生的数据是不一致的。
有没有什么方式可以利用已有的数据，充分利用已有的数据呢？
pg_rewind登场 告别一下回到解放前。
基本原理 数据库每次的主从切换时，timeLine会增加1。 新老数据库在不同的时间线上运行。 使用pg_rewind 将数据拉回到时间线(timeLine)产生分裂的那个点上。重新选择时间线，重放新时间线上的wal日志，使两个数据库重新回到一个时间线，并且数据一致。
开始实验 背景:
主从数据库结构
10.1.88.71 主库
10.1.88.72 从库
目标
数据库主从兑换， 主降为从时使用pg_rewind校对时间线
实际操作 注意事项 :</description>
    </item>
    
    <item>
      <title>PG高可用Patroni</title>
      <link>https://zhangeamon.top/postgres/patroni/</link>
      <pubDate>Wed, 30 Jan 2019 10:14:55 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/patroni/</guid>
      <description>环境  操作系统 Centos 7 patroni 版本 2.0.2 postgres 版本 13  实现目标  高可用方案对比 patroni 结构分析 patroni 搭建新集群 patroni 接管现有集群 patroni 管理pg配置 手动swithover 自动failover 维护模式 弹性扩容，缩容 对外提供统一服务 RestFULLAPI 备份恢复 监控 日志 升级  高可用方案对比 pg的高可用方案都是基于流复制来实现
 PAF
pacemaker + corosyns
 repmgr
repmgr 手动流复制管理
repmgrd 自动流复制管理 守护进程
主+从
主+从+见证节点
  更多介绍
patroni架构分析  DCS[etcd] 外部依赖 ，集群通信选主 patroni 与pg在同一个节点， 守护进程  patroni搭建新集群 1 虚拟机环境
10.10.1.10 node0 外部节点etcd 10.10.1.11 - 13 node1-node3 集群节点  2 node0 安装etcd</description>
    </item>
    
    <item>
      <title>MySQL常用性能分析命令</title>
      <link>https://zhangeamon.top/mysql/performance-cmd/</link>
      <pubDate>Tue, 29 Jan 2019 14:06:55 +0800</pubDate>
      
      <guid>https://zhangeamon.top/mysql/performance-cmd/</guid>
      <description>MySQL常用性能突发事件分析命令：
 SHOW PROCESSLIST; —当前MySQL数据库的运行的所有线程
 INNODB_TRX; — 当前运行的所有事务
 INNODB_LOCKS; — 当前出现的锁
 INNODB_LOCK_WAITS; — 锁等待的对应关系计
 SHOW OPEN TABLES where In_use &amp;gt;0; — 当前打开表
 SHOW ENGINE INNODB STATUS \G; —Innodb状态
 SHOW STATUS LIKE &amp;lsquo;innodb_rowlock%&amp;lsquo;; — 锁性能状态
 SQL语句EXPLAIN; — 查询优化器
  </description>
    </item>
    
    <item>
      <title>citus 数据库分库</title>
      <link>https://zhangeamon.top/postgres/pg_citus/</link>
      <pubDate>Tue, 29 Jan 2019 13:19:26 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_citus/</guid>
      <description> 数据库分库调研  Greenplum 更适用于AP场景 PGXL PGXC 社区不活跃，沟通问题反馈时间长。没找到用户群体. 在此基础上发展的有亚信antdb，腾讯tbase。没有那个研发实力，算了吧。 citus 插件方式，无侵入。很多牛X的特性企业版才支持。主要强调多租户。 mycat mysql支派，阿里开源（抛弃）项目。主要是对sql语句的拦截，需要对业务理解透彻又要懂mycat，入侵太强。 bdr。 2ndquadrant 其他 由数据库触发器实现的直接略过  citus 开源社区版，如何分库及扩容，ha
主要思路是通过修改系统的分区表，手动进行分库。
ha 数据库自身的主从流复制。
实验目标  加入数据库几点进行扩容 删除数据库节点进行缩容 模拟任意节点宕机观察ha特性 压力测试判断增加主机节点与数据库整体处理能力之间的线形关系  </description>
    </item>
    
    <item>
      <title>pgwatch2 数据库指标监控查看</title>
      <link>https://zhangeamon.top/postgres/pgwatch2/</link>
      <pubDate>Tue, 29 Jan 2019 11:19:05 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgwatch2/</guid>
      <description>介绍 pgwatch2官方
官方演示示例
架构 agent server
 agent 在被监控的pg上自定义方法，用于收集数据库信息。这些自定义的方法需要依赖需要数据库扩展如pg_stat_statements,plpythonu.
 server 负责存储收集过来的信息，可以存放在postgres或influxdb中. 并将收集的信息进行展示grafana.
  安装 客户端
依赖的拓展
yum install postgresql10-plpython.x86_64 -y  配置数据库,需要重启数据库生效，多个拓展之间用,号分割。
shared_preload_libraries = &#39;pg_stat_statements&#39;  连接到对应的数据库，创建拓展
CREATE EXTENSION pg_stat_statements; CREATE EXTENSION plpythonu;  创建自定义方法, 使用supper user 用户执行如下sql. 注意将下面的pql 信息中的用户信息替换成自己的数据库连接用户。
该目录下为所有的自定义方法 https://github.com/cybertec-postgresql/pgwatch2/tree/master/pgwatch2/sql/metric_fetching_helpers https://github.com/cybertec-postgresql/pgwatch2/blob/master/pgwatch2/sql/metric_fetching_helpers/stat_statements_wrapper.sql https://github.com/cybertec-postgresql/pgwatch2/blob/master/pgwatch2/sql/metric_fetching_helpers/cpu_load_plpythonu.sql  服务端
使用docker-compose 来管理服务，切都变得那么easy！
cat docker-compose.yaml version: &#39;2&#39; services: pgw2: restart: unless-stopped image: cybertec/pgwatch2 container_name: pw2 ports: - 3000:3000 - 8080:8080 volumes: - .</description>
    </item>
    
    <item>
      <title>锁机制</title>
      <link>https://zhangeamon.top/postgres/pg_lock/</link>
      <pubDate>Thu, 24 Jan 2019 11:26:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_lock/</guid>
      <description>https://blog.csdn.net/pg_hgdb/article/details/79403651
https://habr.com/en/company/postgrespro/blog/500714/
表锁 https://www.modb.pro/db/26462
查看被堵塞的任务 select * from pg_locks where not granted; locktype | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid | mode | granted | fastpath ----------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+-----+------+---------+---------- (0 行记录) 查看等待锁信息，是被谁堵塞了 select pg_blocking_pids(pid); pg_blocking_pids ------------------ {} 终止进程 select pg_cancel_backend(pid); # select select pg_terminate_backend(pid); # update insert delete  事务的隔离级别 Postgres 数据库共有三种数据隔离级别。
 Read Commit 读看提交 默认级别 在读开始的时候建立数据快照 Repeat Read 可重复读。在事务开始的时候建立数据快照 SSI Serializable 序列化 理解为只有一个用户使用的情况  使用举例</description>
    </item>
    
    <item>
      <title>时间点恢复</title>
      <link>https://zhangeamon.top/postgres/pitr/</link>
      <pubDate>Thu, 24 Jan 2019 11:08:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pitr/</guid>
      <description>PITR Point-in-time recovery
https://blog.csdn.net/a964921988/article/details/84957241
https://github.com/digoal/blog/blob/master/201608/20160823_03.md
https://github.com/digoal/blog/blob/master/201608/20160823_04.md
依赖条件  历史完整备份 不间断wal日志  以上都可有wal-g 备份系统提供支持
恢复到指定点  指定标签 具体时间点 具体事务  指定标签 recovery.conf recovery_target_action= &#39;pause&#39; # promote ,shutdown  --- 打lable select pg_create_restore_point(&#39;my_daily_process_ended&#39;); --- 恢复到指定的lable recovery.conf recovery_target_name = &#39;my_daily_process_ended&#39;  具体时间 restore_command = &#39;cp /data/arch/%f %p&#39; # e.g. &#39;cp /mnt/server/archivedir/%f %p&#39; recovery_target_time = &#39;2020-12-23 09:37:17.010268&#39; recovery_target_inclusive = false recovery_target_timeline = &#39;latest&#39;  具体事务 restore_command = &#39;cp /data/arch/%f %p&#39; # e.g. &#39;cp /mnt/server/archivedir/%f %p&#39; recovery_target_xid = &#39;26897309&#39; recovery_target_inclusive = false recovery_target_timeline = &#39;latest  wal内容解析具体位置，时间、事务 select pg_current_wal_lsn(); pg_current_wal_lsn -------------------- 59/15000090 (1 行记录)  -- 当前wal位置 select pg_walfile_name(pg_current_wal_lsn()); pg_walfile_name -------------------------- 000000020000005900000015 (1 行记录) -- 00000002 TimeLine -- 00000059 逻辑位置 -- 00000015 偏移  -- 解析wal内容 /usr/pgsql-10/bin/pg_waldump .</description>
    </item>
    
    <item>
      <title>pg_pathman 分区表</title>
      <link>https://zhangeamon.top/postgres/pg_pathman/</link>
      <pubDate>Thu, 24 Jan 2019 10:56:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_pathman/</guid>
      <description>介绍 分区表的诉求在现实的生成中的意义不必多说，pg以前的实现方式多采用触发器，rules实现。数据量上来时性能明显不尽如意。
虽然pg10 ，11 版本在分区表的特性上不断发力。但是性能啥还是不够给力。
pg_pathman 分区表功能在目前的pg版本10.6 中优势还是非常明显的。
在期待pg自身分区表特性的同时，当前的pg10中还是使用pg_pathman来实现分区功能吧。
pathman与pg11 对比 优点: 支持HASH和RANGE分区，后续会支持LIST分区 支持自动和手动的分区维护
为分区表生成更有效的执行计划 通过引入两个自定义的执行计划节点RuntimeAppend &amp;amp; RuntimeMergeAppend，
实现运行时动态添加分区到执行计划中 为新插入数据自动创建分区(只对RANGE分区) 提供用户callbacks接口处理创建分区事件。
提供在线分区实施(在线重定义)，父表数据迁移到子表，拆分， 合并分区 不足:
不支持list分区;不支持二级分区;权限，索引，trigger等无法继承; 修改主键默认的seq需要重建分区。
PG11内置分区
优点:
支持hash，range，list分区 支持多字段组合分区，支持表达式分区 支持创建主键，外键，索引，分区表自动继承。 支持update分区键 支持分区表DETACH，ATTACH，支持二级分区 分区自动创建
Default partition Partition improvements
不足:
在主表添加权限，索引，trigger等无法继承 分区表不可以作为其他表的外键主表
分区表数量对插入数据的影响 https://www.jianshu.com/p/1cba77d18694
pathman 分区表 转换为原生分区表 https://github.com/digoal/blog/blob/master/201911/20191113_01.md
主要思路
1 创建一个与原来分区表一样的主表包括分区方式 。
2 将原来的主表上的分区都卸载为普通表，在重新按照原生分区表的方式挂载上去。
直接2 也行
拓展思考。 分区数据迁移使用pg_pathman，迁移后再转换到原生表。
注意事项 需要将pg_pathman放在后面注册，如pg_stat_statements。
shared_preload_libraries = &#39;pg_stat_statements,pg_pathman&#39;  创建拓展
CREATE SCHEMA pathman; GRANT USAGE ON SCHEMA pathman TO PUBLIC; CREATE EXTENSION pg_pathman WITH SCHEMA pathman;  参考 https://github.</description>
    </item>
    
    <item>
      <title>Qos</title>
      <link>https://zhangeamon.top/linux/qos/</link>
      <pubDate>Mon, 21 Jan 2019 17:26:20 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/qos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SSD 4k对齐写放大</title>
      <link>https://zhangeamon.top/linux/4k-wa/</link>
      <pubDate>Thu, 17 Jan 2019 16:12:11 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/4k-wa/</guid>
      <description>4k对齐 早期硬盘每个扇区以512字节为标准，新一代硬盘扇区容量为4096个字节，也就是所说的4k扇区。
硬盘标准更新，但操作系统一直使用的是512字节扇区的标准，所以硬盘厂商为了保证兼容性，把4k扇区模拟成512字节扇区。
通常文件系统的块（簇）是512字节的倍数，新的系统基本上都设成了4k的倍数。比如Linux的簇一般也是4k。
簇到扇区的映射关系变成了 簇（4k）-&amp;gt;512B扇区-&amp;gt;4k扇区
这就可能造成簇到扇区映射错位。
写放大 SSD(WA) 由于闪存必须先擦除才能再写入的特性，如果需要在写入钱清理被删除的数据，则需要把整个分块读出，然后擦除整个块，再写回去。
举个最简单的例子：
当要写入一个4KB的数据时，最坏的情况是一个块里已经没有干净空间了，但有无效的数据可以擦除，所以主控就把所有的数据读到缓存，擦除块，缓存里更新整个块的数据，再把新数据写回去，
这个操作带来的写入放大就是: 实际写4K的数据，造成了整个块（共1024KB）的写入操作，那就是放大了256倍。
同时还带来了原本只需要简单一步写入4KB的操作变成：闪存读取 (1024KB)→缓存改（4KB）→闪存擦除（1024KB）→闪存写入（1024KB），共四步操作，造成延迟大大增加，速度变慢。
所以说WA是影响 SSD随机写入性能和寿命的关键因素。
如何实现4K对齐 查看系统中磁盘物理大小扇区和逻辑大小扇区 cat /sys/block/vdg/queue/physical_block_size 512 cat /sys/block/vdg/queue/logical_block_size 512  可以看到我的这块测试磁盘的物理扇区大小是512字节，逻辑扇区大小也是512字节，这样我们物理块到逻辑块的映射都是512字节的。
linux查看现有磁盘是否是4k对齐，可以用fdisk -l -u fdisk -lu /dev/sde 磁盘 /dev/sde：256.1 GB, 256060514304 字节，500118192 个扇区 Units = 扇区 of 1 * 512 = 512 bytes 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x000ba8b2 设备 Boot Start End Blocks Id System /dev/sde1 * 2048 2099199 1048576 83 Linux /dev/sde2 2099200 52111359 25006080 82 Linux swap / Solaris /dev/sde3 52111360 94054399 20971520 83 Linux /dev/sde4 94054400 500117503 203031552 5 Extended /dev/sde5 94056448 500117503 203030528 83 Linux  Start 为 8的整数倍4k对齐,否则没有对齐。</description>
    </item>
    
    <item>
      <title>memtester 内存压力测试</title>
      <link>https://zhangeamon.top/linux/memtester/</link>
      <pubDate>Mon, 14 Jan 2019 15:45:58 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/memtester/</guid>
      <description>memtester</description>
    </item>
    
    <item>
      <title>memtest 检测内存</title>
      <link>https://zhangeamon.top/linux/memtest/</link>
      <pubDate>Mon, 14 Jan 2019 15:40:01 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/memtest/</guid>
      <description>NAME memtest-setup - Install Memtest86+ into your GRUB boot loader menu SYNOPSIS memtest-setup [OPTIONS] DESCRIPTION memtest-setup installs Memtest86+ into your GRUB boot loader menu. It supports both GRUB 2 and GRUB Legacy (i.e. GRUB 0.9x). In case of GRUB 2 it installs GRUB 2 template into /etc/grub.d and GRUB 2 config needs to be regenerated manually by running grub2-mkconfig -o /boot/grub2/grub.cfg under root. This is not done automatically because it could overwrite any custom changes in /boot/grub2/grub.</description>
    </item>
    
    <item>
      <title>Linux查看内存条信息</title>
      <link>https://zhangeamon.top/linux/dmidecode/</link>
      <pubDate>Mon, 14 Jan 2019 15:38:29 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/dmidecode/</guid>
      <description>1.查看内存槽及内存条
$ sudo dmidecode -t memory  2.查看内存的插槽数,已经使用多少插槽.每条内存多大
$ sudo dmidecode -t memory | grep Size  3.查看服务器型号、序列号
$ sudo dmidecode | grep &amp;quot;System Information&amp;quot; -A9 | egrep &amp;quot;Manufacturer|Product|Serial&amp;quot;  </description>
    </item>
    
    <item>
      <title>cgroups</title>
      <link>https://zhangeamon.top/linux/cgroups/</link>
      <pubDate>Mon, 14 Jan 2019 09:28:49 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cgroups/</guid>
      <description>https://www.certdepot.net/rhel7-get-started-cgroups/
https://www.oracle.com/technical-resources/articles/linux/resource-controllers-linux.html
iops和bps限制
限制sda 的读写
lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk /data sdb 8:16 0 223.6G 0 disk ├─sdb1 8:17 0 200M 0 part /boot/efi ├─sdb2 8:18 0 1G 0 part /boot ├─sdb3 8:19 0 7.8G 0 part [SWAP] └─sdb4 8:20 0 214.6G 0 part /  cd /sys/fs/cgroup/blkio/ echo &amp;quot;8:0 102400&amp;quot; &amp;gt; blkio.throttle.read_bps_device echo &amp;quot;8:0 10&amp;quot; &amp;gt; blkio.throttle.read_iops_device echo &amp;quot;8:0 204800&amp;quot; &amp;gt; blkio.</description>
    </item>
    
    <item>
      <title>Postgres</title>
      <link>https://zhangeamon.top/monitor/postgres/</link>
      <pubDate>Fri, 11 Jan 2019 17:09:51 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/postgres/</guid>
      <description>Postgresql 常用监控 , 巡检报表 直接利用PG提供的性能统计数据
PG的很多性能数据可以通过查询pg_stat_或pg_statio_开头的系统表获取
zabbix
http://pg-monz.github.io/pg_monz/index-en.html
zabbix-extensions
PG专用的监控工具
pgsnap, pgstatspack,pgwatch,pg_statsinfo等。这些工具主要做PG的性能分析，状态查看的。不能做故障通知。
https://github.com/cybertec-postgresql/pgwatch2
https://github.com/wrouesnel/postgres_exporter
https://www.cnblogs.com/ilifeilong/p/10543876.html
基于promethues postgres_exporter
https://github.com/CrunchyData/pgmonitor</description>
    </item>
    
    <item>
      <title>pgfincore</title>
      <link>https://zhangeamon.top/postgres/pgfincore/</link>
      <pubDate>Fri, 11 Jan 2019 13:17:12 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgfincore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>pgbench 压力测试</title>
      <link>https://zhangeamon.top/postgres/pgbench/</link>
      <pubDate>Wed, 09 Jan 2019 16:36:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgbench/</guid>
      <description>介绍 pgbench是一种在PostgreSQL上运行基准测试的简单程序。
官方文档
 默认测试 自定义测试  默认测试 pgbench中默认自带一套测试数据库和测试sql脚本。
初始化默认数据库 使用 -i 初始化数据库 #pgbench -U postgres -i -s 10 pgbenchdb NOTICE: table &amp;quot;pgbench_history&amp;quot; does not exist, skipping NOTICE: table &amp;quot;pgbench_tellers&amp;quot; does not exist, skipping NOTICE: table &amp;quot;pgbench_accounts&amp;quot; does not exist, skipping NOTICE: table &amp;quot;pgbench_branches&amp;quot; does not exist, skipping creating tables... 100000 of 1000000 tuples (10%) done (elapsed 0.14 s, remaining 1.23 s) 200000 of 1000000 tuples (20%) done (elapsed 0.</description>
    </item>
    
    <item>
      <title>定时任务</title>
      <link>https://zhangeamon.top/linux/at-crontab/</link>
      <pubDate>Wed, 09 Jan 2019 10:11:10 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/at-crontab/</guid>
      <description>Linux 系统中的定时任务  重复执行 一次执行  重复执行 详见 /etc/crontab 配置
anacron 用于以天为单位的频率运行命令。它的工作与 cron 稍有不同，它假设机器不会一直开机。
cron 也适合在那些不会 24X7 运行如笔记本以及桌面电脑的机器上运行每日、每周以及每月的计划任务（LCTT 译注：不适合按小时、分钟执行任务）。
假设你有一个计划任务（比如备份脚本）要使用 cron 在每天半夜运行，也许你以及睡着，那时你的桌面/笔记本电脑已经关机。你的备份脚本就不会被运行。
然而，如果你使用 anacron，你可以确保在你下次开启桌面/笔记本电脑的时候，备份脚本会被执行。
一次执行 我们使用at 命令来管理Linux中单次执行任务
安装与启动
yum install at -y systemctl start atd  常用命令及参数讲解
 at和batch读取标准输入或一个指定文件，它们将会在稍后被执行。
 at在指定的时间执行命令。
 atq列出用户待处理作业（jobs），如果是超级用户，所有用户的（待处理）作业都将被列出。输出格式：作业号、日期、小时、队列和用户名。
 atrm删除作业，由作业号标识。
  -t time run the job at time, given in the format [[CC]YY]MMDDhhmm[.ss] -c cats the jobs listed on the command line to standard output.</description>
    </item>
    
    <item>
      <title>no space left on device</title>
      <link>https://zhangeamon.top/linux/nospace-device/</link>
      <pubDate>Wed, 09 Jan 2019 08:32:26 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/nospace-device/</guid>
      <description>问题描述 Linux 系统中出现磁盘空间不足错误：
 No space left on device … 在linux环境下，用vi打开某文件时，提示Write error in swap file  原因分析 导致该问题的可能原因包括：
 磁盘分区空间使用率达到百分之百 磁盘分区inode使用率达到百分之百 僵尸文件：已删除文件因句柄被占用未释放导致相应空间未释放  解决方法 磁盘分区空间使用率达到百分之百 查看磁盘使用情况
 df -h 文件系统 容量 已用 可用 已用% 挂载点 /dev/vda2 91G 21G 70G 23% / devtmpfs 3.9G 0 3.9G 0% /dev tmpfs 3.9G 56K 3.9G 1% /dev/shm tmpfs 3.9G 49M 3.8G 2% /run tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/vda3 1014M 33M 982M 4% /home /dev/vda1 1014M 210M 805M 21% /boot tmpfs 783M 0 783M 0% /run/user/0  进入对应目录找出文件占用情况</description>
    </item>
    
    <item>
      <title>meminfo Linux 内存信息</title>
      <link>https://zhangeamon.top/linux/meminfo/</link>
      <pubDate>Tue, 08 Jan 2019 09:04:15 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/meminfo/</guid>
      <description> 介绍 /proc/meminfo是了解Linux系统内存使用状况的主要接口，我们最常用的”free”、”vmstat”等命令就是通过它获取数据的
内容解读 cat /proc/meminfo MemTotal: 8009504 kB 除了bios ，kernel本身占用的内存以外，可以被kernel所分配的内存。一般这个值固定不变。 MemFree: 2385828 kB 未被使用的内存 MemAvailable: 4741232 kB 该值为系统估计值 Buffers: 0 kB 给文件做缓存大小 Cached: 4701848 kB 内存使用 SwapCached: 35516 kB 交换分区使用 Active: 4175652 kB 在活跃使用中的缓冲或高速缓冲存储器页面文件的大小，除非非常必要否则不会被移作他用. Inactive: 1037948 kB 在不经常使用中的缓冲或高速缓冲存储器页面文件的大小，可能被用于其他途径. Active(anon): 2175852 kB Inactive(anon): 570728 kB Active(file): 1999800 kB Inactive(file): 467220 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 1048572 kB SwapFree: 904956 kB Dirty: 708 kB 等待被写回到磁盘的内存大小。 Writeback: 0 kB 正在被写回到磁盘的内存大小。 AnonPages: 482164 kB Mapped: 1991344 kB Shmem: 2234828 kB Slab: 247824 kB SReclaimable: 194368 kB SUnreclaim: 53456 kB KernelStack: 6976 kB PageTables: 63760 kB 管理内存分页页面的索引表的大小。 NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 5053324 kB Committed_AS: 5182268 kB VmallocTotal: 34359738367 kB VmallocUsed: 23696 kB VmallocChunk: 34359707388 kB HardwareCorrupted: 0 kB AnonHugePages: 65536 kB CmaTotal: 0 kB CmaFree: 0 kB HugePages_Total: 0 Hugepages在/proc/meminfo中是被独立统计的，与其它统计项不重叠 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 133084 kB DirectMap2M: 8255488 kB  </description>
    </item>
    
    <item>
      <title>pg_trgm的gist和gin索引加速字符匹配查询</title>
      <link>https://zhangeamon.top/postgres/pg_trgm/</link>
      <pubDate>Mon, 07 Jan 2019 09:37:23 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_trgm/</guid>
      <description>背景 对车牌号的记忆有时可能记住的是前几位，有时可能是后几位，不同的人记车牌号的习惯也不同。
通常是是容易记住首尾，中间不清楚。
那么如何在大量已有车牌数据中快速根据模糊的信息来进行查询呢？
模拟 数据库表中约有500w条车牌号记录，对表中的车牌号进行模糊查询。
即支持 car_id like &amp;lsquo;%XXXX%XXX%&amp;rsquo; 查询
---创建表 create table t_car (id int , car_id text); --插入500万车牌数据 insert into t_car select generate_series(1,5000000), (array[&#39;辽A&#39;,&#39;辽B&#39;,&#39;吉A&#39;,&#39;吉B&#39;,&#39;黑A&#39;,&#39;黑B&#39;])[floor(random()*6+1)] || substring(md5(random()::text),0,6); --查看数据 select * from t_car limit 5; id | car_id ----+---------- 1 | 吉A43bb9 2 | 吉B19b64 3 | 辽Afb04e 4 | 吉Bcf90c 5 | 辽Be67df (5 行记录)  索引  顺序扫描  explain analyze verbose select * from t_car where car_id = &#39;辽Be67df&#39;; QUERY PLAN ------------------------------------------------------------------------------------------------------------------------------ Gather (cost=1000.</description>
    </item>
    
    <item>
      <title>Docker 问题集</title>
      <link>https://zhangeamon.top/docker/troubles/</link>
      <pubDate>Thu, 03 Jan 2019 15:06:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/docker/troubles/</guid>
      <description>Docker push: Received unexpected HTTP status: 500 Internal Server Error  描述: 使用jenkins 构建docker images时 push images到私有harbor中报错: Received unexpected HTTP status: 500 Internal Server Error,在build机上直接push没有问题。有的项目可以成功，有的失败。即使同一个项目有时执行成功，有时也会失败。
解决方式: 网上很多的关于500的错误，大都是关闭selinux来解决。但是情况与这个不同。现在的问题时在jenkins中执行有问题，直接裸机执行没有问题。
看到这篇文章， 怀疑时在push images 过大时需要的系统内存不足导致。
调整jenkins启动时java的内存参数
JAVA_OPTS=&amp;quot;-Djava.util.logging.config.file=/var/jenkins_home/log.properties -Duser.timezone=Asia/Shanghai -Xms4096m -Xmx4096m  问题过几天后有出现
/var/log/message kernel crash after &amp;quot;unregister_netdevice: waiting for lo to become free. Usage count =  换台build机 , nginx 配置
问题解决
 Docker rpc error: code = 14 desc = grpc: the connection is unavailable  尝试关闭容器，进入容器操作界面也报相同错误：</description>
    </item>
    
    <item>
      <title>Centos mail</title>
      <link>https://zhangeamon.top/linux/mail/</link>
      <pubDate>Sat, 29 Dec 2018 16:53:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/mail/</guid>
      <description> 介绍 电子邮件系统包括两个组件： - MUA(Mail User Agent,邮件用户代理）为用户提供的可以读写邮件的界面,例如 Foxmail, Outlook - MTA(Mail Transport Agent,邮件传送代理）MTA是运行在底层，能够处理邮件的收发工作的程序
邮件的接收是MTA和MUA配合完成的。远程的MUA首先向远程MTA连接并验证发信人身份，然后由远程MTA向本地MTA发送邮件。 接受者通过本地MUA接收阅读邮件。邮件的发信也是MTA和MUA配合完成的，不过方向正好相反。本地MUA首先向本地的MTA连接并验证发信人身份，然后由本地MTA向远程MTA发送邮件，再由远程的MUA读取邮件。
mailx 和 sentmail  mail和mailx即为负责查看、编写邮件和向MTA发送邮件的MUA。mailx是mail的功能加强版。 sendmail即为负责邮件在网络上传输的MTA，将邮件从一个MTA传送至另一个MTA。  mailx 安装及配置 yum install mailx -y vi /etc/mail.rc set sendcharsets=iso-8859-1,utf-8 set from=xxx@XXX.com set smtp=smtp.XXX.com:25 set smtp-auth-user=xxx@XXX.com #认证用户 set smtp-auth-password=xxx #认证密码  测试
echo&amp;quot;zabbix test &amp;quot; |mail -s &amp;quot;zabbix&amp;quot; xxx@xxx.com #如果邮箱中能收到邮件，表示测试成功。  </description>
    </item>
    
    <item>
      <title>pgbouncer 连接池</title>
      <link>https://zhangeamon.top/postgres/pgbouncer/</link>
      <pubDate>Thu, 27 Dec 2018 09:00:49 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pgbouncer/</guid>
      <description>背景介绍  Pgbouncer是一个针对PostgreSQL数据库的轻量级连接池
 pgbouncer 的目标是降低因为新连接到 PostgreSQL 的连接而导致的性能损失
  使用术语说明：
为了后面的描述更清晰，使用如下术语
 Client : 指访问者
 Pgboucer: 指连接池
 Postgres: 指数据库。 Connetions: 指彼此之间的连接  整体架构
原来: Client -&amp;gt; Postgres 现在: Client -&amp;gt; Pgbounce -&amp;gt; Postgres
优势 内存消耗低(默认为2k/连接)，因为Bouncer不需要每次都接受完整的数据包。
Postgres的连接是进程模型，pogbouncer 使用libevent进行socket 通信。
总结： 数据访问过程中建立连接很耗资源，pgboucer就是为了减少数据访问中的建立连接次数，重复利用已建立的连接进而缓解数据库压力。
三种连接池模型  session 会话级 ； 比较友好 transaction 事务级； 比较激进 statement 一个sql ； 客户端强制autocommit 模式  安装 查看当前系统中版本 yum list pgbouncer.x86_64 pgbouncer.x86_64 1.9.0-1.rhel7 升级到最新版 yum update pgbouncer.x86_64 安装 yum install pgbouncer.</description>
    </item>
    
    <item>
      <title>xargs 命令</title>
      <link>https://zhangeamon.top/linux/cmd-xargs/</link>
      <pubDate>Tue, 25 Dec 2018 10:18:26 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cmd-xargs/</guid>
      <description>http://www.cnblogs.com/wangqiguo/p/6464234.html</description>
    </item>
    
    <item>
      <title>sed 命令</title>
      <link>https://zhangeamon.top/linux/cmd-sed/</link>
      <pubDate>Tue, 25 Dec 2018 10:17:45 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cmd-sed/</guid>
      <description>概述 sed命令是一个面向字符流的非交互式编辑器，也就是说sed不允许用户与它进行交互操作。sed是按行来处理文本内容的。在shell中，使用sed来批量修改文本内容是非常方便的。
sed命令的选项 sed [选项] [动作] 选项与参数： -n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 -e ：直接在命令列模式上进行 sed 的动作编辑； -f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作； -r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) -i ：直接修改读取的文件内容，而不是输出到终端。 function： a ：新增行， a 的后面可以是字串，而这些字串会在新的一行出现(目前的下一行) c ：取代行， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行 d ：删除行，因为是删除，所以 d 后面通常不接任何参数，直接删除地址表示的行； i ：插入行， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行 s ：替换，可以直接进行替换的工作,通常这个 s 的动作可以搭配正规表示法，例如 1,20s/old/new/g 一般是替换符合条件的字符串而不是整行  一般function的前面会有一个地址的限制，例如 [地址]function，表示我们的动作要操作的行。下面我们通过具体的例子直观的看看sed的使用方法。</description>
    </item>
    
    <item>
      <title>awk 命令</title>
      <link>https://zhangeamon.top/linux/cmd-awk/</link>
      <pubDate>Tue, 25 Dec 2018 10:14:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cmd-awk/</guid>
      <description>What is awk 官网
man 告诉我们 pattern scanning and processing language
那么awk能做什么，awk适合做什么 ？ awk最常用的工作一般是遍历一个文件中的每一行，然后分别对文件的每一行进行处理。 由于awk天生提供对文件中文本分列进行处理，所以如果一个文件中的每行都被特定的分隔符(常见的是空格)隔开， 我们可以将这个文件看成是由很多列的文本组成，这样的文件最适合用awk进行处理，通过awk对你感兴趣的信息进行提取,其实awk在工作中很多时候被用来处理log文件，进行一些统计工作等。
如何使用 完整格式:
awk [options] &#39;BEGIN{ commands } pattern{ commands } END{ commands }&#39; file -F fs	--field-separator=fs  简单方式 对一行文本按照空行进行分割，并提取第3列内容 echo &#39;11 22 33 44&#39; | awk &#39;{print $3}&#39; 33 说明：默认分割符为空格; print 为awk 内置函数; $数字引用变量 多行处理 echo -e &#39;11 22 33 44\naa bb cc dd&#39; | awk &#39;{print $3}&#39; 33 cc 说明: -e 转换符\n 生效;  parttern 加入partter $1&amp;gt;2 echo -e &#39;1 2 3 4\n5 6 7 8&#39; | awk &#39;$1&amp;gt;2{print $3}&#39; 3 说明: $1&amp;gt;2 表示如果当前行的第1列的值大于2则处理当前行，否则不处理。 parttern 可以时任何表达式判断，例如&amp;gt;，&amp;lt;，==，&amp;gt;=，&amp;lt;=，!</description>
    </item>
    
    <item>
      <title>终端复用</title>
      <link>https://zhangeamon.top/linux/terminal-reuse/</link>
      <pubDate>Tue, 25 Dec 2018 10:06:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/terminal-reuse/</guid>
      <description> 背景 我们在linux服务器上的工作一般都是通过一个远程的终端连接软件连接到远端系统进行操作，例如使用xshell或者SecureCRT工具通过ssh进行远程连接。 在使用过程中，如果要做比较耗时的操作，例如有时候进行编译，或者下载大文件需要比较长的时间，一般情况下是下班之后直接运行希望第二天早上过来运行完成，这样就不用耽误工作时间。 但是网络有时候不稳定，可能在半夜会出现连接断掉的情况，一旦连接断掉，我们所执行的程序也就中断，我们当然可以写一个脚本后台运行，但是还是不方便。那么有没有一种工具可以解决这样的问题呢。
 tmux gux screen  详解 tmux screen 常用方法 安装 yum install screen  创建任务 cmd01 screen -S cmd01 进入命令界面 ， 输入长任务命令  退出方式 ctrl+A ctrl+d 回到主命令界面，任务继续执行 ctrl+C，ctrl+d 回到主命令界面，任务被强制结束  查看任务 screen -ls  重新进入任务 screen -r cmd01  </description>
    </item>
    
    <item>
      <title>Zabbix Postgres Fqa</title>
      <link>https://zhangeamon.top/monitor/zabbix-postgres-fqa/</link>
      <pubDate>Mon, 24 Dec 2018 17:18:11 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/zabbix-postgres-fqa/</guid>
      <description>如何使用篇  如何使用zabbix监控postgres  我们采用的是github中的开源项目zabbix-extensions中的postgres，iostat对Postgres数据库性能指标及系统IO进行监控。
以及对实体机进行监控，本文主要介绍对postgres的性能进行监控和分析
 如何在现有的数据库系统中加入监控，需要哪些条件  哪些条件
1 PostgreSQL version 9.4 and above
2 Zabbix 3.4 and newer
如何加入监控
1 在数据服务的主机中加入zabbix-agent，在cp files/postgresql/postgresql.conf /etc/zabbix/zabbix_agentd.d/，zabbix界面端加入对应模板
2 数据库访问权限，本地访问数据库权限，可在pg_hba.conf中设置， 加入一行&amp;rsquo;host all all 127.0.0.1&amp;frasl;32 trust&amp;rsquo;,这个权限有些大，根据自己的情况设置。
3 数据库中加入extends: pg_buffercache pg_stat_statements
以上所有操作不需要重启数据库， reload即可生效
 监控是如何连接到数据库的  使用模板中的宏定义
 {$PG_CONNINFO}=-h 127.0.0.1 -p 5432 -U postgres -d zabbix  如果现在一套zabbix系统中监控多个数据库，数据库的端口，用户名不统一时，可以在各自的hosts中的宏定义中分别设置各自的连接方式。
 如何指定哪些databases tables被监控  首先模板中包含3种自动发现机制分别是Discovery rule
PostgreSQL databases discovery 数据库中database
PostgreSQL database tables discovery 数据库中的table</description>
    </item>
    
    <item>
      <title>Zabbix FQA</title>
      <link>https://zhangeamon.top/monitor/zabbix-fqa/</link>
      <pubDate>Mon, 24 Dec 2018 16:53:20 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/zabbix-fqa/</guid>
      <description>如何使用篇  如何安装
  安装文档
架构模型为服务端、被监控端。
被监控端agent安装在需要被监控的主机上，负责收集被监控主机相关状态的信息指标如内存，cup，网络等。
服务端负责汇总所有agent的信息，如存储，处理，展现。数据存放在指定的数据库中如mysql pg。
需安装软件说明
zabbix-server-pgsql 服务端
zabbix-web-pgsql 服务端界面
zabbix-agent 被监控端，与被监控端安装在一起
 常用模块说明  Administration Users 新建属于自己的用户，禁用guest，慎用admin user 用户名 密码 media 接收信息 premissions 权限 Media type 媒体类型，用于配置发送报警媒介， Email或自定义脚本 Email 配置系统发送邮件 163为例 Name email Type Email SMTP server smtp.163.com SMTP server port 25 SMTP helo smtp.163.com SMTP email 注册的邮箱地址 Username 注册的用户名 password 密码 Configuration Hosts 管理被监控的主机 host 配置被监控的主机 Templates 监控的内容模版 Actions 触发报警时的动作，一般给管理员方法信息 Discovery 自动发现 Monitoring  FQA  Too Many Process  原因: 被监控的主机进程数过多或默认的触发条件过低 分析:</description>
    </item>
    
    <item>
      <title>Kworker </title>
      <link>https://zhangeamon.top/linux/kworker/</link>
      <pubDate>Mon, 24 Dec 2018 16:43:22 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/kworker/</guid>
      <description>名字的意思 Kernel Worker
什么时候有的 kworker是3.x内核引入的
这么看 系统中查看
Linux下使用 ps -ef|grep kowrker
显示的内容怎么看 显示的格式kworker/%u:%d%s
u：是unbound的缩写，代表没有绑定特定的CPU，kworker /u2:0中的 2 是 work_pool 的ID。
不带u的就是绑定特定cpu的workerq，它在init_workqueues中初始化，给每个cpu分配worker，如果该worker的nice小于0，说明它的优先级很高，所以就加了H属性。
具有负面价值的勤劳工人的名字后缀为&amp;rsquo;H&amp;rsquo;。
有什么用 kworker 进程是内核工作进程，并且有很多进程是无害的。 Linux系统中会将一个个的小任务分到不同的工作队列中，让工作队列里面的工人来完成
内核工作线程可以做任何事情，例如一些随机的例子：
做页面缓存写回 处理某些种类的硬件事件 (如硬件中断,定时器，I / O等) 很多很多其他的东西 要知道任何kworker在做什么，你可以看看cat /proc//stack。</description>
    </item>
    
    <item>
      <title>引起索引失效</title>
      <link>https://zhangeamon.top/postgres/index-invalid/</link>
      <pubDate>Thu, 20 Dec 2018 16:34:22 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/index-invalid/</guid>
      <description>简介 索引的作用，加速检索，排序，分组。
优点： 检索
缺点： 新增，更新时需要维护索引，占磁盘空间，创建时锁表。
维护： 根据统计表发生全表扫描次数，索引使用次数。合理添加删除索引。
索引失效的场景 如果where过滤条件设置不合理，即使索引存在，且where过滤条件中包含索引列，也会导致全表扫描，索引不起作用。什么条件下会导致索引失效呢？
1.任何计算、函数、类型转换
2.!=
3.NOT，相当于使用函数
4.模糊查询通配符在开头
5.索引字段在表中占比较高
6.多字段btree索引查询条件不包含第一列
7.多字段索引查询条件使用OR（有时也会走索引扫描，但查询效率不高）
8.表中数据量太少时
实例 测试表
创建表 postgres#=create table tbl_index(a bigint,b timestamp without time zone ,c varchar(12)); 插入1kw数据，打开计时器 对比创建索引对数据插入的影响。 postgres=# \timing Timing is on. postgres=# insert into tbl_index select generate_series(1,10000000),clock_timestamp()::timestamp without time zone,&#39;zhang&#39;; INSERT 0 10000000 Time: 25004.214 ms (00:25.004) postgres=# create index tbl_index_a ON tbl_index using btree (a); CREATE INDEX Time: 4119.733 ms (00:04.120) postgres=# create index tbl_index_b ON tbl_index using btree (b); CREATE INDEX Time: 6229.</description>
    </item>
    
    <item>
      <title>Access Modify Change 三种时间戳</title>
      <link>https://zhangeamon.top/linux/stat/</link>
      <pubDate>Thu, 20 Dec 2018 13:56:24 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/stat/</guid>
      <description>三种时间对应关系  访问时间 Access atime
 修改时间 Modify mtime 状态改动时间 Change ctime
  如何查看文件文件的三种时间戳 stat filename  三种时间戳的解释  访问时间：读一次文件的内容，这个时间就会更新。比如more、cat等命令。ls、stat命令不会修改atime
 修改时间：修改时间是文件内容最后一次被修改的时间。比如：vim操作后保存文件。ls -l列出的就是这个时间
 状态改动时间。是该文件的inode节点最后一次被修改的时间，通过chmod、chown命令修改一次文件属性，这个时间就会更新。
  应用举例 查看数据库的建立时间 数据库的oid
select oid , datname from pg_database ; oid | datname -------+------------- 13806 | postgres 1 | template1 13805 | template0 16629 | timescaledb 16646 | normaldb 16659 | pgwatch2 26557 | awr 42902 | pipelinedb (8 行记录)  对应的存放位置</description>
    </item>
    
    <item>
      <title>权限管理</title>
      <link>https://zhangeamon.top/postgres/role-manager/</link>
      <pubDate>Thu, 20 Dec 2018 09:54:28 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/role-manager/</guid>
      <description>创建用户 # user 与 role 区别 ， user 具有login权限 postgres=# create user tester with password &#39;123456&#39;; CREATE ROLE  创建数据库,并关联所有者 postgres=# create database test owner tester ; CREATE DATABASE  变更数据库用户所有者 postgres=# alter database test owner to tester; ALTER DATABASE  修改用户&amp;amp;数据库 #用户连接数 postgres=# alter user tester connection limit 100; ALTER ROLE #数据库连接数 postgres=# alter database test connection limit 100; ALTER DATABASE #用户其他属性修改 postgres=# alter user tester BYPASSRLS CREATEDB ENCRYPTED PASSWORD LOGIN NOCREATEDB NOINHERIT NOREPLICATION PASSWORD REPLICATION SET VALID UNTIL CONNECTION LIMIT CREATEROLE INHERIT NOBYPASSRLS NOCREATEROLE NOLOGIN NOSUPERUSER RENAME TO RESET SUPERUSER WITH #数据库其他属性修改 postgres=# alter database test ALLOW_CONNECTIONS CONNECTION LIMIT IS_TEMPLATE OWNER TO RENAME TO RESET SET  sql批量修改table/view的owner DO $$DECLARE r record; BEGIN FOR r IN SELECT tablename/viewname FROM pg_tables/pg_views WHERE schemaname = &#39;public&#39; LOOP EXECUTE &#39;alter table &#39;|| r.</description>
    </item>
    
    <item>
      <title>DBA 日常</title>
      <link>https://zhangeamon.top/postgres/dba/</link>
      <pubDate>Wed, 19 Dec 2018 11:33:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/dba/</guid>
      <description>备份 恢复 时时热备
定期冷备
升级 每年大版本小版本升级，新特性调研，性能测试，稳定性。 可用当前最新的上一个版本。
HA 手动
自动
读写分离 sharding 多副本
安全 权限管理 资源隔离
审计 ddl
慢sql
锁长时间占用
巡检 定期巡检 awr 报告
监控 系统
数据库
诊断 优化 背景 应用程序的野蛮生长，由产品为驱动的开发，一切以快速上线为目标，在快速迭代的输出中很难有质量的保证。
运维人员和dba往往会充当救火队员，进入恶性循环。程序或架构设计不合理，导致数据库使用性能不佳，稍微来点业务量就导致数据库负载升高影响业务。
怎么办 梳理责任划分 必须有明确的责任划分，并不是程序上线后除了问题全部都是运维人员的责任，如果是程序的问题导致的故障，应该将责任追究到研发团队。
追责可以作为研发与运维的共同KPI考核指标，这样研发才有动力把程序开发好，而不是野蛮瞎搞。
建立程序交付标准 必须建立应用交付给运维的交付标准，程序上线前，必须要符合运行交付标准才允许上线。
必须包括试运行 商用前，必须有试运行阶段。建立约束机制，例如试运行阶段如果有N次应用引起的故障或已发现运行过程中的程序BUG，研发必须全部解决后，才允许商用。
变更制度 建立变更制度，操作规范，尽量避免变更带来的问题。
开发规约 事前防范，建立开发规约，避免开发阶段引入的问题。
培训 经常给开发培训，让他们熟悉数据库的最佳实践，避免踩坑。
SQL审核机制 建立自动化或人为的审核机制，涉及数据库变更，新增SQL都必须经过审核。
数据库生命周期管理 建立健全的生命周期管理制度。</description>
    </item>
    
    <item>
      <title>ln -s 建立软连接</title>
      <link>https://zhangeamon.top/linux/ln-s/</link>
      <pubDate>Wed, 19 Dec 2018 09:19:19 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/ln-s/</guid>
      <description> 创建软连接 类似于windows中的创建快捷方式
ln -s source target
具体方法举例
需求
数据库的数据实际存放位置为 /data/pgsql/10/data/
数据库的应用访问地址为 /var/lib/pgsql/10/data/
创建软连接
1 切换目录到需要创建快捷方式的文件目录
cd /var/lib/pgsql/10/  2.1 创建软连接
ln -s /data/pgsql/10/data/ data  2.2 删除软连接
rm data  删除软连接和数据
rm data/  3 权限和所有者
chmod chown  修改软连接的所用者 使用 -h 参数
chown -h postgres:postgres data/  </description>
    </item>
    
    <item>
      <title>hdparm 查看硬盘型号</title>
      <link>https://zhangeamon.top/linux/hdparm/</link>
      <pubDate>Wed, 19 Dec 2018 08:53:10 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/hdparm/</guid>
      <description>安装工具 yum install hdparm  查看 -i参数是在引导驱动器时获得的识别信息，这个信息有时候不完整也不一 定准确
hdparm -i /dev/sdb /dev/sdb: Model=INTEL SSDSC2KW512G8, FwRev=LHF002C, SerialNo=PHLA75210153512DGN Config={ Fixed } RawCHS=16383/16/63, TrkSize=0, SectSize=0, ECCbytes=0 BuffType=unknown, BuffSize=unknown, MaxMultSect=16, MultSect=off CurCHS=16383/16/63, CurSects=16514064, LBA=yes, LBAsects=1000215216 IORDY=on/off, tPIO={min:120,w/IORDY:120}, tDMA={min:120,rec:120} PIO modes: pio0 pio3 pio4 DMA modes: mdma0 mdma1 mdma2 UDMA modes: udma0 udma1 udma2 udma3 udma4 udma5 *udma6 AdvancedPM=yes: unknown setting WriteCache=enabled Drive conforms to: unknown: ATA/ATAPI-2,3,4,5,6,7 * signifies the current active mode  -I参数是直接从驱动器获取识别信息, 并以原始的,未经过修改和更正的形式显示</description>
    </item>
    
    <item>
      <title>扁鹊三兄弟</title>
      <link>https://zhangeamon.top/about/3brothers/</link>
      <pubDate>Mon, 17 Dec 2018 14:28:31 +0800</pubDate>
      
      <guid>https://zhangeamon.top/about/3brothers/</guid>
      <description>系统运维与安全的三种境界
封侯非我意， 我愿海波平。 -- 戚继光  </description>
    </item>
    
    <item>
      <title>数据库三范式五约束</title>
      <link>https://zhangeamon.top/postgres/normal-form/</link>
      <pubDate>Mon, 17 Dec 2018 10:27:04 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/normal-form/</guid>
      <description> 三范式  第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；  -- 1NF 第一范式 字段不能再分，就满足第一范式。 -- 2NF 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除联合主键可以避免部分依赖。增加单列关键字。 -- 3NF 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。  第二范式（2NF）和第三范式（3NF）的概念很容易混淆，区分它们的关键点在于，2NF：非主键列是否完全依赖于主键，还是依赖于主键的一部分；3NF：非主键列是直接依赖于主键，还是直接依赖于非主键列。
举例说明：
关系表（A，B，C，D）中A，B是候选键，那么：（A，B）→ C （A，B）→ D
2NF : 不能存在非主属性部分依赖主键 如: B → C 或 A → C 等。当主键为多值联合主键时可能会存在违反2NF
3NF : 不能存在非主属性之间的传递依赖 如: C → D 或 D → C
BCNF : 不能存在主属性之间的传递依赖 如 : A → B 或 B → A
五约束  primary KEY:设置主键约束； UNIQUE：设置唯一性约束，不能有重复值； DEFAULT 默认值约束 NOT NULL：设置非空约束，该字段不能为空； FOREIGN key :设置外键约束。  </description>
    </item>
    
    <item>
      <title>快速生成大量数据</title>
      <link>https://zhangeamon.top/postgres/insert01/</link>
      <pubDate>Fri, 14 Dec 2018 13:13:57 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/insert01/</guid>
      <description>在数据库中快速生成1w条数据，或测试数据库的写入性能。 创建数据库表 postgres=# create table tbl(id int, info text, crt_time timestamp); CREATE TABLE  方法一 generate_series 查看方法函数 postgres=# \df generate_series 函数列表 架构模式 | 名称 | 结果数据类型 | 参数数据类型 | 类型 ------------+-----------------+-----------------------------------+--------------------------------------------------------------------+------ pg_catalog | generate_series | SETOF bigint | bigint, bigint | 常规 pg_catalog | generate_series | SETOF bigint | bigint, bigint, bigint | 常规 pg_catalog | generate_series | SETOF integer | integer, integer | 常规 pg_catalog | generate_series | SETOF integer | integer, integer, integer | 常规 pg_catalog | generate_series | SETOF numeric | numeric, numeric | 常规 pg_catalog | generate_series | SETOF numeric | numeric, numeric, numeric | 常规 pg_catalog | generate_series | SETOF timestamp without time zone | timestamp without time zone, timestamp without time zone, interval | 常规 pg_catalog | generate_series | SETOF timestamp with time zone | timestamp with time zone, timestamp with time zone, interval | 常规 (8 行记录) postgres=# insert into tbl select id, md5(random()::text), clock_timestamp() from generate_series(1,10000) t(id); INSERT 0 10000  方法二 pgbench vi test.</description>
    </item>
    
    <item>
      <title>Pipelinedb 简介</title>
      <link>https://zhangeamon.top/postgres/pipelinedb02/</link>
      <pubDate>Wed, 12 Dec 2018 11:39:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pipelinedb02/</guid>
      <description>项目已经停止维护 适配支持版本
PostgreSQL 10: 10.1, 10.2, 10.3, 10.4, 10.5 PostgreSQL 11: 11.0  基本概念 流(Stream) 流是基础，Continuous Views和transform则是基于流中的数据进行处理的手段。 对于同一份数据，只需要定义一个流，写入一份即可。 如果对同一份数据有多个维度的统计，可以写在一条SQL完成的（如同一维度的运算或者可以支持窗口的多维度运算），只需定义一个Continuous Views或transform。如果不能在同一条SQL中完成计算，则定义多个Continuous Views或transform即可。 如果有多份数据来源（例如设计时就已经区分了不同的表）时，定义不同的流即可；
流视图 流视图，其实就是定义统计分析的QUERY， 例如select id, count(*), avg(x), &amp;hellip; from stream_1 group by &amp;hellip;; 就属于一个流视图。 定义好之后，数据插入流(stream_1)，这个流视图就会不断增量的进行统计，你只要查询这个流视图，就可以查看到实时的统计结果。 数据库中存储的是实时统计的结果（实际上是在内存中进行增量合并的，增量的方式持久化）。
Transforms 与流视图不同的是，transform是用来触发事件的，所以它可以不保留数据，但是可以设定条件，当记录满足条件时，就触发事件。 例如监视传感器的值，当值的范围超出时，触发报警（如通过REST接口发给指定的server），或者将报警记录下来（通过触发器函数）。
支持特性 pipelinedb继承了PostgreSQL很好的扩展性，例如支持了概率统计相关的功能，例如HLL等。用起来也非常的爽，例如统计网站的UV，或者红绿灯通过的汽车编号唯一值车流，通过手机信号统计基站辐射方圆多少公里的按时UV等。 Bloom Filter
Count-Min Sketch
Filtered-Space Saving Top-K
HyperLogLog
T-Digest
滑窗(Sliding Windows) 因为很多场景的数据有时效，或者有时间窗口的概念，所以pipelinedb提供了窗口分片的接口，允许用户对数据的时效进行定义。 例如仅仅统计最近一分钟的时间窗口内的统计数据。 比如热力图，展示最近一分钟的热度，对于旧的数据不关心，就可以适应SW进行定义，从而保留的数据少，对机器的要求低，效率还高。
安装 base on centos7&amp;amp;postgres10 add repository curl -s http://download.pipelinedb.com/yum.sh | sudo bash pipeline package sudo yum install pipelinedb-postgresql-10 修改数据库配置 # At the bottom of &amp;lt;data directory&amp;gt;/postgresql.</description>
    </item>
    
    <item>
      <title>Pipelinedb文档概览</title>
      <link>https://zhangeamon.top/postgres/pipelinedb01/</link>
      <pubDate>Wed, 12 Dec 2018 09:46:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pipelinedb01/</guid>
      <description>官方文档
介绍 What PipelineDB is
What PipelineDB is not
QuitStart 一个统计wiki浏览的例子
安装 各种环境安装
Continuous Views 定义流视图，其实就是定义 统计分析的QUERY， 例如select id, count(*), avg(x), &amp;hellip; from table group by &amp;hellip;; 定义好之后，数据插入table，这个流视图就会不断增量的进行统计，你只要查询这个流视图，就可以查看到实时的统计结果。 数据库中存储的是实时统计的结果（实际上是在内存中进行增量合并的，增量的方式持久化）。
CREATE CONTINUOUS VIEW
DROP CONTINUOUS VIEW
TRUNCATE CONTINUOUS VIEW
Viewing Continuous Views
Data Retrieval
Time-to-Live (TTL) Expiration
Activation and Deactivation
Examples
Continuous Transforms 与流视图不同的是，transform是用来转换数据流的，所以它可以不保留数据，但是可以设定条件，当记录满足条件时，就触发事件。
用途，将输入的数据流进行转换处理，过滤，加工等，用于复杂的业务逻辑，比如多个来源的数据流的合并加工。与现有的表进行joins操作,可以将结果传入其他流中，实现持续转换。
例如监视传感器的值，当值的范围超出时，触发报警（如通过REST接口发给指定的server），或者将报警记录下来（通过触发器函数）。
CREATE CONTINUOUS TRANSFORM
DROP CONTINUOUS TRANSFORM
Viewing Continuous Transforms
Built-in Transform Triggers
Creating Your Own Trigger</description>
    </item>
    
    <item>
      <title>常用监控介绍</title>
      <link>https://zhangeamon.top/monitor/introduce/</link>
      <pubDate>Fri, 07 Dec 2018 11:32:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/introduce/</guid>
      <description>zabbix
zabbix-extensions
promethues
osquery
m/monit</description>
    </item>
    
    <item>
      <title>学习参考</title>
      <link>https://zhangeamon.top/python/reference/</link>
      <pubDate>Fri, 07 Dec 2018 11:24:11 +0800</pubDate>
      
      <guid>https://zhangeamon.top/python/reference/</guid>
      <description>廖雪峰 Python3
草根学 Python （基于Python3.6)</description>
    </item>
    
    <item>
      <title>云存储介绍</title>
      <link>https://zhangeamon.top/storage/introduce/</link>
      <pubDate>Fri, 07 Dec 2018 11:04:12 +0800</pubDate>
      
      <guid>https://zhangeamon.top/storage/introduce/</guid>
      <description>对象存储(oss) 适用于大量的小文件，RESFULL接口方式存储读取迅速,不能修改，不用担心元数据过大问题。通常的架构为使用其他的数据库软件如(Hbase,ES) 等来存放管理元数据。
swift minio
块存储 这种接口通常以QEMU Driver或者Kernel Module的方式存在，这种接口需要实现Linux的Block Device的接口或者QEMU提供的Block Driver接口，如Sheepdog，AWS的EBS，青云的云硬盘和阿里云的盘古系统，还有Ceph的RBD(RBD是Ceph面向块存储的接口)。 理解成一块硬盘
ceph
文件存储 支持POSIX接口，对应的传统的文件系统有Ext3、Ext4等，与传统文件系统的区别在于分布式存储提供了并行化的能力，如Ceph的CephFS，但是有时候又会把GFS，HDFS这种非POSIX接口的类文件存储接口归入此类 理解成格式化后的文件
glusterfs
fastfs</description>
    </item>
    
    <item>
      <title>集群部署安装</title>
      <link>https://zhangeamon.top/k8s/install/</link>
      <pubDate>Fri, 07 Dec 2018 10:48:00 +0800</pubDate>
      
      <guid>https://zhangeamon.top/k8s/install/</guid>
      <description>kubeadm kubeadm 可当做体验版，证书可用时间一年
Kubespray Kubespray 是 Kubernetes incubator 中的项目，目标是提供 Production Ready Kubernetes 部署方案，该项目基础是通过 Ansible Playbook 来定义系统与 Kubernetes 集群部署的任务，具有以下几个特点：
 可以部署在 AWS, GCE, Azure, OpenStack 以及裸机上.
 部署 High Available Kubernetes 集群.
 可组合性 (Composable)，可自行选择 Network Plugin (flannel, calico, canal, weave) 来部署.
 多种 Linux distributions(CoreOS, Debian Jessie, Ubuntu 16.04, CentOS/RHEL7).
  kops kops 是一个生产级 Kubernetes 集群部署工具，可以在 AWS、GCE、VMWare vSphere 等平台上自动部署高可用的 Kubernetes 集群。主要功能包括
 自动部署高可用的 kubernetes 集群 支持从 kube-up 创建的集群升级到 kops 版本</description>
    </item>
    
    <item>
      <title>Postgres 监控</title>
      <link>https://zhangeamon.top/postgres/monitor/</link>
      <pubDate>Thu, 06 Dec 2018 16:21:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/monitor/</guid>
      <description>各种监控方式  zabbix Monitor PostgreSQL with Zabbix
 postgres_exporter A PostgresSQL metric exporter for Prometheus
 pgwatch2 PostgreSQL metrics monitor/dashboard
 pgmetrics Collect and display information and stats from a running PostgreSQL server
 pgdash (收费)
 pganalyze PostgreSQL Performance Monitoring
 参考自己实现
  状态查看 pgcenter
pgcenter top pgcenter: 2018-12-20 11:10:25, load average: 0.94, 0.84, 0.86 state [ok]: ::1:5432 postgres@postgres (ver: 10.6, up 8 days 19:57:54, recovery: f) %cpu: 15.</description>
    </item>
    
    <item>
      <title>Linux 系统性能检测</title>
      <link>https://zhangeamon.top/linux/sysstat/</link>
      <pubDate>Thu, 06 Dec 2018 14:58:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/sysstat/</guid>
      <description>整体篇 安装
yum install sysstat -y   top htop atop vmstat -wt 1 dstat  内存篇 由于Linux 内存的占用属于饥饿式，所以看到的结果只能作为参考
cat /proc/meminfo
结果具体含义
I/O 篇 整体io情况
iostat -dmx 1 Linux 3.10.0-862.14.4.el7.x86_64 (rjyd) 2018年12月06日 _x86_64_	(40 CPU) Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util sda 0.00 0.05 0.06 0.11 0.00 0.00 53.87 0.00 1.35 0.60 1.78 0.23 0.00 sdb 0.00 0.02 0.08 6.65 0.00 0.</description>
    </item>
    
    <item>
      <title>tablespace 表空间</title>
      <link>https://zhangeamon.top/postgres/tablespace/</link>
      <pubDate>Thu, 06 Dec 2018 11:17:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/tablespace/</guid>
      <description>原文
注意主从架构时，主从软连接位置需要对应一致。
思考： 冷热数据分离 冷数据对热数据的影响，垃圾回收机制。</description>
    </item>
    
    <item>
      <title>TOAST 技术</title>
      <link>https://zhangeamon.top/postgres/toast/</link>
      <pubDate>Thu, 06 Dec 2018 11:14:20 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/toast/</guid>
      <description>原文</description>
    </item>
    
    <item>
      <title>fillfactor 填充因子</title>
      <link>https://zhangeamon.top/postgres/fillfactor/</link>
      <pubDate>Thu, 06 Dec 2018 11:01:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/fillfactor/</guid>
      <description>介绍 PostgreSQL每个表和索引的数据都是由很多个固定尺寸的页面存储（通常是 8kB，不过在编译服务器时[–with-blocksize]可以选择其他不同的尺寸）
一个表的填充因子(fillfactor)是一个介于 10 和 100 之间的百分数。100(完全填充)是默认值。如果指定了较小的填充因子，INSERT 操作仅按照填充因子指定的百分率填充表页。每个页上的剩余空间将用于在该页上更新行，这就使得 UPDATE 有机会在同一页上放置同一条记录的新版本，这比把新版本放置在其它页上更有效。对于一个从不更新的表将填充因子设为 100 是最佳选择，但是对于频繁更新的表，较小的填充因子则更加有效。
PostgresSQL 使用Heap-Only Tuple 技术 会在旧行与新行之间建立一个链表，这样一来就不需要更新索引了，索引项仍会指向旧行，通过链表可以找到新行。因此Heap-Only Tuple 的链表不能跨数据块。
示例 create table t_fillfactor01(id int ,name varchar , blog text ) WITH (fillfactor=70); CREATE TABLE new_test=# \d+ t_fillfactor01 Table &amp;quot;public.t_fillfactor01&amp;quot; Column | Type | Modifiers | Storage | Stats target | Description --------+-------------------+-----------+----------+--------------+------------- id | integer | | plain | | name | character varying | | extended | | blog | text | | extended | | Options: fillfactor=70  测试 /**************************************************************************************** 创建测试表 test1设置fillfactor=100 test2设置fillfactor=80 drop table if exists test1; drop table if exists test2; ****************************************************************************************/ create table test1( objectid bigserial not null, --唯一编号，主键 name text not null, --名称 describe text, --备注 generate timestamptz default now() not null,--创建日期 constraint pk_test1_objectid primary key(objectid) )with (fillfactor=100); create table test2( objectid bigserial not null, --唯一编号，主键 name text not null, --名称 describe text, --备注 generate timestamptz default now() not null,--创建日期 constraint pk_test2_objectid primary key(objectid) )with (fillfactor=80); /**************************************************************************************** 创建随机生成中文字符函数 drop function if exists gen_random_zh(int,int); ****************************************************************************************/ create or replace function gen_random_zh(int,int) returns text as $$ select string_agg(chr((random()*(20901-19968)+19968 )::integer) , &#39;&#39;) from generate_series(1,(random()*($2-$1)+$1)::integer); $$ language sql; /**************************************************************************************** 导入测试数据 ****************************************************************************************/ insert into test1(name) select gen_random_zh(8,32) from generate_series(1,10000); insert into test2(name) select gen_random_zh(8,32) from generate_series(1,10000); /**************************************************************************************** 查看test1数据在页中的布局 ****************************************************************************************/ select ctid,objectid from test1 limit 500; 略 select ctid,objectid from test2 limit 500; 略 ---test1 --- fillfactor = 100 select ctid from test1 where objectid = 93; ctid -------- (1,18) (1 row) update test1 set name=gen_random_zh(8,32) where objectid = 93; select ctid from test1 where objectid = 93; ctid ---------- (133,31) (1 row) --test2 --- fillfactor = 80 select ctid from test2 where objectid = 93; ctid -------- (1,32) (1 row) update test2 set name=gen_random_zh(8,32) where objectid = 93; select ctid from test2 where objectid = 93; ctid -------- (1,58) (1 row) ---------------------  可以看到test1中因为填充率为100%,update后第一页中没有位置存储新的数据了,所以检查最大的页文件是否还有位置,如果有直接插入,如果没有则再新建一页后插入,在本例中跳过了132个页文件.</description>
    </item>
    
    <item>
      <title>vacuum 垃圾回收器</title>
      <link>https://zhangeamon.top/postgres/vacuum/</link>
      <pubDate>Wed, 05 Dec 2018 16:48:00 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/vacuum/</guid>
      <description>介绍 数据库总是不断地在执行删除，更新等操作。良好的空间管理非常重要，能够对性能带来大幅提高。在postgresql中用于维护数据库磁盘空间的工具是VACUUM，其重要的作用是删除那些已经标示为删除的数据并释放空间。 postgresql中执行delete,update操作后，表中的记录只是被标示为删除状态，并没有释放空间，在以后的update或insert操作中该部分的空间是不能够被重用的。经过vacuum清理后，空间才能得到释放。
意义 PostgreSQL每个表和索引的数据都是由很多个固定尺寸的页面存储（通常是 8kB，不过在编译服务器时[–with-blocksize]可以选择其他不同的尺寸）
PostgreSQL中数据操作永远是Append操作,具体含义如下:
 insert 时向页中添加一条数据 update 将历史数据标记为无效,然后向页中添加新数据 delete 将历史数据标记为无效
  因为这个特性,所以需要定期对数据库vacuum,否则会导致数据库膨胀,建议打开autovacuum.
文法 VACUUM [ ( { FULL | FREEZE | VERBOSE | ANALYZE | DISABLE_PAGE_SKIPPING } [, ...] ) ] [ table_name [ (column_name [, ...] ) ] ] VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ table_name ] VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] ANALYZE [ table_name [ (column_name [, .</description>
    </item>
    
    <item>
      <title>Explain 执行计划</title>
      <link>https://zhangeamon.top/postgres/explain/</link>
      <pubDate>Wed, 05 Dec 2018 15:27:30 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/explain/</guid>
      <description>文法 EXPLAIN [ ( option [, ...] ) ] statement EXPLAIN [ ANALYZE ] [ VERBOSE ] statement 这里 option可以是： ANALYZE [ boolean ] VERBOSE [ boolean ] COSTS [ boolean ] BUFFERS [ boolean ] TIMING [ boolean ] SUMMARY [ boolean ] FORMAT { TEXT | XML | JSON | YAML }  注意事项 记住当使用了ANALYZE选项时语句会被实际执行. 如执行dml 时将对数据库进行实际的操作。
避免污染数据的方式
BEGIN; EXPLAIN ANALYZE ...; ROLLBACK;  一个例子 postgres=# explain analyze select * from tbl; QUERY PLAN ------------------------------------------------------------------------------------------------------------------ Seq Scan on tbl (cost=0.</description>
    </item>
    
    <item>
      <title>Nginx log 切割</title>
      <link>https://zhangeamon.top/docker/nginx-log/</link>
      <pubDate>Wed, 05 Dec 2018 11:00:10 +0800</pubDate>
      
      <guid>https://zhangeamon.top/docker/nginx-log/</guid>
      <description> Docker nginx 日志切割 docker 在运行 nginx 日志容器时，将日志挂载到实体机/var/log/nginx/* .log　中.
一般直接运行的nginx服务都会自带logrotate进行日志切分, 由docker方式安装的nginx 缺失日志切割功能!
添加logrotate cat /etc/logrotate.d/nginx
/var/log/nginx/*.log { daily missingok rotate 52 compress delaycompress notifempty create 666 root root sharedscripts postrotate # [ -f /var/run/nginx.pid ] &amp;amp;&amp;amp; kill -USR1 `cat /var/run/nginx.pid` docker inspect -f &#39;{{ .State.Pid }}&#39; nginx | xargs kill -USR1 endscript }  </description>
    </item>
    
    <item>
      <title>Centos FTP 服务</title>
      <link>https://zhangeamon.top/middleware/vsftp/</link>
      <pubDate>Wed, 05 Dec 2018 09:24:29 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/vsftp/</guid>
      <description>利用vsftpd 搭建FTP 服务器 安装 yum -y install vsftpd  添加用户及设置密码 useradd -s /sbin/nologin -d /home/ftp_test ftp_test passwd ftp_test  -s 禁止ssh登录主机
-d 设置ftp_test 用户home 目录，用于存放数据
基础配置 vi /etc/vsftpd/vsftpd.conf
# 禁止匿名访问 anonymous_enable=NO # 禁止dns解析 reverse_lookup_enable=NO  启动&amp;amp;开机自启 systemctl start vsftpd.service systemctl enable vsftpd.service  filezilla 客户端验证 host: 服务器IP port: 默认 user: password:  测试本地上传，远程下载，一切OK,感觉那么顺畅完美。
but可以访问到服务器中的所有文件和目录,似乎权限也忒大了。
接下来是入坑时间，有史以来最折磨的经历，总结出如下绕坑指南。
限制只能访问用户自己的目录，对其他目录不可见 vi /etc/vsftpd/vsftpd.conf
chroot_local_user=YES chroot_list_enable=YES # (default follows) chroot_list_file=/etc/vsftpd/chroot_list  创建文件
touch /etc/vsftpd/chroot_list  chroot_list 中的用户不受限制</description>
    </item>
    
    <item>
      <title>数据库日志</title>
      <link>https://zhangeamon.top/postgres/log/</link>
      <pubDate>Tue, 04 Dec 2018 15:45:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/log/</guid>
      <description>介绍 PostgreSQL有3种日志，分别是pg_log（数据库运行日志）、pg_xlog（WAL 日志，即重做日志）、pg_clog（事务提交日志，记录的是事务的元数据） postgres 10 版本将文件目录结构改为 log，pg_wal，pg_xact log默认是关闭的，需要设置其参数。wal和xact都是强制打开的，无法关闭。 本文主要介绍　log 能
配置 语法:
修改　ALTER SYSTEM SET 参数=值;
查看　show 参数;
重新启动数据库生效;
启用pg_log并配置日志参数
ALTER SYSTEM SET log_destination = &#39;csvlog&#39;; ALTER SYSTEM SET logging_collector = on; ALTER SYSTEM SET log_filename = &#39;postgresql-%Y-%m-%d_%H%M%S.log&#39;; ALTER SYSTEM SET log_rotation_age = &#39;1d&#39;; ALTER SYSTEM SET log_rotation_size = &#39;100MB&#39;; ALTER SYSTEM SET log_min_messages = &#39;info&#39;;  记录日志信息
ALTER SYSTEM SET log_checkpoints = on; ALTER SYSTEM SET log_connections = on; ALTER SYSTEM SET log_disconnections = on; ALTER SYSTEM SET log_duration = on; ALTER SYSTEM SET log_line_prefix = &#39;%m&#39;;  记录执行慢的SQL 记录超过该时长的所有SQL，对找出当前数据库的慢查询很有效。时间单位ms</description>
    </item>
    
    <item>
      <title>fio 硬盘性能测试</title>
      <link>https://zhangeamon.top/linux/fio/</link>
      <pubDate>Tue, 04 Dec 2018 10:30:48 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/fio/</guid>
      <description>基本概念 使用FIO之前，首先要有一些SSD性能测试的基础知识。 包括线程，队列深度，Offset，同步异步，DirectIO，BIO。
线程 线程指的是同时有多少个读或写任务在并行执行，一般来说，CPU里面的一个核心同一时间只能运行一个线程。如果只有一个核心，要想运行多线程，只能使用时间切片，每个线程跑一段时间片，所有线程轮流使用这个核心。Linux使用Jiffies来代表一秒钟被划分成了多少个时间片，一般来说Jiffies是1000或100，所以时间片就是1毫秒或10毫秒。
同步 一般电脑发送一个读写命令到SSD只需要几微秒，但是SSD要花几百微秒甚至几毫秒才能执行完这个命令。如果发一个读写命令，然后线程一直休眠，等待结果回来才唤醒处理结果，这种叫做同步模式。可以想象，同步模式是很浪费SSD性能的，因为SSD里面有很多并行单元，比如一般企业级SSD内部有8-16个数据通道，每个通道内部有4-16个并行逻辑单元（LUN，Plane），所以同一时间可以执行32-256个读写命令。同步模式就意味着，只有其中一个并行单元在工作，暴殄天物。
异步 为了提高并行性，大部分情况下SSD读写采用的是异步模式。就是用几微秒发送命令，发完线程不会傻傻的在那里等，而是继续发后面的命令。如果前面的命令执行完了，SSD通知会通过中断或者轮询等方式告诉CPU，CPU来调用该命令的回调函数来处理结果。这样的好处是，SSD里面几十上百个并行单元大家都能分到活干，效率暴增。
队列深度 不过，在异步模式下，CPU不能一直无限的发命令到SSD。比如SSD执行读写如果发生了卡顿，那有可能系统会一直不停的发命令，几千个，甚至几万个，这样一方面SSD扛不住，另一方面这么多命令会很占内存，系统也要挂掉了。这样，就带来一个参数叫做队列深度。举个例子，队列深度64就是说，系统发的命令都发到一个大小为64的队列，如果填满了就不能再发。等前面的读写命令执行完了，队列里面空出位置来，才能继续填命令。
offset 一个SSD或者文件有大小，测试读写的时候设置Offset就可以从某个偏移地址开始测试。比如从offset=4G的偏移地址开始。
DirectIO Linux读写的时候，内核维护了缓存，数据先写到缓存，后面再后台写到SSD。读的时候也优先读缓存里的数据。这样速度可以加快，但是一旦掉电缓存里的数据就没了。所以有一种模式叫做DirectIO，跳过缓存，直接读写SSD。
BIO Linux读写SSD等块设备使用的是BIO，Block-IO，这是个数据结构，包含了数据块的逻辑地址LBA，数据大小和内存地址等。
安装 官网地址
./configure;make &amp;amp;&amp;amp; make install  DEMO 如果缺失libaio驱动引擎可通过 yum install -y libaio-devel 安装后重新编译安装
fio -rw=randwrite -ioengine=libaio -direct=1 -thread -numjobs=1 -iodepth=64 -filename=/data/1.data -size=10G \ -name=job1 -offset=0MB -bs=4k -name=job2 -offset=10G -bs=16k \ -output TestResult.log  简单说明
fio：软件名称。 -rw=randwrite：读写模式，randwrite是随机写测试，还有顺序读read，顺序写write，随机读randread，混合读写等。 -ioengine=libaio：libaio指的是异步模式，如果是同步就要用sync。 -direct=1：是否使用directIO。 -thread：使用pthread_create创建线程，另一种是fork创建进程。进程的开销比线程要大，一般都采用thread测试。 –numjobs=1：每个job是1个线程，这里用了几，后面每个用-name指定的任务就开几个线程测试。所以最终线程数=任务数* numjobs。 -iodepth=64：队列深度64. -filename=/dev/sdb4：数据写到/dev/sdb4这个盘（块设备）。这里可以是一个文件名，也可以是分区或者SSD。 -size=10G：每个线程写入数据量是10GB。 -name=job1：一个任务的名字，名字随便起，重复了也没关系。这个例子指定了job1和job2，建立了两个任务，共享-name=job1之前的参数。-name之后的就是这个任务独有的参数。 -offset=0MB：从偏移地址0MB开始写。 -bs=4k：每一个BIO命令包含的数据大小是4KB。一般4KB IOPS测试，就是在这里设置。 -output TestResult.log：日志输出到TestResult.log。  结果查看 TestResult.</description>
    </item>
    
    <item>
      <title>smartctl 硬盘检测</title>
      <link>https://zhangeamon.top/linux/smartctl/</link>
      <pubDate>Mon, 03 Dec 2018 14:21:00 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/smartctl/</guid>
      <description>SMART 简介 S.M.A.R.T.，全称为“Self-Monitoring Analysis and Reporting Technology”，即“自我监测、分析及报告技术”。是一种自动的硬盘状态检测与预警系统和规范。通过在硬盘硬件内的检测指令对硬盘的硬件如磁头、盘片、马达、电路的运行情况进行监控、记录并与厂商所设定的预设安全值进行比较，若监控情况将或已超出预设安全值的安全范围，就可以通过主机的监控硬件或软件自动向用户作出警告并进行轻微的自动修复，以提前保障硬盘数据的安全。除一些出厂时间极早的硬盘外，现在大部分硬盘均配备该项技术。
SMART是一种磁盘自我分析检测技术，早在90年代末就基本得到了普及每一块硬盘(包括IDE、SCSI)在运行的时候，都会将自身的若干参数记录下来这些参数包括型号、容量、温度、密度、扇区、寻道时间、传输、误码率等，当硬盘运行了几千小时后，很多内在的物理参数都会发生变化某一参数超过报警阈值，则说明硬盘接近损坏，此时硬盘依然在工作，如果用户不理睬这个报警继续使用那么硬盘将变得非常不可靠，随时可能故障导致数据丢失。
SMART 安装 yum install smartmontools.x86_64 -y  基本用法 smartctl --scan 扫描当前系统中所有支持SMART的设备 smartctl -i /dev/sda 查看设备SMART是否开启 smartctl -s on /dev/sda 将设备SMART开启 smartctl -a /dev/sda 仅显示设备的所有 SMART 属性信息 smartctl -x /dev/sda 显示设备的所有属性信息 smartctl -H /dev/sda 查看设备的自检评估结果 smartctl -a &amp;lt;device&amp;gt; 检查该设备是否已经打开SMART技术。 smartctl -s on &amp;lt;device&amp;gt; 如果没有打开SMART技术，使用该命令打开SMART技术。 smartctl -t short &amp;lt;device&amp;gt; 后台检测硬盘，消耗时间短。 smartctl -t long &amp;lt;device&amp;gt; 后台检测硬盘，消耗时间长。 smartctl -C -t short &amp;lt;device&amp;gt; 前台检测硬盘，消耗时间短。 smartctl -C -t long &amp;lt;device&amp;gt; 前台检测硬盘，消耗时间长。其实就是利用硬盘SMART的自检程序。 smartctl -X &amp;lt;device&amp;gt; 中断后台检测硬盘。 smartctl -l selftest &amp;lt;device&amp;gt; 显示硬盘检测日志。 smartctl -l error &amp;lt;device&amp;gt; 显示硬盘错误汇总。  硬盘信息</description>
    </item>
    
    <item>
      <title>mdadm 软Raid 管理</title>
      <link>https://zhangeamon.top/linux/mdadm/</link>
      <pubDate>Mon, 03 Dec 2018 13:39:39 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/mdadm/</guid>
      <description>背景 mdadm是linux下用于创建和管理软件RAID的命令，是一个模式化命令。但由于现在服务器一般都带有RAID阵列卡，并且RAID阵列卡也很廉价，且由于软件RAID的自身缺陷（不能用作启动分区、使用CPU实现，降低CPU利用率），因此在生产环境下并不适用。但为了学习和了解RAID原理和管理，因此仍然进行一个详细的讲解：
安装 yum install mdadm -y  组建raid 组装raid mdadm -C /dev/md0 -a yes -n 4 -l 10 /dev/sdb /dev/sdc /dev/sdd /dev/sde 说明 : 专用选项： -l 级别 -n 设备个数 -a {yes|no} 自动为其创建设备文件 -c 指定数据块大小（chunk） -x 指定空闲盘（热备磁盘）个数，空闲盘（热备磁盘）能在工作盘损坏后自动顶替 注意：创建阵列时，阵列所需磁盘数为-n参数和-x参数的个数和  查看状态, 组装进度等 mdadm -D /dev/md0 也可以通过mdstat查看状态 cat /proc/mdstat Personalities : [raid10] md127 : active raid10 sdd[2] sda[3] sdb[0] sdc[1] 999950336 blocks super 1.2 512K chunks 2 near-copies [4/4] [UUUU] bitmap: 1/8 pages [4KB], 65536KB chunk unused devices: &amp;lt;none&amp;gt;  如下信息说明： 提示软raid 不能作为启动分区 mdadm: Note: this array has metadata at the start and may not be suitable as a boot device.</description>
    </item>
    
    <item>
      <title>Centos 初始化配置</title>
      <link>https://zhangeamon.top/linux/init-centos/</link>
      <pubDate>Mon, 03 Dec 2018 10:34:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/init-centos/</guid>
      <description>网络配置 设置IP 略
ip_froward 查看 sysctl -a | grep ip_
修改 vi /etc/sysctl.conf
net.ipv4.ip_forward = 1  最大使用内存 vm.max_map_count=262144  生效 sysctl -p
系统更新 yum -y update  安装扩展及工具 yum -y install epel-release net-tools bind-utils telnet wget  文件链接限制 查看
ulimit -n  修改 vi /etc/security/limits.conf
* - nofile 65536 * soft nproc 65536 * hard nproc 65536 * soft nofile 65536 * hard nofile 65536  rm /etc/security/limits.d/* -rf  安全 selinux 查看</description>
    </item>
    
    <item>
      <title>模板数据库</title>
      <link>https://zhangeamon.top/postgres/template/</link>
      <pubDate>Fri, 30 Nov 2018 09:52:43 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/template/</guid>
      <description>模板数据库 模板数据库就是创建新database时，PostgreSQL会基于模板数据库制作一份副本，其中会包含所有的数据库设置和数据文件。 PostgreSQL安装好以后会默认附带两个模板数据库：template0和template1。
 template0 干净版，任何时候不要修改 template1 默认版，如果创建数据库时不指定模板将默认模板指定为template1  区别  template1 可以连接并创建对象，template0 不可以连接
 使用 template1 模板库建库时不可指定新的 encoding 和 locale，而 template0 可以
  使用 使用方法　 create database mytemplate template template1; create database mydatabase template mytemplate;  设置自己的模板　mytemplate
在自己的模板中需改信息，比如　添加必备的扩展，统计函数库等。
其他数据库在创建时使用自定的模板</description>
    </item>
    
    <item>
      <title>pg_stat_statements 数据库统计信息</title>
      <link>https://zhangeamon.top/postgres/pg_stat_statements/</link>
      <pubDate>Thu, 29 Nov 2018 11:08:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/pg_stat_statements/</guid>
      <description>pg_stat_statements 扩展 安装　 yum install postgresql10-contrib.x86_64  修改配置参数 vi $PGDATA/postgresql.conf shared_preload_libraries=&#39;pg_stat_statements&#39; # 加载模块　需要重启 , 近期测试不需要添加也可以。自带扩展 track_io_timing = on # 跟踪IO耗时 (可选) track_activity_query_size = 2048 # 设置单条SQL的最长长度，超过被截断显示（可选) pg_stat_statements.max = 10000 #在pg_stat_statements中最多保留多少条统计信息，通过LRU算法，覆盖老的记录。 pg_stat_statements.track = all # all - (所有SQL包括函数内嵌套的SQL), top - 直接执行的SQL(函数内的sql不被跟踪), none - (不跟踪) pg_stat_statements.track_utility = off #是否跟踪非DML语句 (例如DDL，DCL)，on表示跟踪, off表示不跟踪 pg_stat_statements.save = on #重启后是否保留统计信息  重启数据库 systemctl restart postgresql-10  创建扩展 create extension pg_stat_statements; \d pg_stat_statements View &amp;quot;public.pg_stat_statements&amp;quot; Column | Type | Collation | Nullable | Description ---------------------+------------------+-----------+----------+--------- userid | oid | | | 执行该语句的用户的 OID dbid | oid | | | 在其中执行该语句的数据库的 OID queryid | bigint | | | 内部哈希码，从语句的解析树计算得来 query | text | | | 语句的文本形式 calls | bigint | | | 被执行的次数 total_time | double precision | | | 在该语句中花费的总时间，以毫秒计 min_time | double precision | | | 在该语句中花费的最小时间，以毫秒计 max_time | double precision | | | 在该语句中花费的最大时间，以毫秒计 mean_time | double precision | | | 在该语句中花费的平均时间，以毫秒计 stddev_time | double precision | | | 在该语句中花费时间的总体标准偏差，以毫秒计 rows | bigint | | | 该语句检索或影响的行总数 shared_blks_hit | bigint | | | 该语句造成的共享块缓冲命中总数 shared_blks_read | bigint | | | 该语句读取的共享块的总数 shared_blks_dirtied | bigint | | | 该语句弄脏的共享块的总数 shared_blks_written | bigint | | | local_blks_hit | bigint | | | local_blks_read | bigint | | | 该语句读取的本地块的总数 local_blks_dirtied | bigint | | | 该语句弄脏的本地块的总数 local_blks_written | bigint | | | 该语句写入的本地块的总数 temp_blks_read | bigint | | | temp_blks_written | bigint | | | blk_read_time | double precision | | | 该语句花在读取块上的总时间，以毫秒计（如果track_io_timing被启用，否则为零) blk_write_time | double precision | | | 该语句花在写入块上的总时间，以毫秒计（如果track_io_timing被启用，否则为零)  在数据库中生成了一个名为 pg_stat_statements 的视图,对数据库的跟踪也是基于这个视图展开。</description>
    </item>
    
    <item>
      <title>数据库拓展</title>
      <link>https://zhangeamon.top/postgres/extention/</link>
      <pubDate>Tue, 27 Nov 2018 15:20:33 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/extention/</guid>
      <description> 流计算数据库产品 pipelineDB *
 推荐数据库产品 recDB
 时序数据库 timescaleDB *
 分布式数据库插件 citus *
 列存储插件 IMCS, cstore等
 面向OLAP的codegen数据库 pg_LLVM
 向量计算插件 vops
 数据库性能分析 pg_stat_statements pg_buffercache
 直接访问数据库文件系统 adminpack
 加密数据 pgcrypto
 预热缓存 pg_prewarm
 检查存储，特别是表膨胀 pgstattuple
 模糊搜索 pg_trgm
 连接到远程服务器 postgres_fdw
 k近邻（KNN）搜索 btree_gist
  比如检索10左右的数据，价格在100左右的数据。
create index idx_value_001 on t_talbe01 USING gist(value); select * from t_table01 where value &amp;lt;-&amp;gt; 100 limit 10;  </description>
    </item>
    
    <item>
      <title>英语单词</title>
      <link>https://zhangeamon.top/about/en/</link>
      <pubDate>Tue, 27 Nov 2018 10:15:16 +0800</pubDate>
      
      <guid>https://zhangeamon.top/about/en/</guid>
      <description>单词表 utilizes 利用
degradation 退化，降级
hypertable 元数据表
monotonically 单调的　monotonically increase: 单调递增
solely 单独地，唯一地
cardinality 基数
excel 优于，擅长
eliminate 干掉，排除
refine 精致的，经过改良的
distilled 从..中萃取
robust 精力充沛的
fundamental 基础的 主要的</description>
    </item>
    
    <item>
      <title>数据库参数</title>
      <link>https://zhangeamon.top/postgres/params/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/params/</guid>
      <description>postgres 数据库参数该如何设置 性能参数pgtune pgconfig 日志参数 更多参数详解 管理 listen_addresses = &amp;quot;*&amp;quot; # 连接访问控制，哪些ip可以访问， * 全部。 结合pg_hba.conf , iptables设置。 superuser_reserved_connections = 3 # 预留给超级管理员的连接数。 port = 5432 # 默认访问端口 wal_keep_segments = 1024 # wal 日志保存数量  wal日志 wal_log_hints = on full_page_writes = on  成本因子 # - Planner Cost Constants - #seq_page_cost = 1.0 # measured on an arbitrary scale 顺序扫描 random_page_cost = 1.1 # same scale as above 随机扫描。HDD 4 ;SSD 1.</description>
    </item>
    
    <item>
      <title>LSM Overview</title>
      <link>https://zhangeamon.top/tidb/lsm/</link>
      <pubDate>Mon, 26 Nov 2018 13:40:19 +0800</pubDate>
      
      <guid>https://zhangeamon.top/tidb/lsm/</guid>
      <description>介绍 LSM-Tree，全称为 log-structured merge-tree，是为了满足日益增长的数据量所带来的高效写性能的需求而提出的设计。考虑到磁盘随机写和顺序写上千倍的性能差距，传统的Btree 结构设计采取的分散的 update-in-place 策略在数据量庞大、写缓存作用有限的情况下，存在大批量的随机写操作，使得写性能完全满足不了新数据的业务需求。为了提高写速率，LSM-Tree 采取的简单高效的日志结构的设计，将所有写操作的结果先缓存在内存并按次序分批写入硬盘，在底层管理多个版本的数据内容。理所当然地，不管是在点查还是范围查询的场景下，简单的日志结构会使得读的性能不高。因此为了提高读的性能，适当地保持系统内一定的有序性，引入排序开销是有必要的，即采取 LSM 里的 Merge 操作。此外在日志的基础上也可以添加额外的索引结构，例如 Bloomfilter 或者块索引设计。缓存友好的索引结构能够有效降低 IO 次数，快速定位到查询的数据具体的位置。
在 LSM 结构设计当中，数据按写入顺序拆分成多个批次的数据集合，包括了内存中的Memtable 和硬盘上的 SSTable。具体地，数据插入到 Memtable 当中，在 MemTable 大小超过一定阈值后进行 Flush 操作，变成不可修改的、内部有序的 SSTable。SSTable 在后台根据一定的层次结构进行组织。如下图是一个典型的多个 Level 的层次设计，Level-0 对应多个 Memtable，Level-1 对应 Flush 到硬盘上的多个相互之间无序的 SSTable，Level-2 对应一个有序的大 SSTable。
在适当的条件下后台会触发 Merge 操作，合并多个旧 SSTable 成新的 SSTable。合并的目的是为了减少文件数量，提高读的性能，此外也能够进行垃圾回收，减少多版本数据占用的空间大小。值得注意的是，后台 Merge 可能是一个特别影响前台读、写性能的操作。若系统对读要求越高，即对有序性要求越严格，往往需要更加积极的 Merge 操作，也往往会导致更剧烈的写放大，对系统整体而言累积下来的负担是更大的。
在LSM结构设计中所有的写操作都将是顺序写，换来的代价：
读放大：查询一个 Key 值所对应的 Value 值，可能需要遍历多个 SSTable 文件，对应了复数次随机 IO。
空间放大：多版本数据在合并之前会占用更多的存储空间。
写放大：在系统稳定后硬盘写数据的累积值 / 数据第一次写入硬盘的大小，该比值在LevelDB 或 RocksDB 中可达两位数。
总结来说，LSM结构设计能够提供非常好的写性能，在读方面需要结合业务特性，通过合理的层次结构设计以及索引结构控制负面影响，能够使得读性能达到业务能够接受的范畴。
目前随着固态硬盘的普及，不同于传统Btree结构在大量随机写情况下可能导致FTL层繁重的垃圾回收负载，LSM 的日志结构设计对于固态硬盘天然的友好性以及较为简单的设计模式，使其受到了很多存储引擎开发者的青睐。然而后台排序导致的写放大对于寿命有限的固态盘来说，是 LSM 中备受关注的痛点，近年来也有不少关于 LSM 在 SSD 上深度优化的相关研究。</description>
    </item>
    
    <item>
      <title>Haproxy 算法</title>
      <link>https://zhangeamon.top/middleware/haproxy/</link>
      <pubDate>Mon, 26 Nov 2018 08:53:09 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/haproxy/</guid>
      <description>blance roundrobin # 轮询，软负载均衡基本都具备这种算法
 balance static-rr # 根据权重，建议使用
 balance leastconn # 最少连接者先处理，建议使用
 balance source # 根据请求源IP，建议使用
 balance uri # 根据请求的URI
 balance url_param，# 根据请求的URl参数&amp;rsquo;balance url_param&amp;rsquo; requires an URL parameter name
 balance hdr(name) # 根据HTTP请求头来锁定每一次HTTP请求
 balance rdp-cookie(name) # 根据据cookie(name)来锁定并哈希每一次TCP请求
  配置
https://www.jianshu.com/p/baa296770bd5</description>
    </item>
    
    <item>
      <title>Promethues Altermanager 报警</title>
      <link>https://zhangeamon.top/monitor/prometheus-altermanager/</link>
      <pubDate>Wed, 21 Nov 2018 17:29:01 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/prometheus-altermanager/</guid>
      <description>Prometheus Alertmanager 概述 Alertmanager与Prometheus是相互分离的两个组件。Prometheus服务器根据报警规则将警报发送给Alertmanager，然后Alertmanager将silencing、inhibition、aggregation等消息通过电子邮件、PaperDuty和HipChat发送通知。
设置警报和通知的主要步骤：
 安装配置Alertmanager
 配置Prometheus 指定altermanager服务
 在Prometheus中创建告警规则
  Alertmanager简介及机制 Alertmanager处理由Prometheus服务器等客户端发来的警报。它负责删除重复数据、分组，并将警报通过路由发送到正确的接收器，比如电子邮件、Slack等。Alertmanager还支持groups,silencing和警报抑制的机制。
分组 分组是指将同一类型的警报分类为单个通知。当许多系统同时宕机时，很有可能成百上千的警报会同时生成，这种机制特别有用。 例如，当数十或数百个服务的实例在运行，网络发生故障时，有可能一半的服务实例不能访问数据库。在prometheus告警规则中配置为每一个服务实例都发送警报的话，那么结果是数百警报被发送至Alertmanager。
但是作为用户只想看到单一的报警页面，同时仍然能够清楚的看到哪些实例受到影响，因此，可以通过配置Alertmanager将警报分组打包，并发送一个相对看起来紧凑的通知。
分组警报、警报时间，以及接收警报的receiver是在alertmanager配置文件中通过路由树配置的。
抑制(Inhibition) 抑制是指当警报发出后，停止重复发送由此警报引发其他错误的警报的机制。(比如网络不可达，导致其他服务连接相关警报)
例如，当整个集群网络不可达，此时警报被触发，可以事先配置Alertmanager忽略由该警报触发而产生的所有其他警报，这可以防止通知数百或数千与此问题不相关的其他警报。
抑制机制也是通过Alertmanager的配置文件来配置。
沉默(Silences) Silences是一种简单的特定时间不告警的机制。silences警告是通过匹配器(matchers)来配置，就像路由树一样。传入的警报会匹配RE，如果匹配，将不会为此警报发送通知。
这个可视化编辑器可以帮助构建路由树。
silences报警机制可以通过Alertmanager的Web页面进行配置。
Alermanager的配置 Alertmanager通过命令行flag和一个配置文件进行配置。命令行flag配置不变的系统参数、配置文件定义的抑制(inhibition)规则、通知路由和通知接收器。
要查看所有可用的命令行flag，运行alertmanager -h。 Alertmanager支持在运行时加载配置，如果新配置语法格式不正确，更改将不会被应用，并记录语法错误。通过向该进程发送SIGHUP或向/-/reload端点发送HTTP POST请求来触发配置热加载。
配置文件 要指定加载的配置文件，需要使用-config.file标志。该文件使用YAML来完成，通过下面的描述来定义。带括号的参数表示是可选的，对于非列表的参数的值，将被设置为指定的缺省值。
ref: https://www.jianshu.com/p/239b145e2acc</description>
    </item>
    
    <item>
      <title>Promethues 基本概念</title>
      <link>https://zhangeamon.top/monitor/prometheus-concepts/</link>
      <pubDate>Wed, 21 Nov 2018 14:08:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/monitor/prometheus-concepts/</guid>
      <description>数据模型(Data Model) 由指标名称(metric)和一个或一组标签(lable)集合以及float64类型的值组成。
例如
up{instance=&amp;quot;10.1.88.71:9115&amp;quot;,job=&amp;quot;blackbox_exporter_10.1.88.74_icmp&amp;quot;}	1  metric类型 client libraries提供了四种metric类型，包括Counter、Gauge、Histogram、Summary。
Counter 计数器，只允许增加或重置为0，不允许减少，比如服务的请求数。Counter支持用rate()函数计算平均值，比如QPS。建议使用 _total 作为后缀命名。
Gauge 非固定的值，比如CPU负载 、内存使用量。
其变化取决于server是否采集了数据，衡量的是一个事物的状态变化，比如内存使用量，内存始终是那个内存，只是其使用量会发生变化。
Histogram 采样观测值，可进行分位计算和数据聚合，计算在server端完成。
一个名为的metric，其histogram有3个固定的时间序列
&amp;lt;basename&amp;gt;_bucket 不同bucket下的观测值的累加数量 &amp;lt;basename&amp;gt;_sum 观测值的总和 &amp;lt;basename&amp;gt;_count 观测值的数量  Summary 采样观测值，与histogram不同的是，数量/总和/分位的计算在client端完成，计算结果存在server。因为没有最初的metric数据，所以summary不支持数据聚合。
一个名为的metric，其summary有3个固定的时间序列
&amp;lt;basename&amp;gt;{quantile=&amp;quot;&amp;lt;φ&amp;gt;&amp;quot;} &amp;lt;basename&amp;gt;_sum 观测值的总和 &amp;lt;basename&amp;gt;_count 观测值的数量  Job 和 Instance instance是指收集数据的目标端点，一般对应于一个进程；而job表示实现同一功能或目标的一组instance。
Prometheus采集到数据后自动为其附加job和instance标签，其中job由Prometheus配置文件定义，instance是目标数据源的地址:。
特点  多维数据模型，时间序列由metric名字和K/V标签标识 灵活的查询语言(PromQL)
 单机模式，不依赖分布式存储 基于HTTP采用pull方式收集数据 支持push数据到中间件(pushgateway) 通过服务发现或静态配置发现目标 多种图表和仪表盘  组件 Prometheus生态系统由多个组件构成，其中多是可选的，根据具体情况选择
 Prometheus server - 收集和存储时间序列数据 client library - 用于client访问server/pushgateway pushgateway - 对于短暂运行的任务，负责接收和缓存时间序列数据，同时也是一个数据源 exporter - 各种专用exporter，面向硬件、存储、数据库、HTTP服务等 alertmanager - 处理报警 其他各种支持的工具  各组件之间的通信 1, prometheus与客户端主要采取pull方式获取数据</description>
    </item>
    
    <item>
      <title>Sql 优化</title>
      <link>https://zhangeamon.top/tidb/sql-optimize01/</link>
      <pubDate>Wed, 21 Nov 2018 09:18:37 +0800</pubDate>
      
      <guid>https://zhangeamon.top/tidb/sql-optimize01/</guid>
      <description>一条sql的执行过程 将 SQL 解析成抽象语法树(AST)，将 AST 变换到内部表示(IR)。然后优化器的输入就是 IR，它将生成最优的查询计划（Plan），然后会变成具体的执行器（Executor），里面有许多的算。
优化的阶段为IR 到生成 Plan 的过程，包括逻辑优化和物理优化
逻辑优化 逻辑优化主要是基于规则的优化(RBO)。
逻辑算子  DataSource 这个就是数据源，也就是表。 select * from t 里面的 t Selection 选择，就是 select xxx from t where xx = 5 里面的 where 过滤条件条件 Projection 投影，也就是 select c from t 里面的列 c Join 连接， select xx from t1, t2 where t1.c = t2.c 就是把 t1 t2 两个表做 join，这个连接条件一个简单的等值连接。join 有好多种，内关联，左关联，右关联，全关联..  列裁剪 只读取需要的列
最大最小消除 select min(id) from t</description>
    </item>
    
    <item>
      <title>数据库索引类型及使用场景</title>
      <link>https://zhangeamon.top/postgres/index01/</link>
      <pubDate>Mon, 19 Nov 2018 09:00:44 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/index01/</guid>
      <description>用途 优点
 主键唯一约束 加速检索 排序  缺点
 更新数据时需要同时维护对应索引 占用磁盘空间，甚至比表数据本身还要多  使用场景利弊分析
 TP与AP应用 读写使用比例 点查询批量查询  创建索引 \h create index 命令： CREATE INDEX 描述： 建立新的索引 语法： CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] 名称 ] ON 表名 [ USING 方法 ] ( { 列名称 | ( 表达式 ) } [ COLLATE 校对规则 ] [ 操作符类型的名称 ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, .</description>
    </item>
    
    <item>
      <title>Sysbench 测试</title>
      <link>https://zhangeamon.top/middleware/sysbench/</link>
      <pubDate>Fri, 16 Nov 2018 19:25:45 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/sysbench/</guid>
      <description>下载安装 1.0.15 sysbench官网 curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash sudo yum -y install sysbench  参数说明 sysbench --help Usage: sysbench [options]... [testname] [command] Commands implemented by most tests: prepare run cleanup help General options: --threads=N number of threads to use [1] 线程数 --events=N limit for total number of events [0] 事务数 --time=N limit for total execution time in seconds [10] 测压时间 --forced-shutdown=STRING number of seconds to wait after the --time limit before forcing shutdown, or &#39;off&#39; to disable [off] --thread-stack-size=SIZE size of stack per thread [64K] --rate=N average transactions rate.</description>
    </item>
    
    <item>
      <title>PostgreSQL 无法kill(pg_terminate_backend, pg_cancel_backend)的情况分析 - 进程hang strace,pstack</title>
      <link>https://zhangeamon.top/postgres/kill/</link>
      <pubDate>Wed, 14 Nov 2018 22:09:54 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/kill/</guid>
      <description>先 mark 下 https://yq.aliyun.com/articles/647468</description>
    </item>
    
    <item>
      <title>pstack</title>
      <link>https://zhangeamon.top/linux/cmd-pstack/</link>
      <pubDate>Wed, 14 Nov 2018 22:05:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cmd-pstack/</guid>
      <description>安装
 yum install gdb  使用
pstack pid gstack pid  pstree</description>
    </item>
    
    <item>
      <title> ERROR 2013 (HY000): Lost connection to MySQL server during query </title>
      <link>https://zhangeamon.top/tidb/2013/</link>
      <pubDate>Wed, 14 Nov 2018 10:08:02 +0800</pubDate>
      
      <guid>https://zhangeamon.top/tidb/2013/</guid>
      <description>ERROR 2013 (HY000) Lost connection to MySQL server during query 错误出现场景 select count(id) from account_user where id&amp;gt; 0; +----------+ | count(id) | +----------+ | 2940245 | +----------+ 1 row in set (0.78 sec) delete from account_user where id&amp;gt; 0; ERROR 2013 (HY000): Lost connection to MySQL server during query  tidb.log
2018/11/14 10:57:12.476 server.go:303: [info] con:261 new connection 10.1.88.32:54462 2018/11/14 10:57:15.387 coprocessor.go:689: [info] [TIME_COP_PROCESS] resp_time:792.561353ms txn_start_ts:404269101106331649 region_id:77367 store_addr:10.1.88.84:20160 kv_process_ms:537 2018/11/14 10:57:17.</description>
    </item>
    
    <item>
      <title>熔断，限流，降级</title>
      <link>https://zhangeamon.top/istio/concept01/</link>
      <pubDate>Tue, 13 Nov 2018 10:23:42 +0800</pubDate>
      
      <guid>https://zhangeamon.top/istio/concept01/</guid>
      <description>写在前面 在学习Service Mesh前还是最好先清楚几个概念，如熔断，限流，降级。接下来一起揭开面纱，让陌生的名词变得没有那么神秘。一切都来自于现实的应用场景，及解决问题的方法方式。
 consumer表示服务调用方 provider表示服务提供方 A调用B服务，一般是泛指调用B服务里面的一个接口  拓扑图 大写字母表示不同的服务，后面的序号表示同一个服务部署在不同机器的实例。
从微观角度思考 1 超时（timeout） 在接口调用过程中，consumer调用provider的时候，provider在响应的时候，有可能会慢，如果provider 10s响应，那么consumer也会至少10s才响应。如果这种情况频度很高，那么就会整体降低consumer端服务的性能。
这种响应时间慢的症状，就会像一层一层波浪一样，从底层系统一直涌到最上层，造成整个链路的超时。
所以，consumer不可能无限制地等待provider接口的返回，会设置一个时间阈值，如果超过了这个时间阈值，就不继续等待。
这个超时时间选取，一般看provider正常响应时间是多少，再追加一个buffer即可。
2 重试（retry） 超时时间的配置是为了保护服务，避免consumer服务因为provider 响应慢而也变得响应很慢，这样consumer可以尽量保持原有的性能。
但是也有可能provider只是偶尔抖动，那么超时后直接放弃，不做后续处理，就会导致当前请求错误，也会带来业务方面的损失。
那么，对于这种偶尔抖动，可以在超时后重试一下，重试如果正常返回了，那么这次请求就被挽救了，能够正常给前端返回数据，只不过比原来响应慢一点。
重试时的一些细化策略：
重试可以考虑切换一台机器来进行调用，因为原来机器可能由于临时负载高而性能下降，重试会更加剧其性能问题，而换一台机器，得到更快返回的概率也更大一些。
2.1幂等(idempotent) 如果允许consumer重试，那么provider就要能够做到幂等。
即，同一个请求被consumer多次调用，对provider产生的影响(这里的影响一般是指某些写入相关的操作) 是一致的。
而且这个幂等应该是服务级别的，而不是某台机器层面的，重试调用任何一台机器，都应该做到幂等。
3 熔断（circuit break） 重试是为了应付偶尔抖动的情况，以求更多地挽回损失。
可是如果provider持续的响应时间超长呢?
如果provider是核心路径的服务，down掉基本就没法提供服务了，那我们也没话说。 如果是一个不那么重要的服务，却因为这个服务一直响应时间长导致consumer里面的核心服务也拖慢，那么就得不偿失了。
单纯超时也解决不了这种情况了，因为一般超时时间，都比平均响应时间长一些，现在所有的打到provider的请求都超时了，那么consumer请求provider的平均响应时间就等于超时时间了，负载也被拖下来了。
而重试则会加重这种问题，使consumer的可用性变得更差。
因此就出现了熔断的逻辑，也就是，如果检查出来频繁超时，就把consumer调用provider的请求，直接短路掉，不实际调用，而是直接返回一个mock的值。
等provider服务恢复稳定之后，重新调用。
3.1 简单的熔断处理逻辑 目前我们框架有通过注解使用的熔断器，大家可以参考应用在项目中。
4 限流(current limiting) 上面几个策略都是consumer针对provider出现各种情况而设计的。
而provider有时候也要防范来自consumer的流量突变问题。
这样一个场景，provider是一个核心服务，给N个consumer提供服务，突然某个consumer抽风，流量飙升，占用了provider大部分机器时间，导致其他可能更重要的consumer不能被正常服务。
所以，provider端，需要根据consumer的重要程度，以及平时的QPS大小，来给每个consumer设置一个流量上线，同一时间内只会给A consumer提供N个线程支持，超过限制则等待或者直接拒绝。
4.1 资源隔离 provider可以对consumer来的流量进行限流，防止provider被拖垮。
同样，consumer 也需要对调用provider的线程资源进行隔离。 这样可以确保调用某个consumer逻辑不会耗光整个provider的线程池资源。
曾记否，因为数据库未做资源隔离，一个应用上线后占满了整个数据库的连接，对整个业务都造成了影响。
4.2 服务降级 降级服务既可以代码自动判断，也可以人工根据突发情况切换。
4.2.1 consumer 端 consumer 如果发现某个provider出现异常情况，比如，经常超时(可能是熔断引起的降级)，数据错误，这是，consumer可以采取一定的策略，降级provider的逻辑，基本的有直接返回固定的数据。
4.2.2 provider 端 当provider 发现流量激增的时候，为了保护自身的稳定性，也可能考虑降级服务。</description>
    </item>
    
    <item>
      <title>Istio 1.0.3 安装　</title>
      <link>https://zhangeamon.top/istio/install/</link>
      <pubDate>Mon, 12 Nov 2018 13:44:34 +0800</pubDate>
      
      <guid>https://zhangeamon.top/istio/install/</guid>
      <description>Service Mesh(服务网格) Kubernetes 已经给我们带来了诸多的好处。但是仍有些需求比如 A/B 测试、金丝雀发布、限流、访问控制,端到端认证等需要运维人员进一步去解决。
Istio 是完全开源的服务网格,提供了一套完整的解决方案，可以透明地分层到现有的分布式应用程序上。对开发人员几乎无感的同时获得超能力。
如果想要现有的服务支持 Istio，只需要在当前的环境中部署一个特殊的 sidecar 代理，即可。
前提  安装 Kubernetes 集群 1.9+ 安装 Helm
  准备 进入 Istio release 页面下载最新版安装包(1.0.3)并解压到当前目录,
curl -L https://git.io/getLatestIstio | sh - ll istio-1.0.3/ total 28 drwxr-xr-x 2 root root 22 10月 26 07:36 bin drwxr-xr-x 6 root root 79 10月 26 07:36 install -rw-r--r-- 1 root root 648 10月 26 07:36 istio.VERSION -rw-r--r-- 1 root root 11343 10月 26 07:36 LICENSE -rw-r--r-- 1 root root 5817 10月 26 07:36 README.</description>
    </item>
    
    <item>
      <title>Esrallyi 压力测试</title>
      <link>https://zhangeamon.top/es/esrally/</link>
      <pubDate>Mon, 12 Nov 2018 11:41:20 +0800</pubDate>
      
      <guid>https://zhangeamon.top/es/esrally/</guid>
      <description>https://segmentfault.com/a/1190000011174694</description>
    </item>
    
    <item>
      <title>蓝绿、A/B测试、金丝雀发布</title>
      <link>https://zhangeamon.top/istio/concept02/</link>
      <pubDate>Fri, 09 Nov 2018 10:17:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/istio/concept02/</guid>
      <description>蓝绿发布 准备两套环境，蓝和绿。绿环境为当前正式环境，现在将新版部署到蓝环境当中并进行测试。没有问题后将路由指向蓝环境。若发现问题可将路由指回到原来的绿环境中进行回滚。
问题： 如果是无状态应用还可以，如果应用有状态或类似数据库之类的应该很麻烦，还有新旧版本是否兼容的问题。
A/B 测试 用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。A/B测试通常用在应用的前端上。 A/B测试目的在于通过科学的实验设计、采样样本代表性、流量分割与小流量测试等方式来获得具有代表性的实验结论，并确信该结论在推广到全部流量可信
金丝雀/ 灰度发布 在原有版本可用的情况下，同时部署一个新版本应用作为“金丝雀”（金丝雀对瓦斯极敏感，矿井工人携带金丝雀，以便及时发发现危险），测试新版本的性能和表现，以保障整体系统稳定的情况下，尽早发现、调整问题。 试水版</description>
    </item>
    
    <item>
      <title>KVM</title>
      <link>https://zhangeamon.top/kvm/kvm01/</link>
      <pubDate>Tue, 06 Nov 2018 16:23:07 +0800</pubDate>
      
      <guid>https://zhangeamon.top/kvm/kvm01/</guid>
      <description>安装  ubuntu14.04 .安装kvm
apt-get install qemu-kvm libvirt0 virtinst bridge-utils virt-viewer
.配置实体机网络
cat /etc/network/interfaces
auto lo iface lo inet loopback auto br0 iface br0 inet static address 10.0.*.* netmask 255.255.0.0 gateway 10.1.0.1 type bridge bridge_ports eth0 dns-nameservers 114.114.114.114  .创建一个虚拟机
virt-install --connect qemu:///system -n test01 -r 1024 -f /home/kvm/test01.qcow2 -s 20 -c /home/kvm/ubuntu-12.04.1-server-amd64.iso --vnc --noautoconsole --os-type linux --os-variant ubuntuPrecise --accelerate --network=bridge:br0  centos7 yum install qemu-kvm libvirt virt-install bridge-utils</description>
    </item>
    
    <item>
      <title>APM</title>
      <link>https://zhangeamon.top/elk/apm/</link>
      <pubDate>Tue, 06 Nov 2018 13:39:01 +0800</pubDate>
      
      <guid>https://zhangeamon.top/elk/apm/</guid>
      <description>https://www.elastic.co/solutions/apm
应用程序性能监控 整体架构 先搞起来  agent 收集信息 apm-server 接受agent信息并发送到ES ES 存储信息 Kibana 信息检索展示  agent python django
安装扩展包 pip install elastic-apm django 配置 # Add the agent to the installed apps INSTALLED_APPS = ( &#39;elasticapm.contrib.django&#39;, #... ) ELASTIC_APM = { # Set required service name. # Allowed characters: # a-z, A-Z, 0-9, -, _, and space &#39;SERVICE_NAME&#39;: &#39;my-app&#39;, #后台进程 &#39;TRANSPORT_CLASS&#39;: &#39;elasticapm.transport.http.AsyncTransport&#39;, # Use if APM Server requires a token #&#39;SECRET_TOKEN&#39;: &#39;&#39;, # 没有数据可以开启debug查看 # &#39;DEBUG&#39;: True, # Set custom APM Server URL ( # default: http://localhost:8200) # &#39;SERVER_URL&#39;: &#39;http://10.</description>
    </item>
    
    <item>
      <title>Postgresql指标查看&amp;stat统计信息</title>
      <link>https://zhangeamon.top/postgres/stat/</link>
      <pubDate>Tue, 06 Nov 2018 10:53:52 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/stat/</guid>
      <description>当前连接数  SELECT count(*) FROM pg_stat_activity WHERE NOT pid=pg_backend_pid(); count ------- 3 (1 row)   数据库占用空间  select pg_size_pretty(pg_database_size(&#39;postgres&#39;)); pg_size_pretty ---------------- 14 MB (1 row) or \l+   数据库表(不包括索引)或单条索引占用空间  select pg_size_pretty(pg_relation_size(&#39;t_name&#39;)); pg_size_pretty ---------------- 24 kB (1 行记录) or \d+   表中所有索引占有的空间  select pg_size_pretty(pg_indexes_size(&#39;t_name&#39;)); pg_size_pretty ---------------- 280 kB (1 行记录)   表和索引占用总空间  select pg_size_pretty(pg_total_relation_size(&#39;t_name&#39;)); pg_size_pretty ---------------- 380 kB (1 行记录)   查看一条数据在数据库占用的空间  select pg_column_size(&#39;Let us go !</description>
    </item>
    
    <item>
      <title>Keepalived 问题集</title>
      <link>https://zhangeamon.top/middleware/keepalived01/</link>
      <pubDate>Mon, 05 Nov 2018 10:08:23 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/keepalived01/</guid>
      <description>Q1  问题描述  ip address associated with VRID 51 not present in MASTER advert : 10.1.7.58  其中 51 为 virtual_router_id 10.1.7.58 为虚拟IP
可能原因  ntp 时间不同步
 局域网内 virtual_router_id 与其他集群配置冲突。 另外 router_id 主机标示，一般为hostname即可。
  解决方法： unicast_peer{ } 配置成单播模式</description>
    </item>
    
    <item>
      <title>Docker 本地网络</title>
      <link>https://zhangeamon.top/docker/network01/</link>
      <pubDate>Fri, 02 Nov 2018 16:34:06 +0800</pubDate>
      
      <guid>https://zhangeamon.top/docker/network01/</guid>
      <description>基础命令概览 docker network --help Usage:	docker network COMMAND Manage networks Commands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networks  默认网络 docker network ls NETWORK ID NAME DRIVER SCOPE 0770a8275bff bridge bridge local b6617326f199 host host local 31c55ffcf0a8 none null local  创建容器时通过 &amp;ndash;network= 指定网络类型</description>
    </item>
    
    <item>
      <title>Cgroup Namespaces</title>
      <link>https://zhangeamon.top/docker/cgroup-namespaces/</link>
      <pubDate>Fri, 02 Nov 2018 14:17:44 +0800</pubDate>
      
      <guid>https://zhangeamon.top/docker/cgroup-namespaces/</guid>
      <description>cgroup 实现资源限额 cgroup 全称 Control Group。Linux 操作系统通过 cgroup 可以设置进程使用 CPU、内存 和 IO 资源的限额。
在启动容器时可使用参数 docker run &amp;ndash;blkio-weight-device &amp;ndash;cpu-shares &amp;ndash;memory 等 。
ll /sys/fs/cgroup/cpu/docker/ ll /sys/fs/cgroup/memory/docker ll /sys/fs/cgroup/blkio/docker  namespace 实现资源隔离 Mount Mount namespace 让容器看上去拥有整个文件系统。 容器有自己的 / 目录，可以执行 mount 和 umount 命令。当然我们知道这些操作只在当前容器中生效，不会影响到 host 和其他容器。
UTS hostname 简单的说，UTS namespace 让容器有自己的 hostname。 默认情况下，容器的 hostname 是它的短ID，可以通过 -h 或 &amp;ndash;hostname 参数设置。
IPC IPC namespace 让容器拥有自己的共享内存和信号量（semaphore）来实现进程间通信，而不会与 host 和其他容器的 IPC 混在一起。
PID 
Network Network namespace 让容器拥有自己独立的网卡、IP、路由等资源</description>
    </item>
    
    <item>
      <title>Dumb Init</title>
      <link>https://zhangeamon.top/docker/dumb-init/</link>
      <pubDate>Thu, 01 Nov 2018 11:43:35 +0800</pubDate>
      
      <guid>https://zhangeamon.top/docker/dumb-init/</guid>
      <description>基础概念  孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。  背景知识 Linux来说，pid为1的进程，有着特殊的使命：
 传递信号，确保子进程完全退出 等待子进程退出  容器化环境中，往往直接运行应用程序，而缺少初始化系统（如systemd、sysvinit等），所有会造成两个问题:
1 无法向其子进程传递信号，可能导致容器发送SIGTERM信号之后，父进程等待子进程退出。此时，如果父进程不能将信号传递到子进程，则整个容器就将无法正常退出，除非向父进程发送SIGKILL信号，使其强行退出。
2 init进程另一个任务，是需要接管子进程，确保其能正常退出。但是一般应用程序，不会考虑实现接管进程功能。 当应用程序进程在容器中运行时，其子进程创建的子进程，就有可能成为僵尸进程。
dumb-init解决了上述两个问题：向子进程代理发送信号和接管子进程。
dumb-init使用 要在容器中使用dumb-init，可以直接安装deb包，或者从源码构建。容器启动时，使用dumb-init作为初始进程，确保所有子进程都由dumb-init进程创建：
docker run my_container dumb-init python -c &#39;while True: pass&#39;  其他 除了在容器中使用之外，dumb-init也可以直接在shell脚本中使用。使用dumb-init作为shell的父进程，可以解决shell创建的子进程优雅退出问题。这种场景使用方式类似于supervisord或者daemontools，直接将脚本的改成#!/usr/bin/dumb-init /bin/sh即可。</description>
    </item>
    
    <item>
      <title>代理</title>
      <link>https://zhangeamon.top/middleware/proxy/</link>
      <pubDate>Wed, 31 Oct 2018 14:42:10 +0800</pubDate>
      
      <guid>https://zhangeamon.top/middleware/proxy/</guid>
      <description>科普  正向代理 对服务端来说是无感的，服务端无需配置，要在客户端指定。代理的是客户端。  访问原来无法访问的资源
 用作缓存，加速访问速度
 对客户端访问授权，上网进行认证
 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息  反向代理 对客户端来说的无感的，客户端无需配置，要在服务端实现。代理的是服务端。
 保护内网安全 负载均衡 缓存，减少服务器的压力  透明代理 与正向代理相同，但是客户端无需指定
  透明代理服务器阻断网络通信，并且过滤出访问外部的HTTP（80端口）流量。如果客户端的请求在本地有缓冲则将缓冲的数据直接发给用户，如果在本地没有缓冲则向远程web服务器发出请求， 其余操作和正向代理服务器完全相同。对于linux操作系统来说，透明代理使用Iptables或者Ipchains实现。因此不需要对浏览器作任何设置，所以，透明代理对于ISP（Internet服务器提供商）特别有用。
应用 squid docker-compose.yaml
version: &#39;2&#39; services: squid3: image: sameersbn/squid:3.3.8-14 ports: - 3128:3128 volumes: - /etc/squid3/squid.conf:/etc/squid3/squid.conf - /var/log/squid3://var/log/squid3 - /var/spool/squid3:/var/spool/squid3 restart: always container_name: squid3  /etc/squid3/squid.conf
acl Safe_ports port 80 # http acl Safe_ports port 443 # https acl CONNECT method CONNECT cache_dir ufs /var/spool/squid3 100 16 256 http_access allow all http_port 3128 visible_hostname proxy  #ufs:缓存数据的存储格式 #/var/spool/squid 缓存目录 #100：缓存目录占磁盘空间大小（M） #16：缓存空间一级子目录个数 #256：缓存空间二级子目录个数</description>
    </item>
    
    <item>
      <title>我的收藏</title>
      <link>https://zhangeamon.top/about/favorites/</link>
      <pubDate>Wed, 31 Oct 2018 09:55:24 +0800</pubDate>
      
      <guid>https://zhangeamon.top/about/favorites/</guid>
      <description> 私有云访问管理 SDN 网络
 LSM数据结构
  LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。 Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引
 Raft 动画 api自动化测试 postman
 定时任务
 redis memcache 缓存管理平台
  </description>
    </item>
    
    <item>
      <title>数据库备份和恢复</title>
      <link>https://zhangeamon.top/postgres/backup_restore/</link>
      <pubDate>Tue, 30 Oct 2018 10:18:57 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/backup_restore/</guid>
      <description>Postgres 数据库备份恢复命令
备份：pg_dump -U postgres -v -F c -Z 4 -f ***.backup dbname 9压缩率最狠 恢复：pg_restore -U postgres -v -j 8 -d dbname ***.backup 8是采用8个线程 备份表：pg_dump -U postgres -t tablename dbname &amp;gt; 33.sql 恢复表：psql -U postgres -d dbname &amp;lt; 33.sql 只备份表结构 pg_dump -U postgres -s -t tablename dbname &amp;gt; 33.sql 只备份数据 pg_dump -U postgres -a -t tablename dbname &amp;gt; 33.sql  copy 拷贝数据
数据拷贝到本地： psql -U postgres -d databasename -p 5432 -h 10.</description>
    </item>
    
    <item>
      <title>Ansible Roles</title>
      <link>https://zhangeamon.top/ansible/ansible-role/</link>
      <pubDate>Mon, 29 Oct 2018 14:09:08 +0800</pubDate>
      
      <guid>https://zhangeamon.top/ansible/ansible-role/</guid>
      <description>以特定的层级目录结构进行组织的tasks、variables、handlers、templates、files等
mkdir -pv ./{os_hard,nginx,memcached}/{files,templates,vars,handlers,meta,default,tasks}/main.yaml
tree memcached/ memcached/ ├── default 设定默认变量 │ └── main.yaml ├── files 存储由copy或script等模块调用的文件 │ └── main.yaml ├── handlers │ └── main.yaml ├── meta 定义当前角色的特殊设定及其依赖关系 │ └── main.yaml ├── tasks │ └── main.yaml ├── templates 存储由template模块调用的模板文本 │ └── main.yaml └── vars └── main.yaml  ansible-galaxy https://galaxy.ansible.com 网站为他人分享的 roles， 可以下载学习并使用
ansible-galaxy 语法：
ansible-galaxy [delete|import|info|init|install|list|login|remove|search|setup] [&amp;ndash;help] [options]
 列出已安装的galaxy  ansible-galaxy list geerlingguy.redis   安装galaxy 位置 /root/.ansible/roles/   ansible-galaxy install geerlingguy.</description>
    </item>
    
    <item>
      <title>Ansible Playbooks</title>
      <link>https://zhangeamon.top/ansible/ansible-playbooks/</link>
      <pubDate>Thu, 25 Oct 2018 15:47:50 +0800</pubDate>
      
      <guid>https://zhangeamon.top/ansible/ansible-playbooks/</guid>
      <description>Playbook核心元素 hosts 一个或多个组或主机的 patterns,以逗号为分隔符 。
- hosts: webservices remote_user: root  Tasks 任务集
 tasks: - name: install httpd yum: name=httpd - name: start httpd service: name=httpd state=started  Handlers 和 notity 由特定条件触发的操作，满足条件方才执行，否则不执行。 Handlers也是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生变化时，才会采取一定的操作。
- hosts: webs remote_user: root tasks: - name: install httpd yum: name=httpd - name: change httpd.conf copy: src=/app/httpd.conf dest=/etc/httpd/conf/ backup=yes notify: restart httpd &amp;gt; 在 notify 中定义内容一定要和handlers中定义的 - name 内容一样，这样才能达到触发的效果，否则会不生效。 - name: start httpd service: name=httpd state=started - name: wall http status shell: /usr/bin/wall `ss -nltp|grep httpd` handlers: - name: restart httpd &amp;gt; 只有接收到通知才会执行这里的任务 service: name=httpd state=restarted  Tags 给指定的任务定义一个调用标识 由于ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过 tags跳过此些代码片断。</description>
    </item>
    
    <item>
      <title>Ansible Modules</title>
      <link>https://zhangeamon.top/ansible/ansible-modules/</link>
      <pubDate>Thu, 25 Oct 2018 10:12:59 +0800</pubDate>
      
      <guid>https://zhangeamon.top/ansible/ansible-modules/</guid>
      <description>准备工作  安装  yum install ansible-doc.noarch ansible.noarch -y tree /etc/ansible/ /etc/ansible/ ├── ansible.cfg ├── hosts └── roles ansible --version ansible 2.7.0 config file = /etc/ansible/ansible.cfg configured module search path = [u&#39;/root/.ansible/plugins/modules&#39;, u&#39;/usr/share/ansible/plugins/modules&#39;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Jul 13 2018, 13:06:57) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]   配置清单  cat hosts [webservers] 10.1.88.72 10.1.88.73   免密登录  常用命令 Usage: ansible &amp;lt;host-pattern&amp;gt; [options] 常用选项： -m MOD_NAME -a MOD_ARGS 获取模块列表：ansible-doc -l 获取指定模块的使用帮助：ansible-doc -s MOD_NAME   ping  尝试连接到主机，验证并返回pong成功。</description>
    </item>
    
    <item>
      <title>Ansible Overview</title>
      <link>https://zhangeamon.top/ansible/ansible-overview/</link>
      <pubDate>Thu, 25 Oct 2018 09:16:22 +0800</pubDate>
      
      <guid>https://zhangeamon.top/ansible/ansible-overview/</guid>
      <description>主要模块
 PLAYBOOKS： 任务剧本（任务集），编排定义Ansible任务集的配置文件，由Ansible顺序依次执行，通常是JSON格式的YML文件 INVENTORY： Ansible管理主机的清单/etc/anaible/hosts MODULES： Ansible执行命令的功能模块，多数为内置的核心模块，也可自定义,ansible-doc –l 可查看模块 PLUGINS： 模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API： 供第三方程序调用的应用程序编程接口 ANSIBLE： ansible命令工具，其为核心执行工具  常用命令
 /usr/bin/ansible 主程序，临时命令执行工具 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具 /usr/bin/ansible-playbook 定制自动化任务，编排剧本工具 /usr/bin/ansible-pull 远程执行命令的工具 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台  配置文件
 /etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles/ 存放角色的目录  配置说明
/etc/ansible/ansible.cfg
   [defaults] #inventory = /etc/ansible/hosts # 主机列表配置文件 #library = /usr/share/my_modules/ # 库文件存放目录 #remote_tmp = $HOME/.ansible/tmp #临时py命令文件存放在远程主机目录 #local_tmp = $HOME/.ansible/tmp # 本机的临时命令执行目录 #forks = 5 # 默认并发数 #sudo_user = root # 默认sudo 用户 #ask_sudo_pass = True #每次执行ansible命令是否询问ssh密码 #ask_pass = True #连接时提示输入ssh密码 #remote_port = 22 #远程主机的默认端口，生产中这个端口应该会不同 #log_path = /var/log/ansible.</description>
    </item>
    
    <item>
      <title>Teleport 堡垒机</title>
      <link>https://zhangeamon.top/network-security/teleport/</link>
      <pubDate>Wed, 24 Oct 2018 09:40:32 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/teleport/</guid>
      <description>https://gravitational.com/teleport/ https://mritd.me/2017/11/09/set-up-teleport/</description>
    </item>
    
    <item>
      <title>Git 只下载指定文件或文件夹下的内容</title>
      <link>https://zhangeamon.top/linux/git-sparsecheckout/</link>
      <pubDate>Tue, 23 Oct 2018 17:21:01 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/git-sparsecheckout/</guid>
      <description> 需求 　有些时候我们只想下载项目中的部分文件或文件夹下面的内容，而不是整个项目。这个时候使用git clone难免有些过重。
是时候来寻找一个合适的方式来满足我们的需求了。这就是Sparse Checkout模式
具体方法 比如我只想下载 https://github.com/bodani/bodani.github.io.git 中的k8s 目录的内容
mkdir gitSparse cd gitSparse git init git remote add -f origin https://github.com/bodani/bodani.github.io.git git config core.sparsecheckout true echo &amp;quot;k8s&amp;quot; &amp;gt;&amp;gt; .git/info/sparse-checkout git checkout master git pull  　</description>
    </item>
    
    <item>
      <title>Go 语言安装及配置</title>
      <link>https://zhangeamon.top/go/install/</link>
      <pubDate>Tue, 23 Oct 2018 14:10:27 +0800</pubDate>
      
      <guid>https://zhangeamon.top/go/install/</guid>
      <description>1.下载安装包
https://golang.org/dl/
https://golang.google.cn/dl/
将下载的二进制包解压至 /usr/local目录
2.配置环境变量
cat /etc/profile.d/go.sh
export GOROOT=/usr/local/go export GOPATH=~/golib:~/goproject export GOBIN=~/gobin export PATH=$PATH:$GOROOT/bin:$GOBIN export GOPROXY=https://goproxy.cn export GO111MODULE=on  说明:
GOROOT go安装包存放位置
GOPATH 工作区，多个工作区之间用冒号间隔
GOBIN 可执行文件目录
PATH 系统环境变量
Goproxy 中国完全实现了 Go 的模块代理协议。并且它是一个由中国备受信赖的云服务提供商七牛云支持的非营利性项目。目标是为中国和世界上其他地方的 Gopher 们提供一个免费的、可靠的、持续在线的且经过 CDN 加速的模块代理。
3.目录结构
src 源码
pkg 归档文件 .a 后缀
4.常用命令及参数
go run 执行
-a -n - p -w
go build
go install 编译并安装指定的代码包及它们的依赖包 go get 下载远程代码到GOPATH第一个工作区中，并编译执行
go clean
go doc
go list
go fmt</description>
    </item>
    
    <item>
      <title>Let&#39;s Encrypt 通配符证书</title>
      <link>https://zhangeamon.top/network-security/letusencrypt/</link>
      <pubDate>Mon, 22 Oct 2018 13:56:11 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/letusencrypt/</guid>
      <description>1.介绍
什么是 Let&amp;rsquo;s Encrypt？ 部署 HTTPS 网站的时候需要证书，证书由 CA 机构签发，大部分传统 CA 机构签发证书是需要收费的，这不利于推动 HTTPS 协议的使用。 Let&amp;rsquo;s Encrypt 也是一个 CA 机构，但这个 CA 机构是免费的！也就是说签发证书不需要任何费用。 Let&amp;rsquo;s Encrypt 由于是非盈利性的组织，需要控制开支，他们搞了一个非常有创意的事情，设计了一个 ACME 协议，目前该协议的版本是 v1。 那为什么要创建 ACME 协议呢，传统的 CA 机构是人工受理证书申请、证书更新、证书撤销，完全是手动处理的。而 ACME 协议规范化了证书申请、更新、撤销等流程，只要一个客户端实现了该协议的功能，通过客户端就可以向 Let&amp;rsquo;s Encrypt 申请证书，也就是说 Let&amp;rsquo;s Encrypt CA 完全是自动化操作的。 任何人都可以基于 ACME 协议实现一个客户端，官方推荐的客户端是Certbot 。
什么是通配符证书 在没有出现通配符证书之前，Let&amp;rsquo;s Encrypt 支持两种证书。
1）单域名证书：证书仅仅包含一个主机。
2）SAN 证书：一张证书可以包括多个主机（Let&amp;rsquo;s Encrypt 限制是 20），也就是证书可以包含下列的主机：www.example.com、www.example.cn、blog.example.com 等等。 证书包含的主机可以不是同一个注册域，不要问我注册域是什么？注册域就是向域名注册商购买的域名。 对于个人用户来说，由于主机并不是太多，所以使用 SAN 证书完全没有问题，但是对于大公司来说有一些问题： 子域名非常多，而且过一段时间可能就要使用一个新的主机。 注册域也非常多。 读者可以思考下，对于大企业来说，SAN 证书可能并不能满足需求，类似于 sina 这样的网站，所有的主机全部包含在一张证书中，而使用 Let&amp;rsquo;s Encrypt 证书是无法满足的。
Let&amp;rsquo;s Encrypt 通配符证书 通配符证书就是证书中可以包含一个通配符，比如 .</description>
    </item>
    
    <item>
      <title>自签名证书</title>
      <link>https://zhangeamon.top/network-security/cert/</link>
      <pubDate>Mon, 22 Oct 2018 11:05:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/network-security/cert/</guid>
      <description>1.环境预备
curl -s -L -o /usr/local/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
curl -s -L -o /usr/local/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
chmod +x /usr/local/bin/{cfssl,cfssljson}
2.生成配置模板
三类证书：服务器证书server cert，客户端证书client cert，对等证书peer cert(表示既是server cert又是client cert)
cfssl print-defaults config &amp;gt; ca-config.json
cat ca-config.json
{ &amp;quot;signing&amp;quot;: { &amp;quot;default&amp;quot;: { &amp;quot;expiry&amp;quot;: &amp;quot;168h&amp;quot; }, &amp;quot;profiles&amp;quot;: { &amp;quot;www&amp;quot;: { &amp;quot;expiry&amp;quot;: &amp;quot;8760h&amp;quot;, &amp;quot;usages&amp;quot;: [ &amp;quot;signing&amp;quot;, &amp;quot;key encipherment&amp;quot;, &amp;quot;server auth&amp;quot; ] }, &amp;quot;client&amp;quot;: { &amp;quot;expiry&amp;quot;: &amp;quot;8760h&amp;quot;, &amp;quot;usages&amp;quot;: [ &amp;quot;signing&amp;quot;, &amp;quot;key encipherment&amp;quot;, &amp;quot;client auth&amp;quot; ] } } } }  修改模板, 包括三种类型的证书</description>
    </item>
    
    <item>
      <title>ssh 免密码登&amp;跳板机配置</title>
      <link>https://zhangeamon.top/linux/no-passwd/</link>
      <pubDate>Thu, 18 Oct 2018 14:46:58 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/no-passwd/</guid>
      <description>Linux 免密码登录实现 1.说明
DES算法 加/解速度快,密钥量短,采用对称加密　RSA算法好 算法复杂,加/解速度慢,采用非对称加密　2.生成秘钥
$ssh-keygen -t dsa -P &#39;&#39; Generating public/private dsa key pair. Enter file in which to save the key (/root/.ssh/id_dsa): Your identification has been saved in /root/.ssh/id_dsa. Your public key has been saved in /root/.ssh/id_dsa.pub. The key fingerprint is: SHA256:/K/dqHKbkmm/0qw9IOFvZwRAPx36+yQtXtLM353spns root@kvm71 The key&#39;s randomart image is: +---[DSA 1024]----+ | .. . | | .. o . | | .+ . | | .</description>
    </item>
    
    <item>
      <title>Linux wheel 用户组</title>
      <link>https://zhangeamon.top/linux/wheel/</link>
      <pubDate>Thu, 18 Oct 2018 10:33:14 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/wheel/</guid>
      <description> wheel 用户组 1.在Linux系统中root用户作为超级管理员拥有至高无上的权限，其他用户可以使用su命令将自己切换为root用户。为了加强系统的安全性,对系统用户权限进行限制。 设置为只有wheel用户组的成员拥有su 权利，其他用户不再具备切换到root 用户的权限。
2.设置
　2.1 新建user1 用户并添加用到wheel组
 $ useradd user1 $ passwd user1 $ gpasswd -a user1 wheel  　2.2 验证
 $ sudo su - user1 $ [user1@kvm73 ~]$ sudo su - root $ [user1@kvm73 ~]$ sudo su - root  3.限制其他用户
 $vi /etc/pam.d/su #auth required pam_wheel.so use_uid 这一行去掉注释。 $vi /etc/login.defs SU_WHEEL_ONLY yes 这一行加入到文件末尾。  </description>
    </item>
    
    <item>
      <title>gpasswd 命令</title>
      <link>https://zhangeamon.top/linux/cmd-gpasswd/</link>
      <pubDate>Thu, 18 Oct 2018 09:52:03 +0800</pubDate>
      
      <guid>https://zhangeamon.top/linux/cmd-gpasswd/</guid>
      <description> gpasswd 命令详解  gpasswd命令是Linux下工作组文件/etc/group和/etc/gshadow的管理工具，用于指定要管理的工作组。
 选项详解：
-a : 添加用户到组
-d : 从组删除用户
-A：指定管理员
-M：指定组成员和-A的用途差不多；
-r：删除密码；
-R：限制用户登入组，只有组中的成员才可以用newgrp加入该组。
 实例：
  　3.1 将userA添加到groupB用户组里面：
 gpasswd -a userA groupB  　注意：添加用户到某一个组可以使用 usermod -G groupB userA 这个命令可以添加一个用户到指定的组，但是以前添加的组就会清空掉, 所以想要添加一个用户到一个组，同时保留以前添加的组时，
 请使用gpasswd这个命令来添加操作用户。  　3.2 将userA设置为groupA的群组管理员：
 gpasswd -A userA groupA  </description>
    </item>
    
    <item>
      <title>Kubernetes 安装　- V1.10</title>
      <link>https://zhangeamon.top/k8s/v1.10/</link>
      <pubDate>Thu, 18 Oct 2018 09:12:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/k8s/v1.10/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kubernetes 安装　- V1.11</title>
      <link>https://zhangeamon.top/k8s/v1.11/</link>
      <pubDate>Thu, 18 Oct 2018 09:12:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/k8s/v1.11/</guid>
      <description></description>
    </item>
    
    <item>
      <title>两地三机房方案落地</title>
      <link>https://zhangeamon.top/tidb/%E4%B8%A4%E5%9C%B0%E4%B8%89%E6%9C%BA%E6%88%BF%E6%96%B9%E6%A1%88%E8%90%BD%E5%9C%B0/</link>
      <pubDate>Wed, 17 Oct 2018 17:19:09 +0800</pubDate>
      
      <guid>https://zhangeamon.top/tidb/%E4%B8%A4%E5%9C%B0%E4%B8%89%E6%9C%BA%E6%88%BF%E6%96%B9%E6%A1%88%E8%90%BD%E5%9C%B0/</guid>
      <description></description>
    </item>
    
    <item>
      <title>主从流复制</title>
      <link>https://zhangeamon.top/postgres/replication01/</link>
      <pubDate>Wed, 17 Oct 2018 14:55:38 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/replication01/</guid>
      <description>历史演变
replication
主库配置 根据实际情况分配流复制权限 vi pg_hba.conf host replication all 10.2.0.0/0 trust  vi postgresql.conf max_wal_senders = 10 wal_level = logical # minimal, replica, or logical hot_standby = on # 正常在从库配置，如果在主库配置完毕，因为从库复制主库配置不需要再修改从库配置。 wal_log_hints = on  从库配置 1 数据库安装
2 从主库复制数据
pg_basebackup -h 10.2.0.14 -U postgres -F p -P -R -D /var/lib/pgsql/10/data/ --checkpoint=fast -l postgresback20181219  pg_basebackup支持两种全量备份的方式，
 以fetch的方式，先备份数据在备份日志
 以stream的方式，并行的备份数据和日志
  pg_basebackup对于全量备份的数据和日志，提供了串行备份和并行备份的方式。fetch模式也就是串行备份需要保证在备份数据的过程中，备份开始时刻的日志需要一直保存下来， 也就说pg的wal_keep_segments需要足够大去保存日志文件，如果备份数据期间，日志开始时刻的日志已经被移除，那么备份就会失败。而stream模式，也就是并行备份过程中wal_max_sender必须保证不小于2。 而stream模式不支持，将数据和日志以流的方式输出到标准输出
限速，在生产系统中防止对正常业务的影响
-r, --max-rate=RATE maximum transfer rate to transfer data directory (in kB/s, or use suffix &amp;quot;k&amp;quot; or &amp;quot;M&amp;quot;)  注意新拷贝数据的权限</description>
    </item>
    
    <item>
      <title>安装 Postgresql</title>
      <link>https://zhangeamon.top/postgres/install01/</link>
      <pubDate>Wed, 17 Oct 2018 14:37:56 +0800</pubDate>
      
      <guid>https://zhangeamon.top/postgres/install01/</guid>
      <description>官网
1.准备源
清除历史残余，有些是系统自带的旧版本数据库 rpm -qa | grep postgres rpm -r **** 安装新数据源 yum install https://download.postgresql.org/pub/repos/yum/10/redhat/rhel-7-x86_64/pgdg-centos10-10-2.noarch.rpm yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 可将所有的软件更新到最新版本如 ， postgresql-10.2 更新到当前最新的postgresql-10.6 yum update -y  2.安装
yum install -y postgresql10-server postgresql10 postgresql10-contrib  3.初始化
默认 /usr/pgsql-10/bin/postgresql-10-setup initdb 自定义 /usr/pgsql-10/bin/initdb -D $PGDATA -U postgres -E UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8 -k -D 数据存放位置 -U 超级用户 -E 默认编码 --lc-collate 区域 Collate会影响中文的排序，在zh_CN的区域下中文按拼音排序，其它区域按字符编码排序。 --lc-ctype 字符类型Ctype会影响pg_trgm和部分正则匹配的结果，比如Ctype为&#39;C&#39;时，pg_trgm将无法支持中文。 -k 使用 data checksums  可将数据存放到其他目录下，使用软连接的方式。
为什么会使用软连接而不是更改PGDATA环境变量，因为升级数据库的时 PGDATA 被指回默认值。</description>
    </item>
    
    <item>
      <title>技术图谱</title>
      <link>https://zhangeamon.top/about/tech/</link>
      <pubDate>Tue, 16 Oct 2018 11:25:47 +0800</pubDate>
      
      <guid>https://zhangeamon.top/about/tech/</guid>
      <description> 基础服务架构 Postgres架构  服务治理  接口层 限流，降级，路由 服务层 自动发布，依赖调用 资源层 动态扩容，缩容  </description>
    </item>
    
    <item>
      <title>数据仓库介绍</title>
      <link>https://zhangeamon.top/dw/introduce/</link>
      <pubDate>Fri, 21 Sep 2018 09:54:50 +0800</pubDate>
      
      <guid>https://zhangeamon.top/dw/introduce/</guid>
      <description> 数据库与数据仓库的区别  数据库是面向事务的设计，数据仓库是面向主题设计的。 数据库一般服务于业务系统的，数据仓库一般是服务于分析系统的。 数据库一般存储在线交易数据，数据仓库存储的一般是历史数据。 数据库设计是尽量避免冗余，数据仓库在设计是有意引入冗余。 数据库是为捕获数据而设计，数据仓库是为分析数据而设计。 数据库一般会对数据进行增删改查，数据仓库一般只对进行增和查，基本不会修改数据。   全量表：每天的所有的最新状态的数据， 增量表：每天的新增数据，增量数据是上次导出之后的新数据。 拉链表：维护历史状态，以及最新状态数据的一种表，拉链表根据拉链粒度的不同，实际上相当于快照，只不过做了优化，去除了一部分不变的记录而已,通过拉链表可以很方便的还原出拉链时点的客户记录。 流水表： 对于表的每一个修改都会记录，可以用于反映实际记录的变更。  </description>
    </item>
    
    <item>
      <title>关于本站</title>
      <link>https://zhangeamon.top/about/hugo/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zhangeamon.top/about/hugo/</guid>
      <description>关于本站目的 本站用于记录总结本人在日常工作中所使用的技术，遇到的问题及解决方法等。技术在于积累，更重于分享和交流。 一个人可以跑的更快，一群人可以走的更远! 
关于本站使用技术 本网站是基于Hugo生成, 可运行在Caddy服务中。文档格式为markdown。　 未完成
 目前的导航栏是有硬编码写在simple/layouts/partials/header.html中，数据与展现完全耦合。TODO 数据有config.toml 中定义，　页面动态加载数据。数据与展现解耦，实现通用主题。 二级目录生成plubic网页时没有index.html 索引页。 添加百度统计功能, 已完成 添加站内搜索功能   站内搜索功能 ,只有标题支持中文 contain 不支持中文
https://gohugo.io/tools/search/
https://github.com/10Dimensional/hugo-algolia

 
原博客地址
Github</description>
    </item>
    
  </channel>
</rss>